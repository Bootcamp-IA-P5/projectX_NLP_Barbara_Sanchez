# ğŸ¤ PresentaciÃ³n: DetecciÃ³n de Hate Speech en YouTube

## ğŸ“Š SLIDE 1: IntroducciÃ³n del Proyecto

### Objetivo
Desarrollar un sistema automatizado de detecciÃ³n de hate speech en comentarios de YouTube utilizando tÃ©cnicas de Machine Learning y Deep Learning.

### Problema a Resolver
- YouTube recibe millones de comentarios diarios
- Necesidad de moderaciÃ³n automÃ¡tica de contenido tÃ³xico
- DetecciÃ³n temprana de mensajes de odio

---

## ğŸ“Š SLIDE 2: Dataset Utilizado

### CaracterÃ­sticas del Dataset
- **Total de comentarios**: 1,000
- **Idioma**: InglÃ©s
- **Fuente**: YouTube
- **DistribuciÃ³n de clases**:
  - âœ… **No tÃ³xicos**: 538 comentarios (53.8%)
  - âš ï¸ **TÃ³xicos**: 462 comentarios (46.2%)
  - **Ratio de balance**: 0.86 (relativamente balanceado)

### EstadÃ­sticas del Texto
- **Longitud promedio**: 98.4 caracteres
- **Palabras promedio**: 16.1 palabras
- **Longitud mediana**: 53.0 caracteres
- **Longitud mÃ¡xima**: 2,184 caracteres
- **DesviaciÃ³n estÃ¡ndar**: 142.5 caracteres

### ComparaciÃ³n TÃ³xicos vs No TÃ³xicos
- **Longitud promedio (tÃ³xicos)**: 102.0 caracteres
- **Longitud promedio (no tÃ³xicos)**: 95.2 caracteres
- **Palabras promedio (tÃ³xicos)**: 16.9 palabras
- **Palabras promedio (no tÃ³xicos)**: 15.4 palabras

**Insight**: Los comentarios tÃ³xicos tienden a ser ligeramente mÃ¡s largos.

---

## ğŸ“Š SLIDE 3: Pipeline de Procesamiento

### 1. Preprocesamiento de Texto
- âœ… TokenizaciÃ³n con spaCy
- âœ… ConversiÃ³n a minÃºsculas
- âœ… EliminaciÃ³n de stop words
- âœ… LematizaciÃ³n
- âœ… ExpansiÃ³n de contracciones
- âœ… EliminaciÃ³n de repeticiones

### 2. Feature Engineering
- âœ… **TF-IDF Vectorizer**: 5,000 features mÃ¡ximas
- âœ… **Count Vectorizer**: Alternativa probada
- âœ… N-grams: Unigramas y bigramas

### 3. DivisiÃ³n de Datos
- **Train**: 800 comentarios (80%)
- **Test**: 200 comentarios (20%)
- **EstratificaciÃ³n**: Mantiene proporciÃ³n de clases

---

## ğŸ“Š SLIDE 4: Modelos Baseline Evaluados

| Modelo | F1-Score (Test) | Accuracy | Precision | Recall | Overfitting |
|--------|----------------|----------|-----------|--------|-------------|
| **Naive Bayes** | 0.6310 | 0.60 | 0.55 | 0.73 | 23.81% âŒ |
| **Logistic Regression** | 0.7200 | 0.64 | 0.62 | 0.84 | 16.80% âŒ |
| **SVM** | **0.7263** | **0.65** | **0.63** | **0.85** | **18.50%** âŒ |
| **Random Forest** | 0.6275 | 0.59 | 0.54 | 0.73 | 21.25% âŒ |

### ConclusiÃ³n Baseline
- **Mejor modelo**: SVM con TF-IDF
- **Problema principal**: Overfitting alto (> 15%)
- **Objetivo**: Reducir overfitting a < 5%

---

## ğŸ“Š SLIDE 5: OptimizaciÃ³n de HiperparÃ¡metros

### TÃ©cnica Utilizada
- **Optuna**: Framework de optimizaciÃ³n bayesiana
- **Objetivo**: Maximizar F1-score y minimizar overfitting
- **Trials**: 50 iteraciones

### ParÃ¡metros Optimizados (SVM)
- **C**: 0.056 (regularizaciÃ³n)
- **Kernel**: linear
- **Umbral de decisiÃ³n**: 0.466 (optimizado para balance precision-recall)

### Resultados de OptimizaciÃ³n

| MÃ©trica | Antes | DespuÃ©s | Mejora |
|---------|-------|---------|--------|
| **F1-Score (Test)** | 0.7263 | **0.7407** | +1.98% âœ… |
| **Overfitting** | 18.50% | **2.54%** | -86.3% âœ…âœ… |
| **Falsos Positivos** | 85 | **44** | -48.2% âœ… |

---

## ğŸ“Š SLIDE 6: Modelo Final Seleccionado

### SVM Optimizado - MÃ©tricas Finales

| MÃ©trica | Valor | Objetivo | Estado |
|---------|-------|----------|--------|
| **F1-Score (Test)** | **0.7407** | > 0.55 | âœ… Cumple |
| **F1-Score (Train)** | 0.7595 | - | - |
| **Accuracy** | **0.64** | - | - |
| **Precision** | **0.6452** | - | - |
| **Recall** | **0.8696** | - | - |
| **Overfitting** | **2.54%** | < 5% | âœ… Cumple |

### Matriz de ConfusiÃ³n

```
                PredicciÃ³n
              No TÃ³xico  TÃ³xico
Real
No TÃ³xico        64       44
TÃ³xico           12       80
```

- **Verdaderos Negativos (TN)**: 64
- **Falsos Positivos (FP)**: 44 (reducidos de 85)
- **Falsos Negativos (FN)**: 12
- **Verdaderos Positivos (TP)**: 80

---

## ğŸ“Š SLIDE 7: Modelos Ensemble Evaluados

### Voting Classifier (Soft Voting)
- **F1-Score (Test)**: 0.4651
- **Overfitting**: 28.04% âŒ
- **Resultado**: No mejora vs modelo individual

### Stacking Classifier
- **F1-Score (Test)**: 0.6784
- **Overfitting**: 16.15% âŒ
- **Resultado**: Mejora F1 pero overfitting alto

### ConclusiÃ³n
- âŒ Los ensembles **no mejoran** el modelo individual optimizado
- âœ… El SVM optimizado sigue siendo el mejor

---

## ğŸ“Š SLIDE 8: Modelo Transformer (DistilBERT)

### ConfiguraciÃ³n
- **Modelo base**: distilbert-base-uncased
- **Ã‰pocas**: 5
- **Batch size**: 16
- **Learning rate**: 2e-05
- **TamaÃ±o del modelo**: 255 MB

### Resultados

| MÃ©trica | Valor | Objetivo | Estado |
|---------|-------|----------|--------|
| **F1-Score (Test)** | 0.7027 | > 0.55 | âœ… Cumple |
| **Accuracy** | 0.70 | - | - |
| **Overfitting** | **24.41%** | < 6% | âŒ No cumple |

### Â¿Por quÃ© NO se seleccionÃ³ DistilBERT?
1. âŒ **Overfitting alto** (24.41% > 6%)
2. âŒ **Modelo pesado** (255 MB vs 5 MB del SVM)
3. âŒ **Dataset pequeÃ±o** (1,000 ejemplos no suficientes para transformers)
4. âŒ **F1-score similar** (0.7027 vs 0.7407 del SVM)
5. âŒ **Tiempo de inferencia** mÃ¡s lento

---

## ğŸ“Š SLIDE 9: Comparativa Final de Modelos

| Modelo | F1-Score | Overfitting | TamaÃ±o | Velocidad | Seleccionado |
|--------|----------|-------------|--------|-----------|--------------|
| Naive Bayes | 0.6310 | 23.81% | 2 MB | âš¡âš¡âš¡ | âŒ |
| Logistic Regression | 0.7200 | 16.80% | 3 MB | âš¡âš¡âš¡ | âŒ |
| **SVM Optimizado** | **0.7407** | **2.54%** | **5 MB** | **âš¡âš¡** | **âœ…** |
| Random Forest | 0.6275 | 21.25% | 15 MB | âš¡âš¡ | âŒ |
| Voting Ensemble | 0.4651 | 28.04% | 25 MB | âš¡ | âŒ |
| Stacking Ensemble | 0.6784 | 16.15% | 30 MB | âš¡ | âŒ |
| DistilBERT | 0.7027 | 24.41% | 255 MB | ğŸŒ | âŒ |

### JustificaciÃ³n de SelecciÃ³n
âœ… **SVM Optimizado** ofrece:
- Mejor balance F1-score / Overfitting
- Modelo ligero y rÃ¡pido
- Cumple todos los objetivos (< 5% overfitting, F1 > 0.55)
- Ideal para producciÃ³n

---

## ğŸ“Š SLIDE 10: ProductivizaciÃ³n - API REST

### TecnologÃ­a
- **FastAPI**: Framework moderno y rÃ¡pido
- **Uvicorn**: Servidor ASGI
- **Endpoints implementados**:
  - `POST /predict` - AnÃ¡lisis individual
  - `POST /predict/batch` - AnÃ¡lisis por lotes
  - `POST /analyze/youtube` - AnÃ¡lisis de video YouTube
  - `GET /predictions` - Historial de predicciones
  - `GET /predictions/stats` - EstadÃ­sticas
  - `GET /health` - Health check

### CaracterÃ­sticas
- âœ… DocumentaciÃ³n automÃ¡tica (Swagger UI)
- âœ… ValidaciÃ³n de datos con Pydantic
- âœ… CORS configurado
- âœ… Manejo de errores robusto

---

## ğŸ“Š SLIDE 11: Frontend - Interfaz Web

### TecnologÃ­as
- **React 18**: Framework UI
- **Vite**: Build tool rÃ¡pido
- **Tailwind CSS**: Estilos modernos
- **Recharts**: Visualizaciones
- **Framer Motion**: Animaciones

### Funcionalidades Implementadas
1. âœ… **Analizador Individual**: AnÃ¡lisis de texto en tiempo real
2. âœ… **AnÃ¡lisis por Lotes**: MÃºltiples textos simultÃ¡neos
3. âœ… **AnÃ¡lisis de YouTube**: ExtracciÃ³n y anÃ¡lisis de comentarios
4. âœ… **EDA (AnÃ¡lisis Exploratorio)**: Visualizaciones del dataset
5. âœ… **Comparativa de Modelos**: GrÃ¡ficos de rendimiento
6. âœ… **EstadÃ­sticas**: Dashboard de anÃ¡lisis realizados
7. âœ… **MLflow Metrics**: Tracking de experimentos

---

## ğŸ“Š SLIDE 12: IntegraciÃ³n con YouTube

### Funcionalidad
- ExtracciÃ³n automÃ¡tica de comentarios de videos de YouTube
- AnÃ¡lisis en tiempo real de cada comentario
- EstadÃ­sticas agregadas del video

### CaracterÃ­sticas
- âœ… Sin necesidad de API Key (usa `youtube-comment-downloader`)
- âœ… Filtrado por popularidad (top, newest)
- âœ… LÃ­mite configurable de comentarios
- âœ… AnÃ¡lisis individual y agregado

### Ejemplo de Uso
```
URL: https://www.youtube.com/watch?v=VIDEO_ID
Max comentarios: 20
Resultado: % tÃ³xicos, lista de comentarios tÃ³xicos, estadÃ­sticas
```

---

## ğŸ“Š SLIDE 13: Base de Datos y MLFlow

### Base de Datos (SQLite)
- âœ… Guardado automÃ¡tico de todas las predicciones
- âœ… Campos: texto, predicciÃ³n, probabilidades, timestamp
- âœ… Consulta de historial y estadÃ­sticas

### MLFlow Tracking
- âœ… Registro de todos los experimentos
- âœ… MÃ©tricas: F1, Accuracy, Precision, Recall
- âœ… ParÃ¡metros: hiperparÃ¡metros optimizados
- âœ… Modelos: versionado de modelos entrenados
- âœ… UI disponible en `http://localhost:5000`

---

## ğŸ“Š SLIDE 14: DockerizaciÃ³n y Despliegue

### Docker
- âœ… **Backend**: Dockerfile multi-stage (Python 3.11)
- âœ… **Frontend**: Dockerfile multi-stage (Node.js + Nginx)
- âœ… **docker-compose.yml**: OrquestaciÃ³n local

### Despliegue en Render
- âœ… **Backend**: Web Service (Docker)
- âœ… **Frontend**: Web Service (Docker + Nginx)
- âœ… **Blueprint**: Despliegue conjunto desde `render.yaml`
- âœ… **Auto-deploy**: Activado desde rama `develop`

---

## ğŸ“Š SLIDE 15: Logros por Nivel

### ğŸŸ¢ Nivel Esencial
- âœ… Modelo ML funcional (SVM, F1=0.7407)
- âœ… Overfitting < 5% (2.54%)
- âœ… API REST productiva
- âœ… Repositorio Git organizado
- âœ… DocumentaciÃ³n completa

### ğŸŸ¡ Nivel Medio
- âœ… Ensemble de modelos (Voting, Stacking)
- âœ… IntegraciÃ³n YouTube
- âœ… Tests unitarios (pytest)
- âœ… OptimizaciÃ³n con Optuna

### ğŸŸ  Nivel Avanzado
- âœ… Redes neuronales (DistilBERT)
- âœ… AnÃ¡lisis tiempo real
- âœ… Despliegue pÃºblico (Render)
- âœ… DockerizaciÃ³n completa

### ğŸ”´ Nivel Experto
- âœ… Transformers (DistilBERT)
- âœ… Base de datos (SQLite)
- âœ… MLFlow tracking

---

## ğŸ“Š SLIDE 16: Resultados Finales

### Objetivos Cumplidos âœ…

| Objetivo | Valor Obtenido | Objetivo | Estado |
|----------|----------------|----------|--------|
| **F1-Score** | **0.7407** | > 0.55 | âœ… |
| **Overfitting** | **2.54%** | < 5% | âœ… |
| **Precision** | **0.6452** | - | âœ… |
| **Recall** | **0.8696** | - | âœ… |

### Mejoras Logradas
- âœ… **ReducciÃ³n de overfitting**: 18.50% â†’ 2.54% (-86.3%)
- âœ… **Mejora de F1-score**: 0.7263 â†’ 0.7407 (+1.98%)
- âœ… **ReducciÃ³n de falsos positivos**: 85 â†’ 44 (-48.2%)

### Sistema Completo
- âœ… Backend API funcional
- âœ… Frontend moderno y completo
- âœ… IntegraciÃ³n YouTube
- âœ… Base de datos y tracking
- âœ… Dockerizado y desplegado

---

## ğŸ“Š SLIDE 17: Conclusiones

### Logros Principales
1. âœ… Modelo con **overfitting < 5%** (2.54%)
2. âœ… **F1-score > 0.55** (0.7407)
3. âœ… Sistema completo y productivo
4. âœ… Todos los niveles implementados

### Aprendizajes
- Los modelos simples (SVM) pueden superar a modelos complejos (Transformers) con datasets pequeÃ±os
- La optimizaciÃ³n de hiperparÃ¡metros es crucial para reducir overfitting
- El balance precision-recall requiere ajuste fino del umbral de decisiÃ³n

### PrÃ³ximos Pasos
- Ampliar el dataset para mejorar el modelo
- Probar con mÃ¡s datos para DistilBERT
- Implementar seguimiento en tiempo real con WebSockets
- AÃ±adir soporte multiidioma

---

## ğŸ“Š SLIDE 18: TecnologÃ­as Utilizadas

### Backend
- Python 3.11, FastAPI, scikit-learn, Optuna, Transformers, SQLAlchemy, MLFlow, spaCy

### Frontend
- React 18, Vite, Tailwind CSS, Recharts, Framer Motion, Axios

### DevOps
- Docker, Docker Compose, Render, Git/GitHub

### ML/NLP
- scikit-learn, Hugging Face Transformers, spaCy, NLTK, Optuna

---

## ğŸ“Š SLIDE 19: MÃ©tricas TÃ©cnicas del Proyecto

### CÃ³digo
- **LÃ­neas de cÃ³digo**: ~5,000+
- **Archivos Python**: 20+
- **Componentes React**: 10+
- **Tests unitarios**: 5 suites

### Modelos
- **Modelos entrenados**: 7 (4 baseline + 1 optimizado + 2 ensemble)
- **Experimentos MLFlow**: 10+
- **Tiempo de entrenamiento**: ~2 horas total

### Datos
- **Dataset**: 1,000 comentarios
- **Features**: 5,000 (TF-IDF)
- **Predicciones guardadas**: Variable (segÃºn uso)

---

## ğŸ“Š SLIDE 20: Demo / Q&A

### Demo en Vivo
- Mostrar la interfaz web
- Analizar un texto de ejemplo
- Analizar un video de YouTube
- Mostrar estadÃ­sticas y comparativas

### Preguntas Frecuentes
- Â¿Por quÃ© SVM y no DistilBERT?
- Â¿CÃ³mo se reduce el overfitting?
- Â¿QuÃ© pasa con otros idiomas?
- Â¿CÃ³mo escalar el sistema?

---

## ğŸ“§ Contacto

**Proyecto**: DetecciÃ³n de Hate Speech en YouTube  
**Autora**: BÃ¡rbara SÃ¡nchez  
**Repositorio**: Bootcamp-IA-P5/projectX_NLP_Barbara_Sanchez  
**Rama**: develop

---

## ğŸ“ Notas para la PresentaciÃ³n

### Puntos Clave a Destacar
1. **Overfitting reducido de 18.50% a 2.54%** - Logro tÃ©cnico importante
2. **F1-score de 0.7407** - Supera el objetivo de 0.55
3. **Sistema completo** - No solo un modelo, sino un producto funcional
4. **Todos los niveles completados** - Esencial, Medio, Avanzado, Experto

### Visualizaciones Recomendadas
- GrÃ¡fico de evoluciÃ³n del F1-score
- Comparativa de overfitting
- Matriz de confusiÃ³n
- Screenshots del frontend
- Diagrama de arquitectura

### Tiempo Estimado
- **PresentaciÃ³n completa**: 15-20 minutos
- **Demo**: 5 minutos
- **Q&A**: 5-10 minutos

