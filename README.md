# ðŸŽ¯ DetecciÃ³n de Hate Speech en YouTube

Sistema completo de detecciÃ³n automÃ¡tica de mensajes de odio en comentarios de YouTube utilizando tÃ©cnicas de Machine Learning y Deep Learning, con API REST y interfaz web moderna.

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-18-blue.svg)](https://reactjs.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ðŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#-descripciÃ³n)
- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura](#-arquitectura)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [API Documentation](#-api-documentation)
- [Modelos](#-modelos)
- [Despliegue](#-despliegue)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [TecnologÃ­as](#-tecnologÃ­as)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Licencia](#-licencia)

---

## ðŸŽ¯ DescripciÃ³n

Este proyecto implementa un sistema end-to-end para la detecciÃ³n automÃ¡tica de hate speech en comentarios de YouTube. El sistema utiliza tÃ©cnicas de Procesamiento del Lenguaje Natural (NLP) y Machine Learning para clasificar comentarios como tÃ³xicos o no tÃ³xicos.

### Objetivos del Proyecto

- âœ… **Modelo ML funcional**: F1-score > 0.55 (obtenido: 0.7407)
- âœ… **Control de overfitting**: < 5% (obtenido: 2.54%)
- âœ… **Sistema productivo**: API REST + Frontend completo
- âœ… **IntegraciÃ³n YouTube**: AnÃ¡lisis automÃ¡tico de comentarios
- âœ… **Tracking y persistencia**: MLFlow + Base de datos

---

## âœ¨ CaracterÃ­sticas

### Backend
- ðŸš€ API REST con FastAPI
- ðŸ¤– Modelo SVM optimizado con Optuna
- ðŸ“Š Tracking de experimentos con MLFlow
- ðŸ’¾ Base de datos SQLite para predicciones
- ðŸŽ¬ IntegraciÃ³n con YouTube (extracciÃ³n de comentarios)
- ðŸ³ ContainerizaciÃ³n con Docker

### Frontend
- âš›ï¸ Interfaz moderna con React 18
- ðŸŽ¨ DiseÃ±o responsive con Tailwind CSS
- ðŸ“ˆ Visualizaciones interactivas con Recharts
- ðŸ” AnÃ¡lisis individual, por lotes y YouTube
- ðŸ“Š Dashboard de estadÃ­sticas y EDA
- ðŸŽ­ Animaciones con Framer Motion

### Modelos ML
- ðŸ“Š 4 modelos baseline evaluados
- ðŸ”§ OptimizaciÃ³n de hiperparÃ¡metros con Optuna
- ðŸŽ¯ Ensembles probados (Voting, Stacking)
- ðŸ§  Transformers evaluados (DistilBERT)
- ðŸ† Modelo final: SVM Optimizado

---

## ðŸ—ï¸ Arquitectura

### Diagrama de Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND (React)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   AnÃ¡lisis   â”‚  â”‚   YouTube    â”‚  â”‚ EstadÃ­sticasâ”‚          â”‚
â”‚  â”‚  Individual  â”‚  â”‚   Analysis   â”‚  â”‚   & EDA     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                 â”‚                  â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                    â”‚  Axios Clientâ”‚                             â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/REST
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (FastAPI)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    API Endpoints                         â”‚  â”‚
â”‚  â”‚  â€¢ POST /predict          (anÃ¡lisis individual)         â”‚  â”‚
â”‚  â”‚  â€¢ POST /predict/batch    (anÃ¡lisis por lotes)           â”‚  â”‚
â”‚  â”‚  â€¢ POST /analyze/youtube  (anÃ¡lisis YouTube)             â”‚  â”‚
â”‚  â”‚  â€¢ GET  /predictions     (historial)                    â”‚  â”‚
â”‚  â”‚  â€¢ GET  /predictions/stats (estadÃ­sticas)               â”‚  â”‚
â”‚  â”‚  â€¢ GET  /health           (health check)                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â”‚                                        â”‚
â”‚                        â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              HateSpeechPredictor                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚Preprocesador â”‚  â”‚ Vectorizador â”‚  â”‚   Modelo     â”‚   â”‚ â”‚
â”‚  â”‚  â”‚   (spaCy)    â”‚â†’ â”‚   (TF-IDF)   â”‚â†’ â”‚  (SVM Opt.)  â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                        â”‚                                        â”‚
â”‚                        â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Servicios Auxiliares                        â”‚  â”‚
â”‚  â”‚  â€¢ YouTube Extractor (youtube-comment-downloader)        â”‚  â”‚
â”‚  â”‚  â€¢ Database Manager (SQLite)                             â”‚  â”‚
â”‚  â”‚  â€¢ MLFlow Tracker (experiment tracking)                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Persistencia                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   SQLite     â”‚  â”‚   MLFlow     â”‚  â”‚   Modelos    â”‚          â”‚
â”‚  â”‚  (Prediccionesâ”‚  â”‚  (Experimentsâ”‚  â”‚   (.pkl)     â”‚          â”‚
â”‚  â”‚   & Stats)   â”‚  â”‚   & Metrics) â”‚  â”‚              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

```
1. ENTRADA
   â”œâ”€â”€ Texto individual â†’ POST /predict
   â”œâ”€â”€ MÃºltiples textos â†’ POST /predict/batch
   â””â”€â”€ URL YouTube â†’ POST /analyze/youtube

2. PREPROCESAMIENTO
   â”œâ”€â”€ TokenizaciÃ³n (spaCy)
   â”œâ”€â”€ NormalizaciÃ³n (minÃºsculas, stop words)
   â”œâ”€â”€ LematizaciÃ³n
   â””â”€â”€ VectorizaciÃ³n (TF-IDF, 5,000 features)

3. PREDICCIÃ“N
   â”œâ”€â”€ Carga modelo SVM optimizado
   â”œâ”€â”€ PredicciÃ³n con probabilidades
   â”œâ”€â”€ AplicaciÃ³n de umbral (0.466)
   â””â”€â”€ AmplificaciÃ³n de probabilidades

4. RESULTADO
   â”œâ”€â”€ ClasificaciÃ³n: TÃ³xico / No tÃ³xico
   â”œâ”€â”€ Probabilidades y confianza
   â””â”€â”€ Guardado en BD (opcional)

5. RESPUESTA
   â”œâ”€â”€ JSON con resultados
   â”œâ”€â”€ VisualizaciÃ³n en frontend
   â””â”€â”€ EstadÃ­sticas actualizadas
```

---

## ðŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.11+
- Node.js 18+
- Docker (opcional, para containerizaciÃ³n)
- Git

### Backend

1. **Clonar el repositorio**
```bash
git clone https://github.com/Bootcamp-IA-P5/projectX_NLP_Barbara_Sanchez.git
cd projectX_NLP_Barbara_Sanchez
```

2. **Instalar dependencias**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Descargar modelos de spaCy**
```bash
python -m spacy download en_core_web_sm
```

4. **Descargar datos de NLTK**
```python
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
```

5. **Verificar que los modelos estÃ¡n presentes**
```bash
# Los modelos deben estar en:
# backend/models/optimized/best_optimized_model.pkl
# backend/models/tfidf_vectorizer.pkl
```

### Frontend

```bash
cd frontend
npm install
```

---

## ðŸ’» Uso

### Backend

#### OpciÃ³n 1: Ejecutar directamente
```bash
cd backend
python run_api.py
# O
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

#### OpciÃ³n 2: Usar script de inicio
```bash
cd backend
bash start_api.sh
```

#### OpciÃ³n 3: Docker
```bash
cd backend
docker-compose up --build
```

La API estarÃ¡ disponible en: `http://localhost:8000`

- **DocumentaciÃ³n interactiva**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

### Frontend

```bash
cd frontend
npm run dev
```

El frontend estarÃ¡ disponible en: `http://localhost:3000`

### MLFlow UI

Para ver los experimentos de MLFlow:

```bash
cd backend
bash scripts/start_mlflow_ui.sh
```

O manualmente:
```bash
cd backend
mlflow ui --port 5000
```

Accede a: `http://localhost:5000`

---

## ðŸ“¡ API Documentation

### Endpoints Principales

#### 1. AnÃ¡lisis Individual
```http
POST /predict
Content-Type: application/json

{
  "text": "Este es un comentario a analizar"
}
```

**Respuesta**:
```json
{
  "text": "Este es un comentario a analizar",
  "is_toxic": false,
  "toxicity_label": "Not Toxic",
  "probability_toxic": 0.35,
  "probability_not_toxic": 0.65,
  "confidence": 0.65
}
```

#### 2. AnÃ¡lisis por Lotes
```http
POST /predict/batch
Content-Type: application/json

{
  "texts": [
    "Comentario 1",
    "Comentario 2",
    "Comentario 3"
  ]
}
```

#### 3. AnÃ¡lisis de YouTube
```http
POST /analyze/youtube
Content-Type: application/json

{
  "video_url": "https://www.youtube.com/watch?v=VIDEO_ID",
  "max_comments": 20,
  "sort_by": "top"
}
```

#### 4. Historial de Predicciones
```http
GET /predictions?limit=10&offset=0
```

#### 5. EstadÃ­sticas
```http
GET /predictions/stats
```

**Respuesta**:
```json
{
  "total_predictions": 150,
  "toxic_count": 65,
  "not_toxic_count": 85,
  "toxic_percentage": 43.33,
  "average_confidence": 0.72
}
```

#### 6. Health Check
```http
GET /health
```

**Respuesta**:
```json
{
  "status": "ok",
  "model_loaded": true,
  "timestamp": "2024-01-15T10:30:00"
}
```

### DocumentaciÃ³n Completa

Accede a la documentaciÃ³n interactiva en: `http://localhost:8000/docs`

---

## ðŸ¤– Modelos

### Modelo Final: SVM Optimizado

**MÃ©tricas**:
- **F1-Score (Test)**: 0.7407 âœ…
- **Overfitting**: 2.54% âœ…
- **Accuracy**: 0.64
- **Precision**: 0.6452
- **Recall**: 0.8696

**ParÃ¡metros**:
- C: 0.056
- Kernel: linear
- Umbral de decisiÃ³n: 0.466

**UbicaciÃ³n**: `backend/models/optimized/best_optimized_model.pkl`

### Modelos Evaluados

| Modelo | F1-Score | Overfitting | Estado |
|--------|----------|------------|--------|
| Naive Bayes | 0.6310 | 23.81% | âŒ |
| Logistic Regression | 0.7200 | 16.80% | âŒ |
| **SVM Optimizado** | **0.7407** | **2.54%** | âœ… |
| Random Forest | 0.6275 | 21.25% | âŒ |
| Voting Ensemble | 0.4651 | 28.04% | âŒ |
| Stacking Ensemble | 0.6784 | 16.15% | âŒ |
| DistilBERT | 0.7027 | 24.41% | âŒ |

### Entrenar Nuevos Modelos

Ver notebooks en `backend/notebooks/`:
- `04_Modeling_Baseline.ipynb` - Modelos baseline
- `05_Hyperparameter_Tuning.ipynb` - OptimizaciÃ³n
- `06_Ensemble_Models.ipynb` - Ensembles
- `08_Transformers_DistilBERT.ipynb` - Transformers

---

## ðŸš¢ Despliegue

### Docker

#### Backend
```bash
cd backend
docker build -t hate-speech-api .
docker run -p 8000:8000 hate-speech-api
```

#### Frontend
```bash
cd frontend
docker build -t hate-speech-frontend .
docker run -p 3000:80 hate-speech-frontend
```

#### Docker Compose
```bash
cd backend
docker-compose up --build
```

### Render

El proyecto estÃ¡ configurado para desplegarse en Render usando un Blueprint.

1. **Conectar repositorio** en Render
2. **Seleccionar Blueprint** desde `render.yaml`
3. **Configurar variables de entorno**:
   - Backend: `FRONTEND_URL` (URL del frontend)
   - Frontend: `VITE_API_URL` (URL del backend)
4. **Desplegar**

Ver `docs/DEPLOYMENT.md` para mÃ¡s detalles.

---

## ðŸ“ Estructura del Proyecto

```
projectX_NLP_B-rbara_S-nchez/
â”œâ”€â”€ backend/                    # Backend (API + Modelos)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/                # MÃ³dulo de predicciÃ³n
â”‚   â”‚   â”‚   â””â”€â”€ predict.py      # HateSpeechPredictor
â”‚   â”‚   â”œâ”€â”€ data/               # Preprocesamiento
â”‚   â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ features/           # Feature engineering
â”‚   â”‚   â”‚   â””â”€â”€ vectorization.py
â”‚   â”‚   â”œâ”€â”€ models/             # Modelos ML
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â”‚   â”œâ”€â”€ optimization.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ensemble.py
â”‚   â”‚   â”‚   â””â”€â”€ transformers.py
â”‚   â”‚   â””â”€â”€ utils/              # Utilidades
â”‚   â”‚       â”œâ”€â”€ database.py     # SQLite
â”‚   â”‚       â”œâ”€â”€ mlflow_tracking.py
â”‚   â”‚       â””â”€â”€ youtube.py      # ExtracciÃ³n YouTube
â”‚   â”œâ”€â”€ models/                 # Modelos entrenados
â”‚   â”‚   â”œâ”€â”€ optimized/
â”‚   â”‚   â”‚   â””â”€â”€ best_optimized_model.pkl
â”‚   â”‚   â””â”€â”€ tfidf_vectorizer.pkl
â”‚   â”œâ”€â”€ data/                   # Datos
â”‚   â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ processed/
â”‚   â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”‚   â”‚   â”œâ”€â”€ 01_EDA.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_Modeling_Baseline.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_Hyperparameter_Tuning.ipynb
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ tests/                  # Tests unitarios
â”‚   â”œâ”€â”€ main.py                 # API FastAPI
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ render.yaml
â”‚
â”œâ”€â”€ frontend/                    # Frontend React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # Componentes React
â”‚   â”‚   â”‚   â”œâ”€â”€ Hero.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AnalysisForm.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Results.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ModelInfo.jsx
â”‚   â”‚   â”‚   â””â”€â”€ ModelComparison.jsx
â”‚   â”‚   â”œâ”€â”€ pages/              # PÃ¡ginas
â”‚   â”‚   â”‚   â”œâ”€â”€ HomePage.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ BatchPage.jsx
â”‚   â”‚   â”‚   â””â”€â”€ YouTubePage.jsx
â”‚   â”‚   â”œâ”€â”€ services/           # Cliente API
â”‚   â”‚   â”‚   â””â”€â”€ api.js
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ docs/                        # DocumentaciÃ³n
â”‚   â”œâ”€â”€ DOCKER.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â”œâ”€â”€ DATABASE_GUIDE.md
â”‚   â””â”€â”€ MLFLOW_GUIDE.md
â”‚
â”œâ”€â”€ render.yaml                  # Render Blueprint
â”œâ”€â”€ README.md                    # Este archivo
â””â”€â”€ PROJECT_SUMMARY.md           # Resumen del proyecto
```

---

## ðŸ› ï¸ TecnologÃ­as

### Backend
- **Python 3.11**
- **FastAPI**: Framework web moderno
- **scikit-learn**: Modelos ML clÃ¡sicos
- **Optuna**: OptimizaciÃ³n de hiperparÃ¡metros
- **Transformers**: Hugging Face (DistilBERT)
- **SQLAlchemy**: ORM para base de datos
- **MLFlow**: Tracking de experimentos
- **spaCy**: Preprocesamiento NLP
- **youtube-comment-downloader**: ExtracciÃ³n de comentarios

### Frontend
- **React 18**: Framework UI
- **Vite**: Build tool
- **Tailwind CSS**: Estilos
- **Recharts**: Visualizaciones
- **Framer Motion**: Animaciones
- **Axios**: Cliente HTTP

### DevOps
- **Docker**: ContainerizaciÃ³n
- **Docker Compose**: OrquestaciÃ³n
- **Render**: Plataforma de despliegue
- **Git/GitHub**: Control de versiones

---

## ðŸ§ª Testing

### Ejecutar Tests

```bash
cd backend
pytest tests/
```

### Con cobertura

```bash
pytest tests/ --cov=src --cov-report=html
```

### Tests disponibles

- `test_preprocessing.py` - Preprocesamiento
- `test_vectorization.py` - VectorizaciÃ³n
- `test_train.py` - Entrenamiento
- `test_evaluate.py` - EvaluaciÃ³n
- `test_api.py` - API endpoints

---

## ðŸ“Š Dataset

- **Fuente**: YouTube Comments Dataset
- **TamaÃ±o**: 1,000 comentarios en inglÃ©s
- **DistribuciÃ³n**:
  - No tÃ³xicos: 538 (53.8%)
  - TÃ³xicos: 462 (46.2%)
- **UbicaciÃ³n**: `backend/data/raw/youtoxic_english_1000.csv`

---

## ðŸŽ¯ Niveles Completados

### ðŸŸ¢ Nivel Esencial
- âœ… Modelo ML funcional (F1=0.7407, Overfitting=2.54%)
- âœ… Control de overfitting < 5%
- âœ… API REST productiva
- âœ… Repositorio Git organizado
- âœ… DocumentaciÃ³n completa

### ðŸŸ¡ Nivel Medio
- âœ… Ensemble de modelos
- âœ… IntegraciÃ³n YouTube
- âœ… Tests unitarios
- âœ… OptimizaciÃ³n con Optuna

### ðŸŸ  Nivel Avanzado
- âœ… Redes neuronales (DistilBERT)
- âœ… AnÃ¡lisis tiempo real
- âœ… Despliegue pÃºblico (Render)
- âœ… DockerizaciÃ³n completa

### ðŸ”´ Nivel Experto
- âœ… Transformers (DistilBERT)
- âœ… Base de datos (SQLite)
- âœ… MLFlow tracking

---

## ðŸ¤ ContribuciÃ³n

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feat/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'feat: Add some AmazingFeature'`)
4. Push a la rama (`git push origin feat/AmazingFeature`)
5. Abre un Pull Request

### Convenciones

- **Commits**: Usar prefijos (feat, fix, docs, style, refactor, test, chore)
- **Ramas**: `feat/*`, `fix/*`, `docs/*`
- **CÃ³digo**: Seguir PEP 8 (Python) y ESLint (JavaScript)

---

## ðŸ“ Licencia

Este proyecto es parte de un bootcamp de IA.

---

## ðŸ‘¥ Autora

**BÃ¡rbara SÃ¡nchez**

- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- Proyecto: [Bootcamp-IA-P5/projectX_NLP_Barbara_Sanchez](https://github.com/Bootcamp-IA-P5/projectX_NLP_Barbara_Sanchez)

---

## ðŸ“š DocumentaciÃ³n Adicional

- [GuÃ­a de Docker](docs/DOCKER.md)
- [GuÃ­a de Despliegue](docs/DEPLOYMENT.md)
- [GuÃ­a de Base de Datos](docs/DATABASE_GUIDE.md)
- [GuÃ­a de MLFlow](docs/MLFLOW_GUIDE.md)



---

## ðŸ™ Agradecimientos

- Bootcamp de IA por el proyecto
- Comunidad de cÃ³digo abierto por las librerÃ­as utilizadas
- YouTube por proporcionar la plataforma de anÃ¡lisis

---

## ðŸ“ž Soporte

Si tienes preguntas o problemas:

1. Revisa la [documentaciÃ³n](docs/)
2. Abre un [issue](https://github.com/Bootcamp-IA-P5/projectX_NLP_Barbara_Sanchez/issues)
3. Consulta los [notebooks](backend/notebooks/) para ejemplos

---

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella en GitHub**
