# ğŸ¯ Proyecto: DetecciÃ³n de Hate Speech en YouTube

Sistema de detecciÃ³n automÃ¡tica de mensajes de odio en comentarios de YouTube utilizando tÃ©cnicas de Procesamiento del Lenguaje Natural (NLP) y Machine Learning.

## ğŸ“‹ DescripciÃ³n del Proyecto

YouTube necesita una soluciÃ³n automatizada para detectar y moderar comentarios de odio en su plataforma. Este proyecto implementa un sistema completo de clasificaciÃ³n de texto que identifica mensajes tÃ³xicos y de odio en comentarios de YouTube.

## ğŸ¯ Objetivos

### ğŸŸ¢ Nivel Esencial (Obligatorio)
- âœ… Modelo ML que reconozca mensajes de odio
- âœ… Overfitting < 5% (diferencia F1 train-test)
- âœ… ProductivizaciÃ³n (interfaz Streamlit)
- âœ… Repositorio Git organizado
- âœ… DocumentaciÃ³n completa

### ğŸŸ¡ Nivel Medio
- âœ… Ensemble de modelos
- âœ… IntegraciÃ³n con YouTube API
- âœ… Tests unitarios
- âœ… OptimizaciÃ³n de hiperparÃ¡metros (Optuna)

### ğŸŸ  Nivel Avanzado
- âœ… Redes neuronales (RNN/LSTM)
- âœ… Seguimiento en tiempo real
- âœ… Despliegue pÃºblico
- âœ… DockerizaciÃ³n

### ğŸ”´ Nivel Experto
- âœ… Transformers (DistilBERT)
- âœ… Base de datos para predicciones
- âœ… MLFlow para tracking

## ğŸ—ï¸ Estructura del Proyecto

```
projectX_NLP_B-rbara_S-nchez/
â”œâ”€â”€ backend/                 # Backend (API, modelos, notebooks)
â”‚   â”œâ”€â”€ src/                 # CÃ³digo fuente Python
â”‚   â”‚   â”œâ”€â”€ api/             # MÃ³dulo de predicciÃ³n
â”‚   â”‚   â”œâ”€â”€ data/            # Preprocesamiento
â”‚   â”‚   â”œâ”€â”€ features/        # Feature engineering
â”‚   â”‚   â”œâ”€â”€ models/          # Modelos ML
â”‚   â”‚   â””â”€â”€ utils/           # Utilidades (BD, MLFlow, YouTube)
â”‚   â”œâ”€â”€ api/                 # API REST (FastAPI)
â”‚   â”œâ”€â”€ data/                # Datos (raw y processed)
â”‚   â”œâ”€â”€ models/              # Modelos entrenados
â”‚   â”œâ”€â”€ notebooks/           # Jupyter notebooks
â”‚   â”œâ”€â”€ tests/               # Tests unitarios
â”‚   â”œâ”€â”€ scripts/             # Scripts de utilidad
â”‚   â””â”€â”€ requirements.txt      # Dependencias Python
â”œâ”€â”€ frontend/                # Frontend (a implementar)
â”œâ”€â”€ docs/                    # DocumentaciÃ³n general
â””â”€â”€ README.md                # Este archivo

```

## ğŸš€ InstalaciÃ³n

### Requisitos previos
- Python 3.11+
- Git

### Pasos de instalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <url-del-repositorio>
cd projectX_NLP_B-rbara_S-nchez
```

2. **Instalar backend**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Instalar frontend** (cuando estÃ© disponible)
```bash
cd frontend
npm install  # o yarn install
```

4. **Descargar modelos de spaCy**
```bash
python -m spacy download en_core_web_sm
```

5. **Descargar datos de NLTK**
```python
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
```

## ğŸ“Š Dataset

- **Fuente**: YouTube Comments Dataset
- **TamaÃ±o**: 1000 comentarios en inglÃ©s
- **Etiquetas**: TÃ³xico / No tÃ³xico
- **UbicaciÃ³n**: `data/raw/youtoxic_english_1000.csv`

## ğŸ”§ Uso

### Backend

#### Ejecutar la API
```bash
cd backend
bash api/run.sh
# O directamente:
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

#### Ejecutar tests
```bash
cd backend
pytest tests/
```

#### Ejecutar con Docker
```bash
cd backend
docker-compose up --build
```

Ver `docs/DOCKER.md` para mÃ¡s detalles sobre Docker.

### Frontend

El frontend estarÃ¡ disponible en `frontend/` una vez implementado.

## ğŸ“¡ API

La API REST estÃ¡ disponible en `http://localhost:8000` cuando el backend estÃ¡ ejecutÃ¡ndose.

- **DocumentaciÃ³n interactiva**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

Ver `backend/api/README.md` para documentaciÃ³n completa de la API.

## ğŸŒ¿ Estrategia de Ramas Git

- **`main`**: CÃ³digo estable y funcional
- **`develop`**: Rama de desarrollo principal
- **`feat/*`**: Ramas de features individuales

## ğŸ“ TecnologÃ­as Utilizadas

- **Python 3.11+**
- **NLP**: spaCy, NLTK
- **ML**: scikit-learn, Optuna
- **Transformers**: Hugging Face Transformers, PyTorch
- **API**: FastAPI, Uvicorn
- **ContainerizaciÃ³n**: Docker, Docker Compose
- **VisualizaciÃ³n**: Streamlit, Matplotlib, Seaborn
- **Testing**: pytest

## ğŸ‘¥ Autora

BÃ¡rbara SÃ¡nchez

## ğŸ“„ Licencia

Este proyecto es parte de un bootcamp de IA.

## ğŸ“š DocumentaciÃ³n Adicional

- Ver `PLAN_PROYECTO_COMPLETO.md` para el plan detallado del proyecto
- Ver `docs/` para documentaciÃ³n tÃ©cnica especÃ­fica
