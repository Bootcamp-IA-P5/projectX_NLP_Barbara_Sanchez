# ğŸ“‹ PLAN COMPLETO DEL PROYECTO - DetecciÃ³n de Hate Speech en YouTube
## Empezar desde cero con control total

---

## ğŸ” ANÃLISIS DE LA SITUACIÃ“N ACTUAL

### Lo que tienes:
- âœ… Dataset: `youtoxic_english_1000.csv` (1000 comentarios)
- âœ… Datos preprocesados guardados
- âœ… Modelos entrenados guardados
- âœ… Estructura `src/` creada (pero vacÃ­a)
- âœ… MÃºltiples notebooks de experimentaciÃ³n
- âœ… MÃºltiples ramas de Git (desorganizadas)

### Problemas identificados:
- âš ï¸ Ramas de Git desorganizadas (develop, feat/EDA, feat/models, etc.)
- âš ï¸ Notebooks dispersos sin organizaciÃ³n clara
- âš ï¸ CÃ³digo no modularizado (todo en notebooks)
- âš ï¸ Falta estructura clara del proyecto
- âš ï¸ No hay control de quÃ© estÃ¡ en cada rama

---

## ğŸ¯ OBJETIVOS DEL PROYECTO (SegÃºn el Briefing)

### ğŸŸ¢ Nivel Esencial (OBLIGATORIO):
1. âœ… Modelo ML que reconozca mensajes de odio
2. âœ… Overfitting < 5% (diferencia train-test)
3. âœ… ProductivizaciÃ³n (interfaz/API)
4. âœ… Repositorio Git organizado (ramas + commits limpios)
5. âœ… DocumentaciÃ³n (README + cÃ³digo documentado)

### ğŸŸ¡ Nivel Medio (RECOMENDADO):
6. âœ… Ensemble de modelos
7. âœ… IntegraciÃ³n con YouTube (URL de video)
8. âœ… Tests unitarios
9. âœ… OptimizaciÃ³n de hiperparÃ¡metros (Optuna)

### ğŸŸ  Nivel Avanzado (BONUS):
10. âœ… Redes neuronales (RNN/LSTM)
11. âœ… Seguimiento en tiempo real
12. âœ… Despliegue pÃºblico
13. âœ… DockerizaciÃ³n

### ğŸ”´ Nivel Experto (BONUS EXTRA):
14. âœ… Transformers (BERT/DistilBERT)
15. âœ… Base de datos para predicciones
16. âœ… MLFlow para tracking

---

## ğŸ“ ESTRUCTURA DEL PROYECTO (Propuesta)

```
projectX_NLP_B-rbara_S-nchez/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales (NO tocar)
â”‚   â”‚   â””â”€â”€ youtoxic_english_1000.csv
â”‚   â”œâ”€â”€ processed/              # Datos preprocesados
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ test/
â”‚   â””â”€â”€ README.md               # DescripciÃ³n del dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb            # AnÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ 02_Preprocessing.ipynb  # Preprocesamiento
â”‚   â”œâ”€â”€ 03_Feature_Engineering.ipynb  # VectorizaciÃ³n
â”‚   â”œâ”€â”€ 04_Modeling_Baseline.ipynb     # Modelos baseline
â”‚   â”œâ”€â”€ 05_Hyperparameter_Tuning.ipynb # OptimizaciÃ³n
â”‚   â”œâ”€â”€ 06_Anti_Overfitting.ipynb      # ReducciÃ³n overfitting
â”‚   â””â”€â”€ 07_Transformers.ipynb          # DistilBERT (nivel experto)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ load_data.py        # Cargar datos
â”‚   â”‚   â””â”€â”€ preprocessing.py    # Funciones de preprocesamiento
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ vectorization.py    # TF-IDF, Count Vectorizer
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py            # Entrenar modelos
â”‚   â”‚   â”œâ”€â”€ predict.py          # Hacer predicciones
â”‚   â”‚   â””â”€â”€ evaluate.py         # Evaluar modelos
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py          # Funciones auxiliares
â”‚
â”œâ”€â”€ models/                      # Modelos guardados
â”‚   â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ optimized/
â”‚   â””â”€â”€ transformers/
â”‚
â”œâ”€â”€ app/                         # AplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ tests/                       # Tests unitarios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_vectorization.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ docs/                        # DocumentaciÃ³n
â”‚   â”œâ”€â”€ EDA_RESULTS.md
â”‚   â”œâ”€â”€ PREPROCESSING.md
â”‚   â”œâ”€â”€ MODELING_RESULTS.md
â”‚   â””â”€â”€ API_DOCUMENTATION.md
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ PLAN_PROYECTO_COMPLETO.md    # Este archivo
```

---

## ğŸŒ¿ ESTRATEGIA DE RAMAS GIT

### Ramas principales:
- **`main`**: CÃ³digo estable y funcional (solo merges de develop)
- **`develop`**: Rama de desarrollo principal (integraciÃ³n de features)

### Ramas de features (una por tarea):
- **`feat/01-eda`**: AnÃ¡lisis exploratorio
- **`feat/02-preprocessing`**: Preprocesamiento
- **`feat/03-features`**: Feature engineering
- **`feat/04-modeling-baseline`**: Modelos baseline
- **`feat/05-hyperparameter-tuning`**: OptimizaciÃ³n
- **`feat/06-anti-overfitting`**: ReducciÃ³n overfitting
- **`feat/07-transformers`**: DistilBERT (nivel experto)
- **`feat/08-modularization`**: Modularizar cÃ³digo
- **`feat/09-streamlit-app`**: Interfaz Streamlit
- **`feat/10-youtube-integration`**: IntegraciÃ³n YouTube API
- **`feat/11-tests`**: Tests unitarios
- **`feat/12-docker`**: DockerizaciÃ³n (nivel avanzado)

### Flujo de trabajo:
1. Crear rama desde `develop`
2. Trabajar en la feature
3. Commit frecuente y descriptivo
4. Merge a `develop` cuando estÃ© lista
5. Merge `develop` â†’ `main` cuando estÃ© estable

---

## ğŸ“… PLAN PASO A PASO (8 dÃ­as)

### **DÃA 1: LIMPIEZA Y ORGANIZACIÃ“N**

#### Objetivo: Empezar con proyecto limpio y organizado

**Tareas:**

1. **Limpieza de Git** (30 min)
   - Decidir quÃ© mantener y quÃ© eliminar
   - Crear rama `develop` limpia desde `main`
   - Eliminar ramas obsoletas o fusionarlas

2. **Estructura del proyecto** (1h)
   - Crear estructura de carpetas completa
   - Crear archivos `__init__.py` necesarios
   - Crear `.gitignore` apropiado
   - Crear `requirements.txt` inicial

3. **DocumentaciÃ³n inicial** (30 min)
   - Actualizar `README.md` con estructura del proyecto
   - Crear `PLAN_PROYECTO_COMPLETO.md` (este archivo)
   - Documentar decisiones de diseÃ±o

4. **RevisiÃ³n del dataset** (30 min)
   - Verificar que el dataset estÃ¡ completo
   - Entender la estructura de los datos
   - Documentar en `data/README.md`

**Entregable**: Proyecto limpio y organizado, README actualizado

---

### **DÃA 2: EDA (AnÃ¡lisis Exploratorio de Datos)**

#### Objetivo: Entender completamente el dataset

**Rama**: `feat/01-eda`

**Tareas:**

1. **Cargar y explorar datos** (1h)
   - Cargar `youtoxic_english_1000.csv`
   - EstadÃ­sticas bÃ¡sicas (filas, columnas, nulos)
   - DistribuciÃ³n de clases (tÃ³xico vs no tÃ³xico)
   - AnÃ¡lisis de balance de clases

2. **AnÃ¡lisis de texto** (2h)
   - Longitud promedio de comentarios
   - Palabras mÃ¡s frecuentes
   - AnÃ¡lisis de tipos de toxicidad (IsAbusive, IsHatespeech, etc.)
   - Visualizaciones (distribuciones, word clouds)

3. **Insights y documentaciÃ³n** (1h)
   - Documentar hallazgos en `docs/EDA_RESULTS.md`
   - Identificar problemas potenciales
   - Decidir estrategia de preprocesamiento

**Entregable**: Notebook `01_EDA.ipynb` completo + `docs/EDA_RESULTS.md`

---

### **DÃA 3: PREPROCESAMIENTO**

#### Objetivo: Limpiar y normalizar el texto

**Rama**: `feat/02-preprocessing`

**Tareas:**

1. **Implementar pipeline de preprocesamiento** (2h)
   - Limpieza bÃ¡sica (URLs, emails, caracteres especiales)
   - NormalizaciÃ³n (contracciones, repeticiones)
   - TokenizaciÃ³n (NLTK o spaCy)
   - EliminaciÃ³n de stopwords
   - LematizaciÃ³n (spaCy preferido sobre stemming)

2. **Aplicar preprocesamiento** (1h)
   - Aplicar pipeline a todo el dataset
   - Guardar datos preprocesados
   - Verificar calidad del preprocesamiento

3. **Modularizar cÃ³digo** (1h)
   - Crear `src/data/preprocessing.py`
   - Funciones reutilizables
   - Tests bÃ¡sicos

**Entregable**: 
- Notebook `02_Preprocessing.ipynb`
- `src/data/preprocessing.py` modularizado
- Datos preprocesados guardados

---

### **DÃA 4: FEATURE ENGINEERING**

#### Objetivo: Convertir texto en vectores numÃ©ricos

**Rama**: `feat/03-features`

**Tareas:**

1. **Implementar vectorizaciÃ³n** (2h)
   - TF-IDF Vectorizer
   - Count Vectorizer (Bag of Words)
   - Probar diferentes configuraciones (ngram_range, max_features)
   - Comparar resultados

2. **DivisiÃ³n train/test** (30 min)
   - Estratificado (mantener proporciÃ³n de clases)
   - Guardar splits

3. **Modularizar cÃ³digo** (1h)
   - Crear `src/features/vectorization.py`
   - Funciones reutilizables

**Entregable**:
- Notebook `03_Feature_Engineering.ipynb`
- `src/features/vectorization.py`
- Matrices vectorizadas guardadas

---

### **DÃA 5: MODELADO BASELINE**

#### Objetivo: Entrenar modelos clÃ¡sicos y seleccionar baseline

**Rama**: `feat/04-modeling-baseline`

**Tareas:**

1. **Entrenar modelos clÃ¡sicos** (2h)
   - Naive Bayes
   - Logistic Regression
   - SVM
   - Random Forest
   - Comparar TF-IDF vs Count Vectorizer

2. **EvaluaciÃ³n y selecciÃ³n** (1h)
   - Calcular mÃ©tricas (F1, Accuracy, Precision, Recall)
   - Analizar overfitting (diferencia train-test)
   - Seleccionar mejor modelo baseline
   - Documentar resultados

3. **Modularizar cÃ³digo** (1h)
   - Crear `src/models/train.py`
   - Crear `src/models/evaluate.py`

**Entregable**:
- Notebook `04_Modeling_Baseline.ipynb`
- `src/models/train.py` y `evaluate.py`
- Modelo baseline guardado
- `docs/MODELING_RESULTS.md`

---

### **DÃA 6: OPTIMIZACIÃ“N Y ANTI-OVERFITTING**

#### Objetivo: Reducir overfitting a <5% y optimizar hiperparÃ¡metros

**Rama**: `feat/06-anti-overfitting`

**Tareas:**

1. **OptimizaciÃ³n de hiperparÃ¡metros** (2h)
   - Usar Optuna para optimizar modelo seleccionado
   - FunciÃ³n objetivo que priorice overfitting <5%
   - Probar diferentes configuraciones

2. **TÃ©cnicas anti-overfitting** (2h)
   - RegularizaciÃ³n mÃ¡s fuerte
   - Reducir complejidad del vectorizador
   - Probar modelos alternativos (Naive Bayes, Random Forest, XGBoost)
   - Si no funciona: probar Transformers (DistilBERT)

3. **ValidaciÃ³n cruzada** (30 min)
   - 5-fold cross-validation
   - Confirmar que el modelo generaliza

**Entregable**:
- Notebook `06_Anti_Overfitting.ipynb`
- Modelo optimizado guardado
- Overfitting <5% (objetivo cumplido)

---

### **DÃA 7: MODULARIZACIÃ“N Y PRODUCTIVIZACIÃ“N**

#### Objetivo: CÃ³digo modular y aplicaciÃ³n funcional

**Rama**: `feat/08-modularization` y `feat/09-streamlit-app`

**Tareas:**

1. **ModularizaciÃ³n completa** (2h)
   - Revisar y completar mÃ³dulos en `src/`
   - Asegurar que todo es reutilizable
   - Tests bÃ¡sicos

2. **AplicaciÃ³n Streamlit** (3h)
   - Crear `app/app.py`
   - Interfaz simple: input de texto â†’ predicciÃ³n
   - Mostrar probabilidad y resultado
   - DiseÃ±o limpio y funcional

3. **IntegraciÃ³n YouTube (Nivel Medio)** (1h)
   - FunciÃ³n para extraer comentarios de URL
   - Integrar en Streamlit
   - Mostrar resultados en tabla

**Entregable**:
- CÃ³digo completamente modularizado
- App Streamlit funcional
- IntegraciÃ³n YouTube (si nivel medio)

---

### **DÃA 8: PULIDO FINAL Y DOCUMENTACIÃ“N**

#### Objetivo: Proyecto completo y listo para entrega

**Rama**: `feat/12-documentation`

**Tareas:**

1. **Tests unitarios** (2h)
   - Tests para preprocesamiento
   - Tests para vectorizaciÃ³n
   - Tests para modelos
   - Configurar pytest

2. **DocumentaciÃ³n completa** (2h)
   - README.md completo
   - DocumentaciÃ³n de funciones (docstrings)
   - GuÃ­a de instalaciÃ³n y uso
   - DocumentaciÃ³n de la API

3. **Git final** (1h)
   - Revisar todos los commits
   - Asegurar que todo estÃ¡ en las ramas correctas
   - Merge final a `main`
   - Tags de versiÃ³n

4. **PreparaciÃ³n presentaciÃ³n** (1h)
   - Slides tÃ©cnicos
   - Preparar demo
   - Tablero Kanban actualizado

**Entregable**: Proyecto completo, documentado y listo para entrega

---

## ğŸ¯ DECISIONES TÃ‰CNICAS IMPORTANTES

### Preprocesamiento:
- **LibrerÃ­a**: spaCy (mÃ¡s rÃ¡pido y preciso que NLTK)
- **LematizaciÃ³n**: SÃ­ (mejor que stemming)
- **Stopwords**: SÃ­ (eliminar palabras comunes)
- **NormalizaciÃ³n**: SÃ­ (contracciones, repeticiones)

### VectorizaciÃ³n:
- **Principal**: TF-IDF (mejor que Count Vectorizer)
- **N-grams**: (1, 2) - unigramas y bigramas
- **Max features**: 500-1000 (balance entre informaciÃ³n y overfitting)

### Modelos:
- **Baseline**: Probar Naive Bayes, Logistic Regression, SVM
- **OptimizaciÃ³n**: Optuna
- **Si no funciona**: DistilBERT (Transformers)

### Overfitting:
- **Objetivo**: <5% diferencia F1 train-test
- **Estrategias**:
  1. RegularizaciÃ³n mÃ¡s fuerte
  2. Reducir complejidad (menos features)
  3. Modelos mÃ¡s simples
  4. Si no funciona: Transformers

---

## ğŸ“ CHECKLIST DE ENTREGA

### ğŸŸ¢ Nivel Esencial:
- [ ] Modelo ML entrenado y guardado
- [ ] Overfitting <5% (diferencia F1 train-test)
- [ ] App Streamlit funcional
- [ ] Repositorio Git organizado (ramas + commits)
- [ ] README completo
- [ ] CÃ³digo documentado

### ğŸŸ¡ Nivel Medio:
- [ ] Ensemble de modelos
- [ ] IntegraciÃ³n YouTube API
- [ ] Tests unitarios
- [ ] OptimizaciÃ³n con Optuna

### ğŸŸ  Nivel Avanzado:
- [ ] RNN/LSTM implementado
- [ ] DockerizaciÃ³n
- [ ] Despliegue pÃºblico

### ğŸ”´ Nivel Experto:
- [ ] DistilBERT implementado
- [ ] Base de datos para predicciones
- [ ] MLFlow tracking

---

## ğŸš€ PRÃ“XIMOS PASOS INMEDIATOS

1. **Decidir quÃ© mantener del proyecto actual**
   - Â¿Mantener datos preprocesados? â†’ SÃ­, ahorra tiempo
   - Â¿Mantener modelos entrenados? â†’ Solo como referencia
   - Â¿Mantener notebooks? â†’ Reorganizarlos

2. **Crear estructura limpia**
   - Crear todas las carpetas
   - Crear archivos base
   - Configurar Git correctamente

3. **Empezar con DÃA 1**
   - Limpieza y organizaciÃ³n
   - Estructura del proyecto
   - README inicial

---

## â“ PREGUNTAS PARA DECIDIR ANTES DE EMPEZAR

1. **Â¿QuÃ© nivel quieres alcanzar?**
   - MÃ­nimo: Nivel Esencial (obligatorio)
   - Recomendado: Nivel Esencial + Nivel Medio
   - Ambicioso: Todos los niveles

2. **Â¿QuÃ© mantener del proyecto actual?**
   - Datos preprocesados: âœ… SÃ­ (ahorra tiempo)
   - Modelos entrenados: âš ï¸ Solo como referencia
   - Notebooks: âš ï¸ Reorganizarlos

3. **Â¿Estrategia de ramas?**
   - Propuesta: `main` (estable) + `develop` (desarrollo) + `feat/*` (features)
   - Â¿Te parece bien?

---

**Â¿EstÃ¡s listo para empezar? Cuando me digas, comenzamos con el DÃA 1: Limpieza y OrganizaciÃ³n.**

