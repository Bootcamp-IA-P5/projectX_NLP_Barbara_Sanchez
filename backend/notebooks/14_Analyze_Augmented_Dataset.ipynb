{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä An√°lisis del Dataset Aumentado\n",
        "\n",
        "Este notebook analiza la calidad y caracter√≠sticas del dataset aumentado para determinar si es √∫til para mejorar el modelo.\n",
        "\n",
        "## Objetivos:\n",
        "1. Analizar balance de clases\n",
        "2. Verificar calidad del texto aumentado\n",
        "3. Comparar estad√≠sticas original vs aumentado\n",
        "4. Identificar problemas potenciales\n",
        "5. Recomendar acciones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importar librer√≠as y cargar datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Cargar datasets\n",
        "df_original = pd.read_csv('../data/raw/youtoxic_english_1000.csv')\n",
        "df_augmented = pd.read_csv('../data/processed/youtoxic_english_1000_augmented.csv')\n",
        "\n",
        "print(\"‚úÖ Datasets cargados:\")\n",
        "print(f\"   Original: {len(df_original)} ejemplos\")\n",
        "print(f\"   Aumentado: {len(df_augmented)} ejemplos\")\n",
        "print(f\"   Incremento: {len(df_augmented) - len(df_original)} ejemplos ({((len(df_augmented) - len(df_original))/len(df_original)*100):.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. An√°lisis de Balance de Clases y Calidad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä AN√ÅLISIS COMPLETO DEL DATASET AUMENTADO:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Balance de clases\n",
        "orig_toxic = df_original['IsToxic'].sum()\n",
        "orig_not_toxic = len(df_original) - orig_toxic\n",
        "orig_toxic_pct = (orig_toxic / len(df_original)) * 100\n",
        "\n",
        "aug_toxic = df_augmented['IsToxic'].sum()\n",
        "aug_not_toxic = len(df_augmented) - aug_toxic\n",
        "aug_toxic_pct = (aug_toxic / len(df_augmented)) * 100\n",
        "\n",
        "aug_only = df_augmented[df_augmented['_augmented'] == True] if '_augmented' in df_augmented.columns else pd.DataFrame()\n",
        "\n",
        "print(f\"\\nüìà Balance de Clases:\")\n",
        "print(f\"   Original: {orig_toxic} t√≥xicos ({orig_toxic_pct:.1f}%), {orig_not_toxic} no t√≥xicos ({100-orig_toxic_pct:.1f}%)\")\n",
        "print(f\"   Aumentado: {aug_toxic} t√≥xicos ({aug_toxic_pct:.1f}%), {aug_not_toxic} no t√≥xicos ({100-aug_toxic_pct:.1f}%)\")\n",
        "\n",
        "if len(aug_only) > 0:\n",
        "    aug_only_toxic = aug_only['IsToxic'].sum()\n",
        "    aug_only_pct = (aug_only_toxic / len(aug_only)) * 100\n",
        "    print(f\"   Solo aumentados: {aug_only_toxic} t√≥xicos ({aug_only_pct:.1f}%) de {len(aug_only)} ejemplos\")\n",
        "\n",
        "balance_change = abs(aug_toxic_pct - orig_toxic_pct)\n",
        "print(f\"\\n   Cambio en balance: {balance_change:.1f}%\")\n",
        "if balance_change < 2:\n",
        "    print(\"   ‚úÖ Balance se mantiene correctamente\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  Balance cambi√≥ significativamente\")\n",
        "\n",
        "# Calidad del texto\n",
        "print(f\"\\nüìè Calidad del Texto:\")\n",
        "orig_lengths = df_original['Text'].str.len()\n",
        "aug_lengths = df_augmented['Text'].str.len()\n",
        "print(f\"   Longitud promedio - Original: {orig_lengths.mean():.1f}, Aumentado: {aug_lengths.mean():.1f}\")\n",
        "\n",
        "if len(aug_only) > 0:\n",
        "    aug_only_lengths = aug_only['Text'].str.len()\n",
        "    print(f\"   Longitud promedio - Solo aumentados: {aug_only_lengths.mean():.1f}\")\n",
        "\n",
        "# Duplicados\n",
        "duplicates = df_augmented.duplicated(subset=['Text'], keep=False)\n",
        "print(f\"\\nüîç Duplicados: {duplicates.sum()} textos duplicados ({duplicates.sum()/len(df_augmented)*100:.1f}%)\")\n",
        "if duplicates.sum() < len(df_augmented) * 0.05:\n",
        "    print(\"   ‚úÖ Pocos duplicados, dataset limpio\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  Muchos duplicados, considerar limpiar\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Verificar Resultados del Modelo Aumentado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar si el modelo aumentado se guard√≥ (significa que mejor√≥)\n",
        "import pickle\n",
        "model_path = Path('../models/augmented/svm_augmented_model_info.pkl')\n",
        "\n",
        "if model_path.exists():\n",
        "    with open(model_path, 'rb') as f:\n",
        "        model_info = pickle.load(f)\n",
        "    \n",
        "    print(\"‚úÖ MODELO AUMENTADO ENCONTRADO (Mejor√≥ el rendimiento):\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"   F1-Score (Test): {model_info.get('test_f1', 'N/A'):.4f}\")\n",
        "    print(f\"   Accuracy: {model_info.get('test_accuracy', 'N/A'):.4f}\")\n",
        "    print(f\"   Overfitting: {model_info.get('overfitting', 'N/A'):.2f}%\")\n",
        "    print(f\"   Dataset size: {model_info.get('dataset_size', 'N/A')}\")\n",
        "    print(f\"   M√©todo: {model_info.get('augmentation_method', 'N/A')}\")\n",
        "    \n",
        "    print(\"\\nüí° RECOMENDACI√ìN: Usar modelo aumentado en producci√≥n\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è  Modelo aumentado no se guard√≥ (no mejor√≥ significativamente)\")\n",
        "    print(\"   El modelo original sigue siendo el mejor\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Decisi√≥n Final y Pr√≥ximos Pasos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìå DECISI√ìN Y PR√ìXIMOS PASOS:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if model_path.exists():\n",
        "    print(\"\\n‚úÖ EL DATASET AUMENTADO MEJOR√ì EL MODELO\")\n",
        "    print(\"\\nüìã Acciones recomendadas:\")\n",
        "    print(\"   1. ‚úÖ Dataset aumentado es de buena calidad\")\n",
        "    print(\"   2. ‚úÖ Modelo aumentado tiene mejor rendimiento\")\n",
        "    print(\"   3. üîÑ OPCIONAL: Actualizar API para usar modelo aumentado\")\n",
        "    print(\"      - Cambiar ruta del modelo en backend/src/api/predict.py\")\n",
        "    print(\"      - De: models/optimized/best_optimized_model.pkl\")\n",
        "    print(\"      - A: models/augmented/svm_augmented_model.pkl\")\n",
        "    print(\"   4. üìù Documentar en README que se usa dataset aumentado\")\n",
        "    print(\"\\n‚ö†Ô∏è  NOTA: Si actualizas el modelo en producci√≥n, verifica que:\")\n",
        "    print(\"   - El overfitting sigue siendo bajo (<5%)\")\n",
        "    print(\"   - Las m√©tricas mejoraron significativamente\")\n",
        "    print(\"   - El modelo funciona correctamente en la API\")\n",
        "else:\n",
        "    print(\"\\n‚ûñ EL DATASET AUMENTADO NO MEJOR√ì SIGNIFICATIVAMENTE\")\n",
        "    print(\"\\nüìã Acciones recomendadas:\")\n",
        "    print(\"   1. ‚úÖ Mantener modelo original (mejor rendimiento)\")\n",
        "    print(\"   2. ‚ÑπÔ∏è  Dataset aumentado puede usarse para an√°lisis adicionales\")\n",
        "    print(\"   3. üîÑ OPCIONAL: Probar otras t√©cnicas de augmentation\")\n",
        "    print(\"      - Traducci√≥n y back-translation\")\n",
        "    print(\"      - Parafraseo\")\n",
        "    print(\"      - Aumentar solo clase minoritaria\")\n",
        "    print(\"\\nüí° CONCLUSI√ìN: El dataset original es suficiente para este proyecto\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
