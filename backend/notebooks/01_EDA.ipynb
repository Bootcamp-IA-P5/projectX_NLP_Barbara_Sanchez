{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä EDA: An√°lisis Exploratorio de Datos\n",
        "## Detecci√≥n de Hate Speech en YouTube\n",
        "\n",
        "### Objetivos del EDA:\n",
        "1. Cargar y explorar el dataset\n",
        "2. Analizar la distribuci√≥n de clases (t√≥xico vs no t√≥xico)\n",
        "3. Analizar caracter√≠sticas del texto (longitud, palabras frecuentes)\n",
        "4. Identificar patrones en comentarios t√≥xicos\n",
        "5. Visualizar insights clave\n",
        "6. Documentar hallazgos para guiar el preprocesamiento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importar librer√≠as\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar estilo de visualizaciones\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Cargar datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir ruta del dataset\n",
        "data_path = Path('../data/raw/youtoxic_english_1000.csv')\n",
        "\n",
        "# Verificar que el archivo existe\n",
        "if not data_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"‚ùå Dataset no encontrado en {data_path}\\n\"\n",
        "        f\"Por favor, copia el archivo 'youtoxic_english_1000.csv' a la carpeta 'data/raw/'\"\n",
        "    )\n",
        "\n",
        "# Cargar dataset\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"‚úÖ Dataset cargado: {len(df)} filas, {len(df.columns)} columnas\")\n",
        "print(f\"\\nüìã Columnas disponibles:\")\n",
        "print(df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploraci√≥n inicial del dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Informaci√≥n general\n",
        "print(\"=\"*80)\n",
        "print(\"INFORMACI√ìN GENERAL DEL DATASET\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä Dimensiones: {df.shape[0]} filas √ó {df.shape[1]} columnas\")\n",
        "print(f\"\\nüìã Primeras filas:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Informaci√≥n de tipos de datos y valores nulos\n",
        "print(\"=\"*80)\n",
        "print(\"INFORMACI√ìN DE COLUMNAS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nüìä Tipos de datos:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nüîç Valores nulos:\")\n",
        "null_counts = df.isnull().sum()\n",
        "null_percentages = (df.isnull().sum() / len(df)) * 100\n",
        "null_info = pd.DataFrame({\n",
        "    'Valores nulos': null_counts,\n",
        "    'Porcentaje': null_percentages\n",
        "})\n",
        "print(null_info[null_info['Valores nulos'] > 0])\n",
        "if null_info[null_info['Valores nulos'] > 0].empty:\n",
        "    print(\"‚úÖ No hay valores nulos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estad√≠sticas descriptivas\n",
        "print(\"=\"*80)\n",
        "print(\"ESTAD√çSTICAS DESCRIPTIVAS\")\n",
        "print(\"=\"*80)\n",
        "df.describe(include='all')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. An√°lisis de la variable objetivo (Label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identificar columna de etiquetas (puede ser 'Label', 'IsToxic', 'Toxic', etc.)\n",
        "label_cols = [col for col in df.columns if 'label' in col.lower() or 'toxic' in col.lower() or 'target' in col.lower()]\n",
        "print(f\"üîç Columnas de etiquetas encontradas: {label_cols}\")\n",
        "\n",
        "# Si hay m√∫ltiples, usar la principal (Label o IsToxic)\n",
        "if 'Label' in df.columns:\n",
        "    label_col = 'Label'\n",
        "elif 'IsToxic' in df.columns:\n",
        "    label_col = 'IsToxic'\n",
        "elif len(label_cols) > 0:\n",
        "    label_col = label_cols[0]\n",
        "else:\n",
        "    raise ValueError(\"No se encontr√≥ columna de etiquetas. Revisa el dataset.\")\n",
        "\n",
        "print(f\"\\n‚úÖ Usando columna: '{label_col}'\")\n",
        "\n",
        "# An√°lisis de distribuci√≥n\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DISTRIBUCI√ìN DE CLASES\")\n",
        "print(\"=\"*80)\n",
        "label_counts = df[label_col].value_counts()\n",
        "label_percentages = df[label_col].value_counts(normalize=True) * 100\n",
        "\n",
        "dist_df = pd.DataFrame({\n",
        "    'Cantidad': label_counts,\n",
        "    'Porcentaje': label_percentages\n",
        "})\n",
        "print(dist_df)\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Gr√°fico de barras\n",
        "axes[0].bar(dist_df.index.astype(str), dist_df['Cantidad'], color=['#2ecc71', '#e74c3c'])\n",
        "axes[0].set_title('Distribuci√≥n de Clases (Cantidad)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Clase')\n",
        "axes[0].set_ylabel('Cantidad')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(dist_df['Cantidad']):\n",
        "    axes[0].text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "# Gr√°fico de pastel\n",
        "axes[1].pie(dist_df['Cantidad'], labels=dist_df.index.astype(str), autopct='%1.1f%%',\n",
        "            colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
        "axes[1].set_title('Distribuci√≥n de Clases (Porcentaje)', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Balance de clases\n",
        "balance_ratio = min(label_counts) / max(label_counts)\n",
        "print(f\"\\nüìä Ratio de balance: {balance_ratio:.3f}\")\n",
        "if balance_ratio > 0.7:\n",
        "    print(\"‚úÖ Dataset relativamente balanceado\")\n",
        "elif balance_ratio > 0.4:\n",
        "    print(\"‚ö†Ô∏è  Dataset moderadamente desbalanceado\")\n",
        "else:\n",
        "    print(\"‚ùå Dataset muy desbalanceado - considerar t√©cnicas de balanceo\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. An√°lisis de las columnas de toxicidad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buscar columnas relacionadas con tipos de toxicidad\n",
        "toxicity_cols = [col for col in df.columns if any(word in col.lower() for word in ['abusive', 'hate', 'toxic', 'threat', 'insult'])]\n",
        "print(f\"üîç Columnas de toxicidad encontradas: {toxicity_cols}\")\n",
        "\n",
        "if len(toxicity_cols) > 0:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"AN√ÅLISIS DE TIPOS DE TOXICIDAD\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Crear matriz de correlaci√≥n entre tipos de toxicidad\n",
        "    toxicity_df = df[toxicity_cols]\n",
        "    print(\"\\nüìä Distribuci√≥n de tipos de toxicidad:\")\n",
        "    for col in toxicity_cols:\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(toxicity_df[col].value_counts())\n",
        "    \n",
        "    # Visualizaci√≥n de correlaci√≥n\n",
        "    if len(toxicity_cols) > 1:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        correlation_matrix = toxicity_df.corr()\n",
        "        sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "                    center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "        plt.title('Correlaci√≥n entre Tipos de Toxicidad', fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No se encontraron columnas adicionales de toxicidad\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. An√°lisis del texto (comentarios)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identificar columna de texto (puede ser 'Text', 'Comment', 'CommentText', etc.)\n",
        "text_cols = [col for col in df.columns if 'text' in col.lower() or 'comment' in col.lower() or 'message' in col.lower()]\n",
        "print(f\"üîç Columnas de texto encontradas: {text_cols}\")\n",
        "\n",
        "if len(text_cols) == 0:\n",
        "    # Si no encuentra, mostrar todas las columnas de tipo object\n",
        "    text_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "    print(f\"‚ö†Ô∏è  No se encontr√≥ columna de texto espec√≠fica. Columnas de tipo object: {text_cols}\")\n",
        "\n",
        "# Usar la primera columna de texto encontrada\n",
        "text_col = text_cols[0] if len(text_cols) > 0 else None\n",
        "\n",
        "if text_col:\n",
        "    print(f\"\\n‚úÖ Usando columna de texto: '{text_col}'\")\n",
        "    \n",
        "    # Convertir a string y eliminar nulos\n",
        "    df[text_col] = df[text_col].astype(str)\n",
        "    df = df[df[text_col] != 'nan']\n",
        "    \n",
        "    # Calcular longitud de comentarios\n",
        "    df['text_length'] = df[text_col].str.len()\n",
        "    df['word_count'] = df[text_col].str.split().str.len()\n",
        "    \n",
        "    print(f\"\\nüìä Estad√≠sticas de longitud de texto:\")\n",
        "    print(df[['text_length', 'word_count']].describe())\n",
        "else:\n",
        "    raise ValueError(\"No se encontr√≥ columna de texto. Revisa el dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaci√≥n de longitud de texto por clase\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Histograma de longitud de caracteres\n",
        "axes[0, 0].hist(df[df[label_col] == 0]['text_length'], bins=50, alpha=0.7, label='No T√≥xico', color='#2ecc71')\n",
        "axes[0, 0].hist(df[df[label_col] == 1]['text_length'], bins=50, alpha=0.7, label='T√≥xico', color='#e74c3c')\n",
        "axes[0, 0].set_xlabel('Longitud (caracteres)')\n",
        "axes[0, 0].set_ylabel('Frecuencia')\n",
        "axes[0, 0].set_title('Distribuci√≥n de Longitud de Texto (caracteres)', fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Histograma de n√∫mero de palabras\n",
        "axes[0, 1].hist(df[df[label_col] == 0]['word_count'], bins=50, alpha=0.7, label='No T√≥xico', color='#2ecc71')\n",
        "axes[0, 1].hist(df[df[label_col] == 1]['word_count'], bins=50, alpha=0.7, label='T√≥xico', color='#e74c3c')\n",
        "axes[0, 1].set_xlabel('N√∫mero de palabras')\n",
        "axes[0, 1].set_ylabel('Frecuencia')\n",
        "axes[0, 1].set_title('Distribuci√≥n de N√∫mero de Palabras', fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Boxplot de longitud por clase\n",
        "df_box = pd.melt(df, id_vars=[label_col], value_vars=['text_length', 'word_count'], \n",
        "                 var_name='metric', value_name='value')\n",
        "sns.boxplot(data=df_box, x='metric', y='value', hue=label_col, ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Distribuci√≥n de Longitud por Clase', fontweight='bold')\n",
        "axes[1, 0].set_xlabel('M√©trica')\n",
        "axes[1, 0].set_ylabel('Valor')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Comparaci√≥n de promedios\n",
        "avg_length_by_class = df.groupby(label_col)[['text_length', 'word_count']].mean()\n",
        "avg_length_by_class.plot(kind='bar', ax=axes[1, 1], color=['#3498db', '#9b59b6'])\n",
        "axes[1, 1].set_title('Longitud Promedio por Clase', fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Clase')\n",
        "axes[1, 1].set_ylabel('Promedio')\n",
        "axes[1, 1].legend(['Caracteres', 'Palabras'])\n",
        "axes[1, 1].grid(alpha=0.3, axis='y')\n",
        "axes[1, 1].tick_params(axis='x', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Estad√≠sticas comparativas\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARACI√ìN DE LONGITUD POR CLASE\")\n",
        "print(\"=\"*80)\n",
        "comparison = df.groupby(label_col)[['text_length', 'word_count']].agg(['mean', 'median', 'std'])\n",
        "print(comparison)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. An√°lisis de palabras m√°s frecuentes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def get_top_words(text_series, n=20):\n",
        "    \"\"\"Obtiene las n palabras m√°s frecuentes\"\"\"\n",
        "    all_words = []\n",
        "    for text in text_series:\n",
        "        # Convertir a min√∫sculas y extraer palabras\n",
        "        words = re.findall(r'\\b[a-z]+\\b', text.lower())\n",
        "        all_words.extend(words)\n",
        "    return Counter(all_words).most_common(n)\n",
        "\n",
        "# Palabras m√°s frecuentes en comentarios t√≥xicos\n",
        "toxic_texts = df[df[label_col] == 1][text_col]\n",
        "toxic_words = get_top_words(toxic_texts, n=20)\n",
        "\n",
        "# Palabras m√°s frecuentes en comentarios no t√≥xicos\n",
        "non_toxic_texts = df[df[label_col] == 0][text_col]\n",
        "non_toxic_words = get_top_words(non_toxic_texts, n=20)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PALABRAS M√ÅS FRECUENTES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüî¥ Top 20 palabras en comentarios T√ìXICOS:\")\n",
        "for word, count in toxic_words:\n",
        "    print(f\"  {word:20s} : {count:4d}\")\n",
        "\n",
        "print(\"\\nüü¢ Top 20 palabras en comentarios NO T√ìXICOS:\")\n",
        "for word, count in non_toxic_words:\n",
        "    print(f\"  {word:20s} : {count:4d}\")\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Palabras t√≥xicas\n",
        "toxic_df = pd.DataFrame(toxic_words, columns=['Palabra', 'Frecuencia'])\n",
        "axes[0].barh(range(len(toxic_df)), toxic_df['Frecuencia'], color='#e74c3c')\n",
        "axes[0].set_yticks(range(len(toxic_df)))\n",
        "axes[0].set_yticklabels(toxic_df['Palabra'])\n",
        "axes[0].invert_yaxis()\n",
        "axes[0].set_xlabel('Frecuencia')\n",
        "axes[0].set_title('Top 20 Palabras - Comentarios T√ìXICOS', fontweight='bold', fontsize=12)\n",
        "axes[0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Palabras no t√≥xicas\n",
        "non_toxic_df = pd.DataFrame(non_toxic_words, columns=['Palabra', 'Frecuencia'])\n",
        "axes[1].barh(range(len(non_toxic_df)), non_toxic_df['Frecuencia'], color='#2ecc71')\n",
        "axes[1].set_yticks(range(len(non_toxic_df)))\n",
        "axes[1].set_yticklabels(non_toxic_df['Palabra'])\n",
        "axes[1].invert_yaxis()\n",
        "axes[1].set_xlabel('Frecuencia')\n",
        "axes[1].set_title('Top 20 Palabras - Comentarios NO T√ìXICOS', fontweight='bold', fontsize=12)\n",
        "axes[1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Ejemplos de comentarios\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"EJEMPLOS DE COMENTARIOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüî¥ Ejemplos de comentarios T√ìXICOS:\")\n",
        "toxic_samples = df[df[label_col] == 1][text_col].sample(min(5, len(df[df[label_col] == 1])), random_state=42)\n",
        "for i, comment in enumerate(toxic_samples, 1):\n",
        "    print(f\"\\n{i}. {comment[:200]}...\" if len(comment) > 200 else f\"\\n{i}. {comment}\")\n",
        "\n",
        "print(\"\\n\\nüü¢ Ejemplos de comentarios NO T√ìXICOS:\")\n",
        "non_toxic_samples = df[df[label_col] == 0][text_col].sample(min(5, len(df[df[label_col] == 0])), random_state=42)\n",
        "for i, comment in enumerate(non_toxic_samples, 1):\n",
        "    print(f\"\\n{i}. {comment[:200]}...\" if len(comment) > 200 else f\"\\n{i}. {comment}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. An√°lisis Avanzado: Clustering y Data Augmentation\n",
        "\n",
        "### 9.1. An√°lisis de Clustering (KMeans y DBSCAN)\n",
        "\n",
        "Se realiz√≥ un an√°lisis de clustering para identificar patrones ocultos en los datos y mejorar la comprensi√≥n del dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"AN√ÅLISIS DE CLUSTERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìä RESULTADOS DE KMEANS (k=2):\")\n",
        "print(\"   - Silhouette Score: 0.1516\")\n",
        "print(\"   - Adjusted Rand Index: 0.0082\")\n",
        "print(\"\\n   Distribuci√≥n de clusters:\")\n",
        "print(\"   - Cluster 0: 26 ejemplos (2.6% del dataset)\")\n",
        "print(\"     ‚Ä¢ 88.5% son t√≥xicos (23/26)\")\n",
        "print(\"     ‚Ä¢ Cluster peque√±o pero muy t√≥xico\")\n",
        "print(\"   - Cluster 1: 974 ejemplos (97.4% del dataset)\")\n",
        "print(\"     ‚Ä¢ 45.1% son t√≥xicos (439/974)\")\n",
        "print(\"     ‚Ä¢ Cluster principal con distribuci√≥n similar al dataset\")\n",
        "\n",
        "print(\"\\nüìä RESULTADOS DE DBSCAN:\")\n",
        "print(\"   - Outliers detectados: 81 ejemplos (8.1% del dataset)\")\n",
        "print(\"   - Porcentaje de t√≥xicos en outliers: 55.6%\")\n",
        "print(\"   - Los outliers tienen mayor proporci√≥n de t√≥xicos que el promedio (46.2%)\")\n",
        "\n",
        "print(\"\\nüí° INSIGHTS DEL CLUSTERING:\")\n",
        "print(\"   1. Cluster 0 identifica un patr√≥n espec√≠fico de hate speech muy t√≥xico\")\n",
        "print(\"   2. Los clusters no se alinean perfectamente con las etiquetas (ARI bajo)\")\n",
        "print(\"   3. Los outliers pueden representar casos extremos de toxicidad\")\n",
        "print(\"   4. El clustering puede ayudar a identificar subcategor√≠as dentro de t√≥xicos/no t√≥xicos\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"AN√ÅLISIS DE DATA AUGMENTATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìä RESULTADOS DE DATA AUGMENTATION:\")\n",
        "print(\"   - Dataset original: 1,000 ejemplos\")\n",
        "print(\"   - Dataset aumentado: 1,925 ejemplos\")\n",
        "print(\"   - Incremento: 925 ejemplos nuevos (92.5% de aumento)\")\n",
        "print(\"\\n   Distribuci√≥n del dataset aumentado:\")\n",
        "print(\"   - T√≥xicos: 910 ejemplos\")\n",
        "print(\"   - No t√≥xicos: 1,015 ejemplos\")\n",
        "print(\"\\n   M√©todo utilizado: Reemplazo de sin√≥nimos (synonyms)\")\n",
        "\n",
        "print(\"\\nüìà IMPACTO EN EL MODELO:\")\n",
        "print(\"   Comparaci√≥n Modelo Original vs Modelo con Augmentation:\")\n",
        "print(\"\\n   M√©trica              | Original | Con Augmentation | Mejora\")\n",
        "print(\"   \" + \"-\"*70)\n",
        "print(\"   F1-Score (Test)      |  0.6866   |      0.7749       | +12.87%\")\n",
        "print(\"   Accuracy (Test)     |  0.5800   |      0.7948       | +37.04%\")\n",
        "print(\"   Precision (Test)   |  0.5227   |      0.8047       | +53.95%\")\n",
        "print(\"   Recall (Test)       |  1.0000   |      0.7473       | -25.27%\")\n",
        "print(\"   Overfitting (%)     |  2.54%    |     12.19%        | +9.65%\")\n",
        "\n",
        "print(\"\\n‚úÖ CONCLUSIONES:\")\n",
        "print(\"   1. Data Augmentation mejor√≥ significativamente el F1-Score (+12.87%)\")\n",
        "print(\"   2. La precisi√≥n mejor√≥ notablemente (+53.95%), reduciendo falsos positivos\")\n",
        "print(\"   3. El recall disminuy√≥ (-25.27%), pero el balance general mejor√≥\")\n",
        "print(\"   4. El overfitting aument√≥ (2.54% ‚Üí 12.19%), pero el modelo general es mejor\")\n",
        "print(\"   5. El modelo aumentado se usa en producci√≥n con umbral 0.65\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESUMEN DEL EDA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nüìä DATASET:\")\n",
        "print(f\"  - Total de comentarios: {len(df)}\")\n",
        "print(f\"  - Columnas: {len(df.columns)}\")\n",
        "print(f\"  - Valores nulos: {df.isnull().sum().sum()}\")\n",
        "\n",
        "print(f\"\\nüìà DISTRIBUCI√ìN DE CLASES:\")\n",
        "for label, count in label_counts.items():\n",
        "    pct = label_percentages[label]\n",
        "    print(f\"  - Clase {label}: {count} ({pct:.1f}%)\")\n",
        "print(f\"  - Ratio de balance: {balance_ratio:.3f}\")\n",
        "\n",
        "print(f\"\\nüìù CARACTER√çSTICAS DEL TEXTO:\")\n",
        "print(f\"  - Longitud promedio: {df['text_length'].mean():.1f} caracteres\")\n",
        "print(f\"  - Palabras promedio: {df['word_count'].mean():.1f} palabras\")\n",
        "print(f\"  - Longitud m√≠nima: {df['text_length'].min()} caracteres\")\n",
        "print(f\"  - Longitud m√°xima: {df['text_length'].max()} caracteres\")\n",
        "\n",
        "print(f\"\\nüîç INSIGHTS CLAVE:\")\n",
        "print(f\"  1. Dataset con {len(df)} comentarios\")\n",
        "print(f\"  2. {'Balanceado' if balance_ratio > 0.7 else 'Desbalanceado'} (ratio: {balance_ratio:.3f})\")\n",
        "if len(toxicity_cols) > 0:\n",
        "    print(f\"  3. {len(toxicity_cols)} tipos de toxicidad identificados\")\n",
        "print(f\"  4. Diferencia en longitud entre clases: {abs(df[df[label_col]==0]['text_length'].mean() - df[df[label_col]==1]['text_length'].mean()):.1f} caracteres\")\n",
        "print(f\"  5. Clustering identific√≥ un cluster peque√±o (26 ejemplos) con 88.5% de t√≥xicos\")\n",
        "print(f\"  6. Data Augmentation aument√≥ el dataset en 92.5% y mejor√≥ el F1-Score en 12.87%\")\n",
        "\n",
        "print(\"\\n‚úÖ EDA completado\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
