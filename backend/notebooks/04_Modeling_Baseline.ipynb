{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Modelado Baseline: Modelos Cl√°sicos de ML\n",
    "## Entrenamiento y evaluaci√≥n de modelos de clasificaci√≥n\n",
    "\n",
    "### Objetivos:\n",
    "1. Entrenar modelos cl√°sicos (Naive Bayes, Logistic Regression, SVM, Random Forest)\n",
    "2. Comparar TF-IDF vs Count Vectorizer\n",
    "3. Evaluar m√©tricas (F1, Accuracy, Precision, Recall)\n",
    "4. Analizar overfitting\n",
    "5. Seleccionar mejor modelo baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar librer√≠as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# A√±adir src al path\n",
    "sys.path.append(str(Path('../src').resolve()))\n",
    "\n",
    "from models.train import train_model, save_model\n",
    "from models.evaluate import evaluate_model, compare_models, print_classification_report\n",
    "from features.vectorization import load_vectorized_data\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar datos vectorizados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos vectorizados cargados desde: ../data/processed\n",
      "‚úÖ Datos vectorizados cargados desde: ../data/processed\n",
      "\n",
      "‚úÖ Datos cargados:\n",
      "   TF-IDF - Train: (800, 1000), Test: (200, 1000)\n",
      "   Count  - Train: (800, 1000), Test: (200, 1000)\n",
      "   Labels - Train: 800, Test: 200\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos vectorizados con TF-IDF\n",
    "data_dir = Path('../data/processed')\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = load_vectorized_data(data_dir, prefix='tfidf')\n",
    "\n",
    "# Cargar datos vectorizados con Count Vectorizer\n",
    "X_train_count, X_test_count, _, _ = load_vectorized_data(data_dir, prefix='count')\n",
    "\n",
    "print(f\"\\n‚úÖ Datos cargados:\")\n",
    "print(f\"   TF-IDF - Train: {X_train_tfidf.shape}, Test: {X_test_tfidf.shape}\")\n",
    "print(f\"   Count  - Train: {X_train_count.shape}, Test: {X_test_count.shape}\")\n",
    "print(f\"   Labels - Train: {len(y_train)}, Test: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenar modelos con TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTRENANDO MODELOS CON TF-IDF\n",
      "================================================================================\n",
      "\n",
      "üîµ Entrenando Naive Bayes...\n",
      "================================================================================\n",
      "RESULTADOS DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "   Accuracy:  0.8825\n",
      "   Precision: 0.8966\n",
      "   Recall:    0.8432\n",
      "   F1-score:  0.8691\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "   Accuracy:  0.6900\n",
      "   Precision: 0.6974\n",
      "   Recall:    0.5761\n",
      "   F1-score:  0.6310\n",
      "\n",
      "‚ö†Ô∏è  OVERFITTING:\n",
      "   Diferencia F1 (train-test): 23.81%\n",
      "   ‚ùå Overfitting alto (>10%)\n",
      "\n",
      "üìã Matriz de confusi√≥n (test):\n",
      "[[85 23]\n",
      " [39 53]]\n",
      "\n",
      "üü¢ Entrenando Logistic Regression...\n",
      "================================================================================\n",
      "RESULTADOS DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "   Accuracy:  0.8975\n",
      "   Precision: 0.8978\n",
      "   Recall:    0.8784\n",
      "   F1-score:  0.8880\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "   Accuracy:  0.7550\n",
      "   Precision: 0.7590\n",
      "   Recall:    0.6848\n",
      "   F1-score:  0.7200\n",
      "\n",
      "‚ö†Ô∏è  OVERFITTING:\n",
      "   Diferencia F1 (train-test): 16.80%\n",
      "   ‚ùå Overfitting alto (>10%)\n",
      "\n",
      "üìã Matriz de confusi√≥n (test):\n",
      "[[88 20]\n",
      " [29 63]]\n",
      "\n",
      "üü° Entrenando SVM...\n",
      "================================================================================\n",
      "RESULTADOS DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "   Accuracy:  0.9175\n",
      "   Precision: 0.9064\n",
      "   Recall:    0.9162\n",
      "   F1-score:  0.9113\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "   Accuracy:  0.7550\n",
      "   Precision: 0.7471\n",
      "   Recall:    0.7065\n",
      "   F1-score:  0.7263\n",
      "\n",
      "‚ö†Ô∏è  OVERFITTING:\n",
      "   Diferencia F1 (train-test): 18.50%\n",
      "   ‚ùå Overfitting alto (>10%)\n",
      "\n",
      "üìã Matriz de confusi√≥n (test):\n",
      "[[86 22]\n",
      " [27 65]]\n",
      "\n",
      "üî¥ Entrenando Random Forest...\n",
      "================================================================================\n",
      "RESULTADOS DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "   Accuracy:  0.8700\n",
      "   Precision: 0.9750\n",
      "   Recall:    0.7378\n",
      "   F1-score:  0.8400\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "   Accuracy:  0.7150\n",
      "   Precision: 0.7869\n",
      "   Recall:    0.5217\n",
      "   F1-score:  0.6275\n",
      "\n",
      "‚ö†Ô∏è  OVERFITTING:\n",
      "   Diferencia F1 (train-test): 21.25%\n",
      "   ‚ùå Overfitting alto (>10%)\n",
      "\n",
      "üìã Matriz de confusi√≥n (test):\n",
      "[[95 13]\n",
      " [44 48]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ENTRENANDO MODELOS CON TF-IDF\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models_tfidf = {}\n",
    "results_tfidf = {}\n",
    "\n",
    "# 1. Naive Bayes\n",
    "print(\"\\nüîµ Entrenando Naive Bayes...\")\n",
    "models_tfidf['Naive Bayes'] = train_model('naive_bayes', X_train_tfidf, y_train, alpha=1.0)\n",
    "results_tfidf['Naive Bayes'] = evaluate_model(\n",
    "    models_tfidf['Naive Bayes'], X_train_tfidf, X_test_tfidf, y_train, y_test\n",
    ")\n",
    "\n",
    "# 2. Logistic Regression\n",
    "print(\"\\nüü¢ Entrenando Logistic Regression...\")\n",
    "models_tfidf['Logistic Regression'] = train_model(\n",
    "    'logistic', X_train_tfidf, y_train, C=1.0, penalty='l2', class_weight='balanced'\n",
    ")\n",
    "results_tfidf['Logistic Regression'] = evaluate_model(\n",
    "    models_tfidf['Logistic Regression'], X_train_tfidf, X_test_tfidf, y_train, y_test\n",
    ")\n",
    "\n",
    "# 3. SVM\n",
    "print(\"\\nüü° Entrenando SVM...\")\n",
    "models_tfidf['SVM'] = train_model(\n",
    "    'svm', X_train_tfidf, y_train, C=1.0, kernel='linear', class_weight='balanced'\n",
    ")\n",
    "results_tfidf['SVM'] = evaluate_model(\n",
    "    models_tfidf['SVM'], X_train_tfidf, X_test_tfidf, y_train, y_test\n",
    ")\n",
    "\n",
    "# 4. Random Forest\n",
    "print(\"\\nüî¥ Entrenando Random Forest...\")\n",
    "models_tfidf['Random Forest'] = train_model(\n",
    "    'random_forest', X_train_tfidf, y_train, \n",
    "    n_estimators=100, max_depth=10, class_weight='balanced'\n",
    ")\n",
    "results_tfidf['Random Forest'] = evaluate_model(\n",
    "    models_tfidf['Random Forest'], X_train_tfidf, X_test_tfidf, y_train, y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenar modelos con Count Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTRENANDO MODELOS CON COUNT VECTORIZER\n",
      "================================================================================\n",
      "\n",
      "üîµ Entrenando Naive Bayes...\n",
      "================================================================================\n",
      "RESULTADOS DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "   Accuracy:  0.8425\n",
      "   Precision: 0.8128\n",
      "   Recall:    0.8568\n",
      "   F1-score:  0.8342\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "   Accuracy:  0.6850\n",
      "   Precision: 0.6629\n",
      "   Recall:    0.6413\n",
      "   F1-score:  0.6519\n",
      "\n",
      "‚ö†Ô∏è  OVERFITTING:\n",
      "   Diferencia F1 (train-test): 18.23%\n",
      "   ‚ùå Overfitting alto (>10%)\n",
      "\n",
      "üìã Matriz de confusi√≥n (test):\n",
      "[[78 30]\n",
      " [33 59]]\n",
      "\n",
      "üü¢ Entrenando Logistic Regression...\n",
      "================================================================================\n",
      "RESULTADOS DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "   Accuracy:  0.9587\n",
      "   Precision: 0.9694\n",
      "   Recall:    0.9405\n",
      "   F1-score:  0.9547\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "   Accuracy:  0.7400\n",
      "   Precision: 0.7564\n",
      "   Recall:    0.6413\n",
      "   F1-score:  0.6941\n",
      "\n",
      "‚ö†Ô∏è  OVERFITTING:\n",
      "   Diferencia F1 (train-test): 26.06%\n",
      "   ‚ùå Overfitting alto (>10%)\n",
      "\n",
      "üìã Matriz de confusi√≥n (test):\n",
      "[[89 19]\n",
      " [33 59]]\n",
      "\n",
      "üü° Entrenando SVM...\n",
      "================================================================================\n",
      "RESULTADOS DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "   Accuracy:  0.9750\n",
      "   Precision: 0.9861\n",
      "   Recall:    0.9595\n",
      "   F1-score:  0.9726\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "   Accuracy:  0.7100\n",
      "   Precision: 0.7125\n",
      "   Recall:    0.6196\n",
      "   F1-score:  0.6628\n",
      "\n",
      "‚ö†Ô∏è  OVERFITTING:\n",
      "   Diferencia F1 (train-test): 30.98%\n",
      "   ‚ùå Overfitting alto (>10%)\n",
      "\n",
      "üìã Matriz de confusi√≥n (test):\n",
      "[[85 23]\n",
      " [35 57]]\n",
      "\n",
      "üî¥ Entrenando Random Forest...\n",
      "================================================================================\n",
      "RESULTADOS DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "   Accuracy:  0.8488\n",
      "   Precision: 0.9698\n",
      "   Recall:    0.6946\n",
      "   F1-score:  0.8094\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "   Accuracy:  0.7400\n",
      "   Precision: 0.8333\n",
      "   Recall:    0.5435\n",
      "   F1-score:  0.6579\n",
      "\n",
      "‚ö†Ô∏è  OVERFITTING:\n",
      "   Diferencia F1 (train-test): 15.16%\n",
      "   ‚ùå Overfitting alto (>10%)\n",
      "\n",
      "üìã Matriz de confusi√≥n (test):\n",
      "[[98 10]\n",
      " [42 50]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ENTRENANDO MODELOS CON COUNT VECTORIZER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models_count = {}\n",
    "results_count = {}\n",
    "\n",
    "# 1. Naive Bayes\n",
    "print(\"\\nüîµ Entrenando Naive Bayes...\")\n",
    "models_count['Naive Bayes'] = train_model('naive_bayes', X_train_count, y_train, alpha=1.0)\n",
    "results_count['Naive Bayes'] = evaluate_model(\n",
    "    models_count['Naive Bayes'], X_train_count, X_test_count, y_train, y_test\n",
    ")\n",
    "\n",
    "# 2. Logistic Regression\n",
    "print(\"\\nüü¢ Entrenando Logistic Regression...\")\n",
    "models_count['Logistic Regression'] = train_model(\n",
    "    'logistic', X_train_count, y_train, C=1.0, penalty='l2', class_weight='balanced'\n",
    ")\n",
    "results_count['Logistic Regression'] = evaluate_model(\n",
    "    models_count['Logistic Regression'], X_train_count, X_test_count, y_train, y_test\n",
    ")\n",
    "\n",
    "# 3. SVM\n",
    "print(\"\\nüü° Entrenando SVM...\")\n",
    "models_count['SVM'] = train_model(\n",
    "    'svm', X_train_count, y_train, C=1.0, kernel='linear', class_weight='balanced'\n",
    ")\n",
    "results_count['SVM'] = evaluate_model(\n",
    "    models_count['SVM'], X_train_count, X_test_count, y_train, y_test\n",
    ")\n",
    "\n",
    "# 4. Random Forest\n",
    "print(\"\\nüî¥ Entrenando Random Forest...\")\n",
    "models_count['Random Forest'] = train_model(\n",
    "    'random_forest', X_train_count, y_train, \n",
    "    n_estimators=100, max_depth=10, class_weight='balanced'\n",
    ")\n",
    "results_count['Random Forest'] = evaluate_model(\n",
    "    models_count['Random Forest'], X_train_count, X_test_count, y_train, y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARACI√ìN DE MODELOS - TF-IDF\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'test_f1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/lg/8fd06zcn26j2kwzxcggvm05c0000gn/T/ipykernel_43055/2273700360.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m print(\u001b[33m\"=\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m      2\u001b[39m print(\u001b[33m\"COMPARACI√ìN DE MODELOS - TF-IDF\"\u001b[39m)\n\u001b[32m      3\u001b[39m print(\u001b[33m\"=\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m comparison_tfidf = compare_models(results_tfidf)\n\u001b[32m      5\u001b[39m print(\u001b[33m\"\\n\"\u001b[39m + comparison_tfidf.to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m print(\u001b[33m\"\\n\"\u001b[39m + \u001b[33m\"=\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
      "\u001b[32m~/Desktop/bootcamp IA/projectX_NLP_B-rbara_S-nchez/src/models/evaluate.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(results_dict, metric)\u001b[39m\n\u001b[32m    136\u001b[39m             \u001b[33m'Recall (test)'\u001b[39m: results[\u001b[33m'test_recall'\u001b[39m]\n\u001b[32m    137\u001b[39m         })\n\u001b[32m    138\u001b[39m \n\u001b[32m    139\u001b[39m     df = pd.DataFrame(comparison_data)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     df = df.sort_values(by=metric, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7207\u001b[39m             )\n\u001b[32m   7208\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7209\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7210\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7211\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7212\u001b[39m \n\u001b[32m   7213\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7214\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'test_f1'"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARACI√ìN DE MODELOS - TF-IDF\")\n",
    "print(\"=\"*80)\n",
    "comparison_tfidf = compare_models(results_tfidf)\n",
    "print(\"\\n\" + comparison_tfidf.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACI√ìN DE MODELOS - COUNT VECTORIZER\")\n",
    "print(\"=\"*80)\n",
    "comparison_count = compare_models(results_count)\n",
    "print(\"\\n\" + comparison_count.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizaci√≥n de resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Comparaci√≥n F1-score\n",
    "comparison_all = pd.concat([\n",
    "    comparison_tfidf.assign(Vectorizer='TF-IDF'),\n",
    "    comparison_count.assign(Vectorizer='Count')\n",
    "])\n",
    "\n",
    "# F1-score por modelo\n",
    "pivot_f1 = comparison_all.pivot(index='Modelo', columns='Vectorizer', values='F1 (test)')\n",
    "pivot_f1.plot(kind='bar', ax=axes[0, 0], color=['#3498db', '#e74c3c'])\n",
    "axes[0, 0].set_title('F1-Score (Test) por Modelo y Vectorizador', fontweight='bold', fontsize=12)\n",
    "axes[0, 0].set_ylabel('F1-Score')\n",
    "axes[0, 0].set_xlabel('Modelo')\n",
    "axes[0, 0].legend(title='Vectorizador')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Overfitting por modelo\n",
    "pivot_overfitting = comparison_all.pivot(index='Modelo', columns='Vectorizer', values='Overfitting (%)')\n",
    "pivot_overfitting.plot(kind='bar', ax=axes[0, 1], color=['#3498db', '#e74c3c'])\n",
    "axes[0, 1].axhline(y=5, color='r', linestyle='--', label='Objetivo (<5%)')\n",
    "axes[0, 1].set_title('Overfitting por Modelo y Vectorizador', fontweight='bold', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Overfitting (%)')\n",
    "axes[0, 1].set_xlabel('Modelo')\n",
    "axes[0, 1].legend(title='Vectorizador')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Accuracy por modelo\n",
    "pivot_acc = comparison_all.pivot(index='Modelo', columns='Vectorizer', values='Accuracy (test)')\n",
    "pivot_acc.plot(kind='bar', ax=axes[1, 0], color=['#3498db', '#e74c3c'])\n",
    "axes[1, 0].set_title('Accuracy (Test) por Modelo y Vectorizador', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].set_xlabel('Modelo')\n",
    "axes[1, 0].legend(title='Vectorizador')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Scatter: F1 vs Overfitting\n",
    "axes[1, 1].scatter(\n",
    "    comparison_all[comparison_all['Vectorizer'] == 'TF-IDF']['Overfitting (%)'],\n",
    "    comparison_all[comparison_all['Vectorizer'] == 'TF-IDF']['F1 (test)'],\n",
    "    label='TF-IDF', s=100, alpha=0.7, color='#3498db'\n",
    ")\n",
    "axes[1, 1].scatter(\n",
    "    comparison_all[comparison_all['Vectorizer'] == 'Count']['Overfitting (%)'],\n",
    "    comparison_all[comparison_all['Vectorizer'] == 'Count']['F1 (test)'],\n",
    "    label='Count', s=100, alpha=0.7, color='#e74c3c', marker='s'\n",
    ")\n",
    "axes[1, 1].axvline(x=5, color='r', linestyle='--', alpha=0.5, label='Objetivo Overfitting')\n",
    "axes[1, 1].set_xlabel('Overfitting (%)')\n",
    "axes[1, 1].set_ylabel('F1-Score (Test)')\n",
    "axes[1, 1].set_title('F1-Score vs Overfitting', fontweight='bold', fontsize=12)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "# A√±adir etiquetas de modelos\n",
    "for idx, row in comparison_all.iterrows():\n",
    "    if row['Vectorizer'] == 'TF-IDF':\n",
    "        axes[1, 1].annotate(row['Modelo'], \n",
    "                           (row['Overfitting (%)'], row['F1 (test)']),\n",
    "                           fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los resultados\n",
    "all_results = {}\n",
    "for name, results in results_tfidf.items():\n",
    "    all_results[f\"{name} (TF-IDF)\"] = results\n",
    "for name, results in results_count.items():\n",
    "    all_results[f\"{name} (Count)\"] = results\n",
    "\n",
    "# Seleccionar mejor modelo (mayor F1 en test, priorizando overfitting < 5%)\n",
    "comparison_all = compare_models(all_results)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SELECCI√ìN DEL MEJOR MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filtrar modelos con overfitting < 5%\n",
    "good_models = comparison_all[comparison_all['Overfitting (%)'] < 5.0]\n",
    "\n",
    "if len(good_models) > 0:\n",
    "    best_model_name = good_models.iloc[0]['Modelo']\n",
    "    best_model_results = all_results[best_model_name]\n",
    "    print(f\"\\nüèÜ MEJOR MODELO (Overfitting < 5%): {best_model_name}\")\n",
    "    print(f\"   F1-score (test): {best_model_results['test_f1']:.4f}\")\n",
    "    print(f\"   Overfitting: {best_model_results['diff_f1']:.2f}%\")\n",
    "    print(f\"   Accuracy: {best_model_results['test_accuracy']:.4f}\")\n",
    "    \n",
    "    # Determinar qu√© modelo y vectorizador usar\n",
    "    if 'TF-IDF' in best_model_name:\n",
    "        best_model = models_tfidf[best_model_name.replace(' (TF-IDF)', '')]\n",
    "        vectorizer_type = 'tfidf'\n",
    "    else:\n",
    "        best_model = models_count[best_model_name.replace(' (Count)', '')]\n",
    "        vectorizer_type = 'count'\n",
    "else:\n",
    "    # Si ning√∫n modelo cumple, elegir el mejor F1\n",
    "    best_model_name = comparison_all.iloc[0]['Modelo']\n",
    "    best_model_results = all_results[best_model_name]\n",
    "    print(f\"\\n‚ö†Ô∏è  MEJOR MODELO (Overfitting > 5%): {best_model_name}\")\n",
    "    print(f\"   F1-score (test): {best_model_results['test_f1']:.4f}\")\n",
    "    print(f\"   Overfitting: {best_model_results['diff_f1']:.2f}%\")\n",
    "    print(f\"   ‚ö†Ô∏è  Necesita optimizaci√≥n para reducir overfitting\")\n",
    "    \n",
    "    if 'TF-IDF' in best_model_name:\n",
    "        best_model = models_tfidf[best_model_name.replace(' (TF-IDF)', '')]\n",
    "        vectorizer_type = 'tfidf'\n",
    "    else:\n",
    "        best_model = models_count[best_model_name.replace(' (Count)', '')]\n",
    "        vectorizer_type = 'count'\n",
    "\n",
    "print(f\"\\nüìä Top 3 modelos:\")\n",
    "print(comparison_all.head(3).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardar mejor modelo baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar mejor modelo\n",
    "models_dir = Path('../models/baseline')\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = models_dir / 'best_baseline_model.pkl'\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'vectorizer_type': vectorizer_type,\n",
    "    'test_f1': best_model_results['test_f1'],\n",
    "    'test_accuracy': best_model_results['test_accuracy'],\n",
    "    'overfitting': best_model_results['diff_f1'],\n",
    "    'train_f1': best_model_results['train_f1']\n",
    "}\n",
    "\n",
    "save_model(best_model, model_path, model_info)\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo baseline guardado:\")\n",
    "print(f\"   {model_path}\")\n",
    "print(f\"   Informaci√≥n: {models_dir / 'best_baseline_model_info.pkl'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen del modelado baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUMEN DEL MODELADO BASELINE\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Modelos entrenados:\n",
      "   1. Naive Bayes\n",
      "   2. Logistic Regression\n",
      "   3. SVM\n",
      "   4. Random Forest\n",
      "\n",
      "‚úÖ Vectorizadores probados:\n",
      "   1. TF-IDF\n",
      "   2. Count Vectorizer\n",
      "\n",
      "üèÜ Mejor modelo seleccionado:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   2. Count Vectorizer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müèÜ Mejor modelo seleccionado:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbest_model_name\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   F1-score (test): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_results[\u001b[33m'\u001b[39m\u001b[33mtest_f1\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Overfitting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_results[\u001b[33m'\u001b[39m\u001b[33mdiff_f1\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'best_model_name' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RESUMEN DEL MODELADO BASELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n‚úÖ Modelos entrenados:\")\n",
    "print(f\"   1. Naive Bayes\")\n",
    "print(f\"   2. Logistic Regression\")\n",
    "print(f\"   3. SVM\")\n",
    "print(f\"   4. Random Forest\")\n",
    "\n",
    "print(f\"\\n‚úÖ Vectorizadores probados:\")\n",
    "print(f\"   1. TF-IDF\")\n",
    "print(f\"   2. Count Vectorizer\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo seleccionado:\")\n",
    "print(f\"   {best_model_name}\")\n",
    "print(f\"   F1-score (test): {best_model_results['test_f1']:.4f}\")\n",
    "print(f\"   Overfitting: {best_model_results['diff_f1']:.2f}%\")\n",
    "\n",
    "print(f\"\\nüíæ Modelo guardado en:\")\n",
    "print(f\"   ../models/baseline/best_baseline_model.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Modelado baseline completado\")\n",
    "print(\"   Pr√≥ximo paso: Optimizaci√≥n de hiperpar√°metros y reducci√≥n de overfitting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
