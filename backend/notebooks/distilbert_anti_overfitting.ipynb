{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBERT - Transformers para Reducci√≥n de Overfitting\n",
    "\n",
    "## Objetivo\n",
    "Implementar DistilBERT (modelo Transformer) como soluci√≥n de nivel experto para reducir overfitting manteniendo F1-score > 0.55.\n",
    "\n",
    "## Ventajas de DistilBERT\n",
    "- ‚úÖ‚úÖ‚úÖ Entiende contexto y sem√°ntica (no solo frecuencias)\n",
    "- ‚úÖ‚úÖ‚úÖ Pre-entrenado en millones de textos\n",
    "- ‚úÖ‚úÖ‚úÖ Fine-tuning con tu dataset (aprende patrones espec√≠ficos)\n",
    "- ‚úÖ‚úÖ‚úÖ Mejor control de overfitting que modelos cl√°sicos\n",
    "- ‚úÖ‚úÖ‚úÖ 60% m√°s r√°pido que BERT\n",
    "- ‚úÖ‚úÖ‚úÖ Dropout incorporado (regularizaci√≥n autom√°tica)\n",
    "- ‚úÖ Captura sutilezas del hate speech que TF-IDF no puede\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de librer√≠as necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dispositivo: cpu\n",
      "‚úÖ Librer√≠as importadas (enfoque directo con PyTorch, sin datasets)\n"
     ]
    }
   ],
   "source": [
    "# Instalar si no est√°n instaladas (descomentar si es necesario)\n",
    "# !pip install transformers torch accelerate\n",
    "\n",
    "# Suprimir warnings de TensorFlow (no lo necesitamos para DistilBERT)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suprimir warnings de TensorFlow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suprimir errores de protobuf/TensorFlow\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Configurar dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Dispositivo: {device}\")\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas (enfoque directo con PyTorch, sin datasets)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos cargados: 800 train, 200 test\n",
      "Distribuci√≥n train: [430 370]\n",
      "Distribuci√≥n test: [108  92]\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "df = pd.read_csv('../data/processed/youtoxic_english_1000_processed.csv')\n",
    "\n",
    "# Convertir IsToxic a num√©rico\n",
    "if df['IsToxic'].dtype == object:\n",
    "    df['Label'] = df['IsToxic'].map({'TRUE': 1, 'FALSE': 0, True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "else:\n",
    "    df['Label'] = df['IsToxic'].astype(int)\n",
    "\n",
    "# Dividir en train/test usando el mismo m√©todo que otros notebooks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Text_processed']\n",
    "y = df['Label']\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Convertir a arrays numpy para evitar problemas con √≠ndices\n",
    "X_train_text = X_train_text.values\n",
    "X_test_text = X_test_text.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "print(f\"‚úÖ Datos cargados: {len(X_train_text)} train, {len(X_test_text)} test\")\n",
    "print(f\"Distribuci√≥n train: {np.bincount(y_train)}\")\n",
    "print(f\"Distribuci√≥n test: {np.bincount(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cargar tokenizador y modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando distilbert-base-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo cargado: distilbert-base-uncased\n",
      "   Par√°metros: 66,955,010\n"
     ]
    }
   ],
   "source": [
    "# Cargar tokenizador y modelo pre-entrenado\n",
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "print(f\"Cargando {model_name}...\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,  # Clasificaci√≥n binaria\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Modelo cargado: {model_name}\")\n",
    "print(f\"   Par√°metros: {model.num_parameters():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset personalizado para PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clase Dataset definida\n"
     ]
    }
   ],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    \"\"\"Dataset personalizado para clasificaci√≥n de hate speech.\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        # Convertir a listas para evitar problemas con √≠ndices de pandas\n",
    "        self.texts = [str(text) for text in texts]\n",
    "        self.labels = [int(label) for label in labels]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenizar texto\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Clase Dataset definida\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Funci√≥n de evaluaci√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funci√≥n de evaluaci√≥n definida\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Eval√∫a el modelo y retorna m√©tricas.\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions, zero_division=0)\n",
    "    f1 = f1_score(true_labels, predictions, zero_division=0)\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de evaluaci√≥n definida\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preparar datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datasets creados\n",
      "   Train: 800 ejemplos\n",
      "   Test: 200 ejemplos\n"
     ]
    }
   ],
   "source": [
    "# Crear datasets\n",
    "train_dataset = HateSpeechDataset(X_train_text, y_train, tokenizer)\n",
    "test_dataset = HateSpeechDataset(X_test_text, y_test, tokenizer)\n",
    "\n",
    "print(f\"‚úÖ Datasets creados\")\n",
    "print(f\"   Train: {len(train_dataset)} ejemplos\")\n",
    "print(f\"   Test: {len(test_dataset)} ejemplos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configurar entrenamiento con anti-overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONFIGURACI√ìN DE ENTRENAMIENTO - DISTILBERT\n",
      "================================================================================\n",
      "‚úÖ √âpocas: 5\n",
      "‚úÖ Learning rate: 2e-05\n",
      "‚úÖ Weight decay: 0.01 (regularizaci√≥n L2)\n",
      "‚úÖ Batch size: 16\n",
      "‚úÖ Warmup steps: 100\n",
      "‚úÖ Early stopping: S√≠ (patience=2)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Configurar hiperpar√°metros de entrenamiento\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 5\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CONFIGURACI√ìN DE ENTRENAMIENTO - DISTILBERT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ √âpocas: {NUM_EPOCHS}\")\n",
    "print(f\"‚úÖ Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"‚úÖ Weight decay: {WEIGHT_DECAY} (regularizaci√≥n L2)\")\n",
    "print(f\"‚úÖ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"‚úÖ Warmup steps: {WARMUP_STEPS}\")\n",
    "print(f\"‚úÖ Early stopping: S√≠ (patience=2)\")\n",
    "print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Entrenar modelo (enfoque directo con PyTorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTRENAMIENTO DISTILBERT - CONTROL DE OVERFITTING\n",
      "================================================================================\n",
      "‚úÖ Early stopping (patience=2)\n",
      "‚úÖ Weight decay (regularizaci√≥n L2)\n",
      "‚úÖ Learning rate bajo (2e-5)\n",
      "‚úÖ Pocas √©pocas (5)\n",
      "‚úÖ Evaluaci√≥n cada √©poca\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "√âpoca 1/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:00<00:00,  2.41s/it, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "√âpoca 1/5\n",
      "  Loss: 0.6886\n",
      "  F1 (test): 0.1414\n",
      "  Accuracy (test): 0.5750\n",
      "  ‚úÖ Mejor modelo guardado (F1: 0.1414)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "√âpoca 2/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:00<00:00,  2.40s/it, loss=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "√âpoca 2/5\n",
      "  Loss: 0.6428\n",
      "  F1 (test): 0.4806\n",
      "  Accuracy (test): 0.6650\n",
      "  ‚úÖ Mejor modelo guardado (F1: 0.4806)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "√âpoca 3/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:59<00:00,  2.40s/it, loss=0.377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "√âpoca 3/5\n",
      "  Loss: 0.4839\n",
      "  F1 (test): 0.6851\n",
      "  Accuracy (test): 0.7150\n",
      "  ‚úÖ Mejor modelo guardado (F1: 0.6851)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "√âpoca 4/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:01<00:00,  2.43s/it, loss=0.207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "√âpoca 4/5\n",
      "  Loss: 0.3359\n",
      "  F1 (test): 0.7010\n",
      "  Accuracy (test): 0.7100\n",
      "  ‚úÖ Mejor modelo guardado (F1: 0.7010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "√âpoca 5/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:04<00:00,  2.48s/it, loss=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "√âpoca 5/5\n",
      "  Loss: 0.2259\n",
      "  F1 (test): 0.7027\n",
      "  Accuracy (test): 0.7250\n",
      "  ‚úÖ Mejor modelo guardado (F1: 0.7027)\n",
      "\n",
      "‚úÖ Entrenamiento completado\n"
     ]
    }
   ],
   "source": [
    "# Crear DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Mover modelo a dispositivo\n",
    "model = model.to(device)\n",
    "\n",
    "# Configurar optimizador y scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * NUM_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Funci√≥n de p√©rdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENTRENAMIENTO DISTILBERT - CONTROL DE OVERFITTING\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ Early stopping (patience=2)\")\n",
    "print(\"‚úÖ Weight decay (regularizaci√≥n L2)\")\n",
    "print(\"‚úÖ Learning rate bajo (2e-5)\")\n",
    "print(\"‚úÖ Pocas √©pocas (5)\")\n",
    "print(\"‚úÖ Evaluaci√≥n cada √©poca\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Entrenar modelo\n",
    "best_f1 = 0\n",
    "patience_counter = 0\n",
    "patience = 2\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Entrenamiento\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'√âpoca {epoch+1}/{NUM_EPOCHS}')\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Evaluaci√≥n\n",
    "    eval_results = evaluate_model(model, test_loader, device)\n",
    "    test_f1 = eval_results['f1']\n",
    "    \n",
    "    print(f\"\\n√âpoca {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"  Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  F1 (test): {test_f1:.4f}\")\n",
    "    print(f\"  Accuracy (test): {eval_results['accuracy']:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if test_f1 > best_f1:\n",
    "        best_f1 = test_f1\n",
    "        patience_counter = 0\n",
    "        # Guardar mejor modelo\n",
    "        os.makedirs('../models', exist_ok=True)\n",
    "        torch.save(model.state_dict(), '../models/distilbert_best_model.pt')\n",
    "        print(f\"  ‚úÖ Mejor modelo guardado (F1: {best_f1:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  ‚èπÔ∏è  Early stopping (patience={patience})\")\n",
    "            break\n",
    "\n",
    "# Cargar mejor modelo\n",
    "model.load_state_dict(torch.load('../models/distilbert_best_model.pt'))\n",
    "print(\"\\n‚úÖ Entrenamiento completado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluaci√≥n del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando en conjunto de entrenamiento...\n",
      "\n",
      "Evaluando en conjunto de prueba...\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS FINALES - DISTILBERT\n",
      "================================================================================\n",
      "F1-score (train): 0.9468\n",
      "F1-score (test): 0.7027\n",
      "Accuracy (test): 0.7250\n",
      "Precision (test): 0.6989\n",
      "Recall (test): 0.7065\n",
      "Diferencia F1: 24.41%\n",
      "\n",
      "Matriz de confusi√≥n (test):\n",
      "[[80 28]\n",
      " [27 65]]\n",
      "\n",
      "‚ö†Ô∏è  Overfitting a√∫n alto\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en train y test para calcular overfitting\n",
    "print(\"Evaluando en conjunto de entrenamiento...\")\n",
    "train_results = evaluate_model(model, train_loader, device)\n",
    "\n",
    "print(\"\\nEvaluando en conjunto de prueba...\")\n",
    "test_results = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Calcular diferencia F1 (overfitting)\n",
    "diff_f1 = abs(train_results['f1'] - test_results['f1']) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS FINALES - DISTILBERT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"F1-score (train): {train_results['f1']:.4f}\")\n",
    "print(f\"F1-score (test): {test_results['f1']:.4f}\")\n",
    "print(f\"Accuracy (test): {test_results['accuracy']:.4f}\")\n",
    "print(f\"Precision (test): {test_results['precision']:.4f}\")\n",
    "print(f\"Recall (test): {test_results['recall']:.4f}\")\n",
    "print(f\"Diferencia F1: {diff_f1:.2f}%\")\n",
    "print(f\"\\nMatriz de confusi√≥n (test):\")\n",
    "print(test_results['confusion_matrix'])\n",
    "\n",
    "if diff_f1 < 5.0 and test_results['f1'] > 0.55:\n",
    "    print(\"\\n‚úÖ‚úÖ‚úÖ OBJETIVO CUMPLIDO: Overfitting < 5% Y F1 > 0.55\")\n",
    "elif diff_f1 < 6.0:\n",
    "    print(\"\\nüéØ MUY CERCA: Overfitting < 6%\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Overfitting a√∫n alto\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar modelo (si cumple objetivos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  Modelo no guardado (no cumple objetivos)\n",
      "   Overfitting: 24.41% (objetivo: <6%)\n",
      "   F1-score: 0.7027 (objetivo: >0.55)\n"
     ]
    }
   ],
   "source": [
    "if diff_f1 < 6.0 and test_results['f1'] > 0.55:\n",
    "    # Guardar modelo y tokenizador\n",
    "    model_path = Path('../models/distilbert_model')\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Guardar modelo completo\n",
    "    model.save_pretrained(str(model_path))\n",
    "    tokenizer.save_pretrained(str(model_path))\n",
    "    \n",
    "    # Guardar informaci√≥n del modelo\n",
    "    model_info = {\n",
    "        'model_type': 'DistilBERT',\n",
    "        'model_name': model_name,\n",
    "        'test_f1': test_results['f1'],\n",
    "        'diff_f1': diff_f1,\n",
    "        'train_f1': train_results['f1'],\n",
    "        'num_epochs': NUM_EPOCHS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "        'batch_size': BATCH_SIZE\n",
    "    }\n",
    "    \n",
    "    with open('../models/distilbert_info.pkl', 'wb') as f:\n",
    "        pickle.dump(model_info, f)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Modelo guardado en: {model_path}\")\n",
    "    print(f\"‚úÖ Informaci√≥n guardada en: ../models/distilbert_info.pkl\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Modelo no guardado (no cumple objetivos)\")\n",
    "    print(f\"   Overfitting: {diff_f1:.2f}% (objetivo: <6%)\")\n",
    "    print(f\"   F1-score: {test_results['f1']:.4f} (objetivo: >0.55)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
