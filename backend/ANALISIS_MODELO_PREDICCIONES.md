# üîç An√°lisis: Por qu√© el Modelo Predice Todo como T√≥xico

## üìä Estado Actual del Modelo

### M√©tricas del Modelo:
- **F1-score**: 0.6866
- **Accuracy**: 0.58 (muy bajo)
- **Precision**: 0.5227 (muy bajo)
- **Recall**: 1.0000 ‚ö†Ô∏è **PROBLEMA**: Predice todo como t√≥xico en el dataset de test

### Pruebas Directas:
```
Texto positivo (ingl√©s) ‚Üí is_toxic = False ‚úÖ
Texto negativo (ingl√©s) ‚Üí is_toxic = True ‚úÖ
Texto espa√±ol ‚Üí is_toxic = True (falso positivo) ‚ö†Ô∏è
```

## üî¥ Problema Identificado

El modelo tiene **Recall = 1.0**, lo que significa que en el dataset de test predice **TODO como t√≥xico**. Esto sugiere:

1. **Sesgo hacia la clase positiva (t√≥xico)**
2. **Umbral de decisi√≥n muy bajo**
3. **Problema en el entrenamiento o evaluaci√≥n**

## üîç D√≥nde Revisar

### 1. **Notebook de Optimizaci√≥n** (PRINCIPAL)
**Archivo**: `backend/notebooks/05_Hyperparameter_Tuning.ipynb`

**Qu√© buscar:**
- L√≠nea ~250-260: M√©tricas de evaluaci√≥n en test
- Verificar si `test_recall = 1.0`
- Verificar matriz de confusi√≥n
- Verificar distribuci√≥n de clases en test

**Comandos para verificar:**
```python
# En el notebook, despu√©s de evaluar:
from sklearn.metrics import confusion_matrix, classification_report

y_test_pred = best_model.predict(X_test)
print(confusion_matrix(y_test, y_test_pred))
print(classification_report(y_test, y_test_pred))
```

### 2. **Dataset de Test**
**Archivo**: `backend/data/processed/youtoxic_english_1000_processed.csv`

**Verificar:**
- Distribuci√≥n de clases en test
- Si hay desbalance extremo
- Si las etiquetas son correctas

### 3. **Umbral de Decisi√≥n del Modelo**

El modelo SVM usa `predict()` que devuelve la clase basada en:
- `decision_function()` > 0 ‚Üí Clase 1 (T√≥xico)
- `decision_function()` <= 0 ‚Üí Clase 0 (No T√≥xico)

**Problema potencial**: Si el modelo est√° sesgado, el hiperplano puede estar muy desplazado hacia una clase.

## üéØ Soluciones Posibles

### Soluci√≥n 1: Ajustar Umbral de Decisi√≥n
En lugar de usar `predict()` (umbral 0.5), usar un umbral personalizado:

```python
# En predict.py
decision = model.decision_function(text_vectorized)[0]
prob_toxic = probabilities[1]

# Usar umbral m√°s alto para reducir falsos positivos
threshold = 0.6  # En lugar de 0.5
is_toxic = prob_toxic > threshold
```

### Soluci√≥n 2: Re-entrenar con Mejor Balanceo
```python
# En optimization.py o train.py
model = SVC(
    C=0.056,
    kernel='linear',
    class_weight={0: 1.0, 1: 0.8},  # Reducir peso de clase t√≥xica
    probability=True
)
```

### Soluci√≥n 3: Verificar Dataset
```python
# Verificar distribuci√≥n
import pandas as pd
df = pd.read_csv('data/processed/youtoxic_english_1000_processed.csv')
print(df['IsToxic'].value_counts())
print(df['IsToxic'].value_counts(normalize=True))
```

## üìù Pasos para Diagnosticar

1. **Abrir**: `backend/notebooks/05_Hyperparameter_Tuning.ipynb`
2. **Buscar**: Celda donde se eval√∫a el modelo final
3. **Verificar**: Matriz de confusi√≥n y recall
4. **Si recall = 1.0**: El modelo predice todo como t√≥xico en test
5. **Revisar**: Distribuci√≥n de clases en test

## üí° Nota Importante

El modelo puede funcionar bien con textos en ingl√©s pero fallar con:
- Textos en otros idiomas (espa√±ol, etc.)
- Textos muy cortos
- Textos con vocabulario fuera del entrenamiento

Esto es **normal** porque el modelo est√° entrenado solo con datos en ingl√©s.

