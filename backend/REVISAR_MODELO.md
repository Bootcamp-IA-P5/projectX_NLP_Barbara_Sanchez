#  Gu铆a: D贸nde Revisar el Modelo

## Problema Identificado

El modelo tiene **Recall = 1.0**, lo que significa que predice **TODO como t贸xico**. Esto explica por qu茅 las probabilidades son siempre similares.

### M茅tricas del Modelo Actual:
- **F1-score**: 0.6866
- **Accuracy**: 0.58 (muy bajo, casi al azar)
- **Precision**: 0.5227 (muy bajo)
- **Recall**: 1.0000 锔 **PROBLEMA**: Predice todo como t贸xico

##  Archivos a Revisar

### 1. **Notebook de Optimizaci贸n** (PRINCIPAL)
**Archivo**: `backend/notebooks/05_Hyperparameter_Tuning.ipynb`

**Qu茅 revisar:**
- C贸mo se cargaron los datos
- Distribuci贸n de clases (驴est谩 balanceado?)
- Par谩metros del modelo optimizado
- M茅tricas de entrenamiento vs test
- Si hay problemas de balance de clases

**L铆neas clave a buscar:**
- Carga de datos
- `y_train.value_counts()` - Ver distribuci贸n de clases
- `best_svm_params` - Ver par谩metros finales
- M茅tricas de evaluaci贸n

### 2. **Dataset de Entrenamiento**
**Archivo**: `data/processed/youtoxic_english_1000_processed.csv` o similar

**Qu茅 revisar:**
- 驴Cu谩ntos ejemplos hay de cada clase?
- 驴Est谩 balanceado el dataset?
- 驴Qu茅 columnas tiene?
- 驴C贸mo se etiquetaron los datos?

**Comando para verificar:**
```python
import pandas as pd
df = pd.read_csv('data/processed/youtoxic_english_1000_processed.csv')
print(df['IsToxic'].value_counts())  # Ver distribuci贸n
print(df['IsToxic'].value_counts(normalize=True))  # Ver porcentajes
```

### 3. **M贸dulo de Optimizaci贸n**
**Archivo**: `backend/src/models/optimization.py`

**Qu茅 revisar:**
- C贸mo se optimizan los hiperpar谩metros
- Si hay validaci贸n cruzada
- Si se est谩 usando estratificaci贸n
- C贸mo se calcula el recall

### 4. **M贸dulo de Entrenamiento**
**Archivo**: `backend/src/models/train.py`

**Qu茅 revisar:**
- C贸mo se entrena el modelo
- Si se usa balanceo de clases
- Par谩metros por defecto

### 5. **M贸dulo de Evaluaci贸n**
**Archivo**: `backend/src/models/evaluate.py`

**Qu茅 revisar:**
- C贸mo se calculan las m茅tricas
- Si hay problemas en el c谩lculo de recall

##  Posibles Causas del Problema

### Causa 1: Dataset Desbalanceado
Si el dataset tiene muchos m谩s ejemplos de una clase que de otra, el modelo puede aprender a predecir siempre la clase mayoritaria.

**Soluci贸n:**
```python
# Usar class_weight='balanced' en SVM
from sklearn.svm import SVC
model = SVC(class_weight='balanced', ...)
```

### Causa 2: Par谩metros Incorrectos
El modelo puede tener par谩metros que lo sesgan hacia una clase.

**Revisar:**
- `C` (regularizaci贸n) - puede estar muy bajo
- `class_weight` - puede estar desbalanceado
- `kernel` - puede no ser el adecuado

### Causa 3: Problema en la Etiquetaci贸n
Los datos pueden estar mal etiquetados o tener un sesgo.

**Revisar:**
- Verificar que las etiquetas son correctas
- Verificar que 0 = Not Toxic, 1 = Toxic

##  Pasos para Diagnosticar

### Paso 1: Verificar Dataset
```python
import pandas as pd
df = pd.read_csv('data/processed/youtoxic_english_1000_processed.csv')
print("Distribuci贸n de clases:")
print(df['IsToxic'].value_counts())
print("\nPorcentajes:")
print(df['IsToxic'].value_counts(normalize=True))
```

### Paso 2: Verificar Modelo
```python
from src.api.predict import load_predictor
p = load_predictor()

# Probar con textos claramente diferentes
texts = [
    'I love this amazing video',
    'I hate you you are stupid'
]

for text in texts:
    result = p.predict(text)
    print(f'{text} -> {result["is_toxic"]} ({result["probability_toxic"]:.4f})')
```

### Paso 3: Revisar Notebook de Entrenamiento
Abrir `backend/notebooks/05_Hyperparameter_Tuning.ipynb` y revisar:
- Distribuci贸n de clases
- M茅tricas de entrenamiento
- Par谩metros del mejor modelo

##  Soluciones Posibles

### Soluci贸n 1: Re-entrenar con Balanceo
```python
from sklearn.svm import SVC

model = SVC(
    C=0.056,
    kernel='linear',
    class_weight='balanced',  # A帽adir esto
    probability=True
)
```

### Soluci贸n 2: Usar Otro Modelo
- Logistic Regression (mejores probabilidades)
- Random Forest (mejor con datos desbalanceados)
- XGBoost (mejor manejo de desbalance)

### Soluci贸n 3: Re-balancear Dataset
- Oversampling de clase minoritaria
- Undersampling de clase mayoritaria
- SMOTE

##  Comandos tiles

```bash
# Ver informaci贸n del modelo guardado
cd backend
python3 -c "import pickle; m = pickle.load(open('models/optimized/best_optimized_model.pkl', 'rb')); print(type(m)); print(m.get_params())"

# Ver informaci贸n del dataset
python3 -c "import pandas as pd; df = pd.read_csv('data/processed/youtoxic_english_1000_processed.csv'); print(df['IsToxic'].value_counts())"
```

