{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¢ Feature Engineering: Vectorizaci√≥n de Texto\n",
        "## Conversi√≥n de texto a vectores num√©ricos\n",
        "\n",
        "### Objetivos:\n",
        "1. Implementar TF-IDF Vectorizer\n",
        "2. Implementar Count Vectorizer (Bag of Words)\n",
        "3. Probar diferentes configuraciones\n",
        "4. Dividir datos en train/test estratificados\n",
        "5. Guardar matrices vectorizadas\n",
        "6. Comparar resultados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importar librer√≠as\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# A√±adir src al path\n",
        "sys.path.append(str(Path('../src').resolve()))\n",
        "\n",
        "from features.vectorization import (\n",
        "    TextVectorizer,\n",
        "    split_train_test,\n",
        "    vectorize_data,\n",
        "    save_vectorized_data\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Cargar datos preprocesados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset preprocesado\n",
        "data_path = Path('../data/processed/youtoxic_english_1000_processed.csv')\n",
        "\n",
        "if not data_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"‚ùå Dataset preprocesado no encontrado en {data_path}\\n\"\n",
        "        f\"Por favor, ejecuta primero el notebook 02_Preprocessing.ipynb\"\n",
        "    )\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"‚úÖ Dataset preprocesado cargado: {len(df)} filas\")\n",
        "print(f\"\\nüìã Columnas disponibles:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\nüìã Primeras filas:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Identificar columnas y dividir train/test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identificar columnas\n",
        "text_col = 'Text_processed'  # Columna con texto preprocesado\n",
        "label_col = 'IsToxic'  # Columna de etiquetas\n",
        "\n",
        "# Verificar que existen\n",
        "assert text_col in df.columns, f\"Columna '{text_col}' no encontrada\"\n",
        "assert label_col in df.columns, f\"Columna '{label_col}' no encontrada\"\n",
        "\n",
        "print(f\"‚úÖ Columna de texto: '{text_col}'\")\n",
        "print(f\"‚úÖ Columna de etiquetas: '{label_col}'\")\n",
        "\n",
        "# Dividir en train/test estratificado\n",
        "X_train, X_test, y_train, y_test = split_train_test(\n",
        "    df,\n",
        "    text_column=text_col,\n",
        "    label_column=label_col,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Vectorizaci√≥n con TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"VECTORIZACI√ìN CON TF-IDF\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Par√°metros del vectorizador TF-IDF\n",
        "tfidf_params = {\n",
        "    'max_features': 1000,  # M√°ximo 1000 features\n",
        "    'ngram_range': (1, 2),  # Unigramas y bigramas\n",
        "    'min_df': 2,  # M√≠nimo en 2 documentos\n",
        "    'max_df': 0.95,  # M√°ximo en 95% de documentos\n",
        "    'stop_words': 'english',\n",
        "    'lowercase': True\n",
        "}\n",
        "\n",
        "# Vectorizar\n",
        "X_train_tfidf, X_test_tfidf, vectorizer_tfidf = vectorize_data(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    method='tfidf',\n",
        "    save_path=Path('../models/tfidf_vectorizer.pkl'),\n",
        "    **tfidf_params\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Estad√≠sticas TF-IDF:\")\n",
        "print(f\"   Densidad de la matriz: {(X_train_tfidf > 0).sum() / X_train_tfidf.size * 100:.2f}%\")\n",
        "print(f\"   Valores √∫nicos: {len(np.unique(X_train_tfidf))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Vectorizaci√≥n con Count Vectorizer (Bag of Words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"VECTORIZACI√ìN CON COUNT VECTORIZER (BAG OF WORDS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Par√°metros del vectorizador Count\n",
        "count_params = {\n",
        "    'max_features': 1000,  # M√°ximo 1000 features\n",
        "    'ngram_range': (1, 2),  # Unigramas y bigramas\n",
        "    'min_df': 2,  # M√≠nimo en 2 documentos\n",
        "    'max_df': 0.95,  # M√°ximo en 95% de documentos\n",
        "    'stop_words': 'english',\n",
        "    'lowercase': True\n",
        "}\n",
        "\n",
        "# Vectorizar\n",
        "X_train_count, X_test_count, vectorizer_count = vectorize_data(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    method='count',\n",
        "    save_path=Path('../models/count_vectorizer.pkl'),\n",
        "    **count_params\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Estad√≠sticas Count Vectorizer:\")\n",
        "print(f\"   Densidad de la matriz: {(X_train_count > 0).sum() / X_train_count.size * 100:.2f}%\")\n",
        "print(f\"   Valores √∫nicos: {len(np.unique(X_train_count))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Comparaci√≥n de m√©todos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPARACI√ìN DE M√âTODOS DE VECTORIZACI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'TF-IDF': [\n",
        "        X_train_tfidf.shape[1],\n",
        "        X_train_tfidf.mean(),\n",
        "        X_train_tfidf.std(),\n",
        "        (X_train_tfidf > 0).sum() / X_train_tfidf.size * 100,\n",
        "        X_train_tfidf.max()\n",
        "    ],\n",
        "    'Count Vectorizer': [\n",
        "        X_train_count.shape[1],\n",
        "        X_train_count.mean(),\n",
        "        X_train_count.std(),\n",
        "        (X_train_count > 0).sum() / X_train_count.size * 100,\n",
        "        X_train_count.max()\n",
        "    ]\n",
        "}, index=['N√∫mero de features', 'Media', 'Desviaci√≥n est√°ndar', 'Densidad (%)', 'Valor m√°ximo'])\n",
        "\n",
        "print(\"\\nüìä Comparaci√≥n:\")\n",
        "print(comparison)\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Distribuci√≥n de valores (muestra)\n",
        "sample_tfidf = X_train_tfidf.flatten()[:10000]\n",
        "sample_count = X_train_count.flatten()[:10000]\n",
        "\n",
        "axes[0].hist(sample_tfidf, bins=50, alpha=0.7, label='TF-IDF', color='#3498db', edgecolor='black')\n",
        "axes[0].set_xlabel('Valor')\n",
        "axes[0].set_ylabel('Frecuencia')\n",
        "axes[0].set_title('Distribuci√≥n de Valores - TF-IDF', fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].hist(sample_count, bins=50, alpha=0.7, label='Count', color='#e74c3c', edgecolor='black')\n",
        "axes[1].set_xlabel('Valor')\n",
        "axes[1].set_ylabel('Frecuencia')\n",
        "axes[1].set_title('Distribuci√≥n de Valores - Count Vectorizer', fontweight='bold')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Guardar datos vectorizados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar datos vectorizados con TF-IDF\n",
        "output_dir = Path('../data/processed')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"GUARDANDO DATOS VECTORIZADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Guardar TF-IDF\n",
        "save_vectorized_data(\n",
        "    X_train_tfidf,\n",
        "    X_test_tfidf,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    output_dir,\n",
        "    prefix='tfidf'\n",
        ")\n",
        "\n",
        "# Guardar Count Vectorizer\n",
        "save_vectorized_data(\n",
        "    X_train_count,\n",
        "    X_test_count,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    output_dir,\n",
        "    prefix='count'\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Todos los datos vectorizados han sido guardados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. An√°lisis de features m√°s importantes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener features m√°s importantes (mayor peso promedio en TF-IDF)\n",
        "feature_names = vectorizer_tfidf.get_feature_names()\n",
        "feature_importance = X_train_tfidf.mean(axis=0)\n",
        "\n",
        "# Top 20 features m√°s importantes\n",
        "top_indices = np.argsort(feature_importance)[-20:][::-1]\n",
        "top_features = [(feature_names[i], feature_importance[i]) for i in top_indices]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TOP 20 FEATURES M√ÅS IMPORTANTES (TF-IDF)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n{'Feature':<30} {'Importancia':<15}\")\n",
        "print(\"-\" * 45)\n",
        "for feature, importance in top_features:\n",
        "    print(f\"{feature:<30} {importance:<15.6f}\")\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "features_df = pd.DataFrame(top_features, columns=['Feature', 'Importance'])\n",
        "ax.barh(range(len(features_df)), features_df['Importance'], color='#3498db')\n",
        "ax.set_yticks(range(len(features_df)))\n",
        "ax.set_yticklabels(features_df['Feature'])\n",
        "ax.invert_yaxis()\n",
        "ax.set_xlabel('Importancia (TF-IDF promedio)')\n",
        "ax.set_title('Top 20 Features M√°s Importantes', fontweight='bold', fontsize=14)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Resumen del Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"RESUMEN DEL FEATURE ENGINEERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n‚úÖ M√©todos implementados:\")\n",
        "print(f\"   1. TF-IDF Vectorizer\")\n",
        "print(f\"   2. Count Vectorizer (Bag of Words)\")\n",
        "\n",
        "print(f\"\\nüìä Configuraci√≥n:\")\n",
        "print(f\"   - max_features: 1000\")\n",
        "print(f\"   - ngram_range: (1, 2) - Unigramas y bigramas\")\n",
        "print(f\"   - min_df: 2\")\n",
        "print(f\"   - max_df: 0.95\")\n",
        "print(f\"   - stop_words: 'english'\")\n",
        "\n",
        "print(f\"\\nüìà Datos:\")\n",
        "print(f\"   - Train: {len(X_train)} ejemplos\")\n",
        "print(f\"   - Test: {len(X_test)} ejemplos\")\n",
        "print(f\"   - Features TF-IDF: {X_train_tfidf.shape[1]}\")\n",
        "print(f\"   - Features Count: {X_train_count.shape[1]}\")\n",
        "\n",
        "print(f\"\\nüíæ Archivos guardados:\")\n",
        "print(f\"   - ../data/processed/tfidf_X_train.pkl\")\n",
        "print(f\"   - ../data/processed/tfidf_X_test.pkl\")\n",
        "print(f\"   - ../data/processed/count_X_train.pkl\")\n",
        "print(f\"   - ../data/processed/count_X_test.pkl\")\n",
        "print(f\"   - ../data/processed/y_train.pkl\")\n",
        "print(f\"   - ../data/processed/y_test.pkl\")\n",
        "print(f\"   - ../models/tfidf_vectorizer.pkl\")\n",
        "print(f\"   - ../models/count_vectorizer.pkl\")\n",
        "\n",
        "print(\"\\n‚úÖ Feature Engineering completado exitosamente\")\n",
        "print(\"   Listo para entrenar modelos de Machine Learning\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
