{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos (EDA)\n",
    "## Dataset: YouToxic English 1000\n",
    "\n",
    "Este notebook contiene el análisis exploratorio del dataset de comentarios tóxicos de YouTube.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías\n",
    "\n",
    "Primero importamos las librerías necesarias para el análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías para visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuración de pandas para ver más columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de datos\n",
    "\n",
    "Cargamos el dataset desde el archivo CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 5 filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "      <th>IsAbusive</th>\n",
       "      <th>IsThreat</th>\n",
       "      <th>IsProvocative</th>\n",
       "      <th>IsObscene</th>\n",
       "      <th>IsHatespeech</th>\n",
       "      <th>IsRacist</th>\n",
       "      <th>IsNationalist</th>\n",
       "      <th>IsSexist</th>\n",
       "      <th>IsHomophobic</th>\n",
       "      <th>IsReligiousHate</th>\n",
       "      <th>IsRadicalism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>If only people would just take a step back and not make this case about them, because it wasn't ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Law enforcement is not trained to shoot to apprehend.  They are trained to shoot to kill.  And I...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>\\nDont you reckon them 'black lives matter' banners being held by white cunts is  kinda patroniz...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>There are a very large number of people who do not like police officers. They are called Crimina...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>The Arab dude is absolutely right, he should have not been shot 6 extra time. Shoot him once if ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CommentId      VideoId  \\\n",
       "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
       "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
       "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
       "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
       "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
       "\n",
       "                                                                                                  Text  \\\n",
       "0  If only people would just take a step back and not make this case about them, because it wasn't ...   \n",
       "1  Law enforcement is not trained to shoot to apprehend.  They are trained to shoot to kill.  And I...   \n",
       "2  \\nDont you reckon them 'black lives matter' banners being held by white cunts is  kinda patroniz...   \n",
       "3  There are a very large number of people who do not like police officers. They are called Crimina...   \n",
       "4  The Arab dude is absolutely right, he should have not been shot 6 extra time. Shoot him once if ...   \n",
       "\n",
       "   IsToxic  IsAbusive  IsThreat  IsProvocative  IsObscene  IsHatespeech  \\\n",
       "0    False      False     False          False      False         False   \n",
       "1     True       True     False          False      False         False   \n",
       "2     True       True     False          False       True         False   \n",
       "3    False      False     False          False      False         False   \n",
       "4    False      False     False          False      False         False   \n",
       "\n",
       "   IsRacist  IsNationalist  IsSexist  IsHomophobic  IsReligiousHate  \\\n",
       "0     False          False     False         False            False   \n",
       "1     False          False     False         False            False   \n",
       "2     False          False     False         False            False   \n",
       "3     False          False     False         False            False   \n",
       "4     False          False     False         False            False   \n",
       "\n",
       "   IsRadicalism  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('../data/raw/youtoxic_english_1000.csv')\n",
    "\n",
    "# Ver las primeras filas\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Información básica del dataset\n",
    "\n",
    "Vamos a explorar las dimensiones, tipos de datos y estructura general del dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: (1000, 15)\n",
      "Número de filas: 1000\n",
      "Número de columnas: 15\n"
     ]
    }
   ],
   "source": [
    "# Dimensiones del dataset (filas, columnas)\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"Número de filas: {df.shape[0]}\")\n",
    "print(f\"Número de columnas: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   CommentId        1000 non-null   object\n",
      " 1   VideoId          1000 non-null   object\n",
      " 2   Text             1000 non-null   object\n",
      " 3   IsToxic          1000 non-null   bool  \n",
      " 4   IsAbusive        1000 non-null   bool  \n",
      " 5   IsThreat         1000 non-null   bool  \n",
      " 6   IsProvocative    1000 non-null   bool  \n",
      " 7   IsObscene        1000 non-null   bool  \n",
      " 8   IsHatespeech     1000 non-null   bool  \n",
      " 9   IsRacist         1000 non-null   bool  \n",
      " 10  IsNationalist    1000 non-null   bool  \n",
      " 11  IsSexist         1000 non-null   bool  \n",
      " 12  IsHomophobic     1000 non-null   bool  \n",
      " 13  IsReligiousHate  1000 non-null   bool  \n",
      " 14  IsRadicalism     1000 non-null   bool  \n",
      "dtypes: bool(12), object(3)\n",
      "memory usage: 35.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Información general del dataset\n",
    "print(\"Información del dataset:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del dataset:\n",
      "['CommentId', 'VideoId', 'Text', 'IsToxic', 'IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene', 'IsHatespeech', 'IsRacist', 'IsNationalist', 'IsSexist', 'IsHomophobic', 'IsReligiousHate', 'IsRadicalism']\n"
     ]
    }
   ],
   "source": [
    "# Nombres de las columnas\n",
    "print(\"Columnas del dataset:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "CommentId          0\n",
      "VideoId            0\n",
      "Text               0\n",
      "IsToxic            0\n",
      "IsAbusive          0\n",
      "IsThreat           0\n",
      "IsProvocative      0\n",
      "IsObscene          0\n",
      "IsHatespeech       0\n",
      "IsRacist           0\n",
      "IsNationalist      0\n",
      "IsSexist           0\n",
      "IsHomophobic       0\n",
      "IsReligiousHate    0\n",
      "IsRadicalism       0\n",
      "dtype: int64\n",
      "\n",
      "Porcentaje de valores nulos:\n",
      "CommentId          0.0\n",
      "VideoId            0.0\n",
      "Text               0.0\n",
      "IsToxic            0.0\n",
      "IsAbusive          0.0\n",
      "IsThreat           0.0\n",
      "IsProvocative      0.0\n",
      "IsObscene          0.0\n",
      "IsHatespeech       0.0\n",
      "IsRacist           0.0\n",
      "IsNationalist      0.0\n",
      "IsSexist           0.0\n",
      "IsHomophobic       0.0\n",
      "IsReligiousHate    0.0\n",
      "IsRadicalism       0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores nulos\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nPorcentaje de valores nulos:\")\n",
    "print((df.isnull().sum() / len(df)) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis de las etiquetas de toxicidad\n",
    "\n",
    "Vamos a analizar la distribución de las diferentes etiquetas de toxicidad en el dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar todas las columnas de etiquetas (todas las que empiezan con \"Is\")\n",
    "label_columns = [col for col in df.columns if col.startswith('Is')]\n",
    "print(\"Columnas de etiquetas de toxicidad:\")\n",
    "print(label_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar cuántos comentarios tienen cada etiqueta activa (True)\n",
    "print(\"Distribución de etiquetas (cantidad de comentarios con cada etiqueta = True):\")\n",
    "for col in label_columns:\n",
    "    count = df[col].sum()\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{col}: {count} ({percentage:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización: Distribución de la etiqueta principal IsToxic\n",
    "plt.figure(figsize=(8, 5))\n",
    "toxic_counts = df['IsToxic'].value_counts()\n",
    "plt.bar(['No Tóxico', 'Tóxico'], toxic_counts.values, color=['green', 'red'], alpha=0.7)\n",
    "plt.title('Distribución de Comentarios Tóxicos vs No Tóxicos', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Cantidad de Comentarios', fontsize=12)\n",
    "plt.xlabel('Categoría', fontsize=12)\n",
    "\n",
    "# Agregar los valores en las barras\n",
    "for i, v in enumerate(toxic_counts.values):\n",
    "    plt.text(i, v + 10, str(v), ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nComentarios tóxicos: {toxic_counts.get(True, 0)} ({toxic_counts.get(True, 0)/len(df)*100:.2f}%)\")\n",
    "print(f\"Comentarios no tóxicos: {toxic_counts.get(False, 0)} ({toxic_counts.get(False, 0)/len(df)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualización de todas las etiquetas de toxicidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un gráfico de barras horizontal con todas las etiquetas (excluyendo IsToxic que ya vimos)\n",
    "sub_labels = [col for col in label_columns if col != 'IsToxic']\n",
    "counts = [df[col].sum() for col in sub_labels]\n",
    "percentages = [(count / len(df)) * 100 for count in counts]\n",
    "\n",
    "# Crear el gráfico\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "bars = ax.barh(sub_labels, counts, color='coral', alpha=0.7)\n",
    "\n",
    "# Agregar los valores en las barras\n",
    "for i, (count, pct) in enumerate(zip(counts, percentages)):\n",
    "    ax.text(count + 5, i, f'{count} ({pct:.1f}%)', \n",
    "            va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Cantidad de Comentarios', fontsize=12)\n",
    "ax.set_title('Distribución de Tipos de Toxicidad en el Dataset', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Análisis de solapamiento entre etiquetas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular cuántas etiquetas tiene cada comentario\n",
    "df['num_labels'] = df[label_columns].sum(axis=1)\n",
    "\n",
    "print(\"Distribución del número de etiquetas por comentario:\")\n",
    "print(df['num_labels'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nComentarios sin ninguna etiqueta: {(df['num_labels'] == 0).sum()}\")\n",
    "print(f\"Comentarios con al menos una etiqueta: {(df['num_labels'] > 0).sum()}\")\n",
    "print(f\"Comentarios con múltiples etiquetas: {(df['num_labels'] > 1).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización: Distribución del número de etiquetas\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_dist = df['num_labels'].value_counts().sort_index()\n",
    "plt.bar(label_dist.index, label_dist.values, color='steelblue', alpha=0.7)\n",
    "plt.xlabel('Número de Etiquetas', fontsize=12)\n",
    "plt.ylabel('Cantidad de Comentarios', fontsize=12)\n",
    "plt.title('Distribución del Número de Etiquetas por Comentario', fontsize=14, fontweight='bold')\n",
    "plt.xticks(label_dist.index)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, v in enumerate(label_dist.values):\n",
    "    plt.text(label_dist.index[i], v + 5, str(v), ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación entre etiquetas (para ver qué etiquetas suelen aparecer juntas)\n",
    "label_df = df[label_columns]\n",
    "correlation_matrix = label_df.corr()\n",
    "\n",
    "# Crear heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlación entre Etiquetas de Toxicidad', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis del texto de los comentarios\n",
    "\n",
    "Vamos a analizar las características del texto: longitud, número de palabras, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular características del texto\n",
    "df['text_length'] = df['Text'].str.len()  # Longitud en caracteres\n",
    "df['word_count'] = df['Text'].str.split().str.len()  # Número de palabras\n",
    "df['sentence_count'] = df['Text'].str.count(r'[.!?]+')  # Número aproximado de oraciones\n",
    "\n",
    "print(\"Estadísticas descriptivas del texto:\")\n",
    "print(df[['text_length', 'word_count', 'sentence_count']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar características del texto entre comentarios tóxicos y no tóxicos\n",
    "toxic_text_stats = df[df['IsToxic'] == True][['text_length', 'word_count', 'sentence_count']].describe()\n",
    "non_toxic_text_stats = df[df['IsToxic'] == False][['text_length', 'word_count', 'sentence_count']].describe()\n",
    "\n",
    "print(\"Estadísticas de comentarios TÓXICOS:\")\n",
    "print(toxic_text_stats)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Estadísticas de comentarios NO TÓXICOS:\")\n",
    "print(non_toxic_text_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización: Distribución de longitud de texto\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Longitud en caracteres\n",
    "axes[0].hist(df[df['IsToxic']==False]['text_length'], bins=50, alpha=0.6, label='No Tóxico', color='green')\n",
    "axes[0].hist(df[df['IsToxic']==True]['text_length'], bins=50, alpha=0.6, label='Tóxico', color='red')\n",
    "axes[0].set_xlabel('Longitud (caracteres)', fontsize=11)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=11)\n",
    "axes[0].set_title('Distribución de Longitud de Texto', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Número de palabras\n",
    "axes[1].hist(df[df['IsToxic']==False]['word_count'], bins=50, alpha=0.6, label='No Tóxico', color='green')\n",
    "axes[1].hist(df[df['IsToxic']==True]['word_count'], bins=50, alpha=0.6, label='Tóxico', color='red')\n",
    "axes[1].set_xlabel('Número de Palabras', fontsize=11)\n",
    "axes[1].set_ylabel('Frecuencia', fontsize=11)\n",
    "axes[1].set_title('Distribución de Número de Palabras', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Número de oraciones\n",
    "axes[2].hist(df[df['IsToxic']==False]['sentence_count'], bins=30, alpha=0.6, label='No Tóxico', color='green')\n",
    "axes[2].hist(df[df['IsToxic']==True]['sentence_count'], bins=30, alpha=0.6, label='Tóxico', color='red')\n",
    "axes[2].set_xlabel('Número de Oraciones', fontsize=11)\n",
    "axes[2].set_ylabel('Frecuencia', fontsize=11)\n",
    "axes[2].set_title('Distribución de Número de Oraciones', fontsize=12, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots comparativos\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Boxplot de longitud\n",
    "df_melted = df.melt(id_vars=['IsToxic'], value_vars=['text_length'], \n",
    "                    var_name='metric', value_name='value')\n",
    "sns.boxplot(data=df, x='IsToxic', y='text_length', ax=axes[0], palette=['green', 'red'])\n",
    "axes[0].set_title('Longitud de Texto: Tóxico vs No Tóxico', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Es Tóxico', fontsize=11)\n",
    "axes[0].set_ylabel('Longitud (caracteres)', fontsize=11)\n",
    "axes[0].set_xticklabels(['No', 'Sí'])\n",
    "\n",
    "# Boxplot de palabras\n",
    "sns.boxplot(data=df, x='IsToxic', y='word_count', ax=axes[1], palette=['green', 'red'])\n",
    "axes[1].set_title('Número de Palabras: Tóxico vs No Tóxico', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Es Tóxico', fontsize=11)\n",
    "axes[1].set_ylabel('Número de Palabras', fontsize=11)\n",
    "axes[1].set_xticklabels(['No', 'Sí'])\n",
    "\n",
    "# Boxplot de oraciones\n",
    "sns.boxplot(data=df, x='IsToxic', y='sentence_count', ax=axes[2], palette=['green', 'red'])\n",
    "axes[2].set_title('Número de Oraciones: Tóxico vs No Tóxico', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Es Tóxico', fontsize=11)\n",
    "axes[2].set_ylabel('Número de Oraciones', fontsize=11)\n",
    "axes[2].set_xticklabels(['No', 'Sí'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis de ejemplos de comentarios\n",
    "\n",
    "Vamos a ver algunos ejemplos de comentarios tóxicos y no tóxicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de comentarios NO tóxicos\n",
    "print(\"=\"*80)\n",
    "print(\"EJEMPLOS DE COMENTARIOS NO TÓXICOS\")\n",
    "print(\"=\"*80)\n",
    "non_toxic_samples = df[df['IsToxic'] == False]['Text'].head(3)\n",
    "for i, text in enumerate(non_toxic_samples, 1):\n",
    "    print(f\"\\nEjemplo {i}:\")\n",
    "    print(f\"{text[:200]}...\" if len(text) > 200 else text)\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de comentarios tóxicos con sus etiquetas\n",
    "print(\"=\"*80)\n",
    "print(\"EJEMPLOS DE COMENTARIOS TÓXICOS\")\n",
    "print(\"=\"*80)\n",
    "toxic_samples = df[df['IsToxic'] == True].head(3)\n",
    "for idx, row in toxic_samples.iterrows():\n",
    "    print(f\"\\nEjemplo {idx + 1}:\")\n",
    "    print(f\"Texto: {row['Text'][:200]}...\" if len(row['Text']) > 200 else f\"Texto: {row['Text']}\")\n",
    "    # Obtener las etiquetas activas\n",
    "    active_labels = [label for label in label_columns if row[label] == True]\n",
    "    print(f\"Etiquetas: {', '.join(active_labels)}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis por VideoId\n",
    "\n",
    "Vamos a ver si hay algún patrón relacionado con los videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de videos únicos\n",
    "print(f\"Número de videos únicos: {df['VideoId'].nunique()}\")\n",
    "print(f\"Número total de comentarios: {len(df)}\")\n",
    "print(f\"Promedio de comentarios por video: {len(df) / df['VideoId'].nunique():.2f}\")\n",
    "\n",
    "# Comentarios por video\n",
    "comments_per_video = df['VideoId'].value_counts()\n",
    "print(f\"\\nVideos con más comentarios:\")\n",
    "print(comments_per_video.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasa de toxicidad por video\n",
    "toxicity_by_video = df.groupby('VideoId').agg({\n",
    "    'IsToxic': ['count', 'sum', 'mean']\n",
    "}).round(3)\n",
    "toxicity_by_video.columns = ['total_comments', 'toxic_comments', 'toxicity_rate']\n",
    "toxicity_by_video = toxicity_by_video.sort_values('toxicity_rate', ascending=False)\n",
    "\n",
    "print(\"Videos con mayor tasa de toxicidad:\")\n",
    "print(toxicity_by_video.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumen y Conclusiones\n",
    "\n",
    "Resumen de los hallazgos principales del análisis exploratorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RESUMEN DEL ANÁLISIS EXPLORATORIO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. DATASET:\")\n",
    "print(f\"   - Total de comentarios: {len(df)}\")\n",
    "print(f\"   - Total de videos: {df['VideoId'].nunique()}\")\n",
    "print(f\"   - Columnas: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\n2. DISTRIBUCIÓN DE TOXICIDAD:\")\n",
    "toxic_count = df['IsToxic'].sum()\n",
    "non_toxic_count = len(df) - toxic_count\n",
    "print(f\"   - Comentarios tóxicos: {toxic_count} ({toxic_count/len(df)*100:.2f}%)\")\n",
    "print(f\"   - Comentarios no tóxicos: {non_toxic_count} ({non_toxic_count/len(df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n3. TIPOS DE TOXICIDAD MÁS COMUNES:\")\n",
    "sub_label_counts = [(col, df[col].sum()) for col in sub_labels]\n",
    "sub_label_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "for label, count in sub_label_counts[:5]:\n",
    "    print(f\"   - {label}: {count} ({count/len(df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n4. CARACTERÍSTICAS DEL TEXTO:\")\n",
    "print(f\"   - Longitud promedio: {df['text_length'].mean():.1f} caracteres\")\n",
    "print(f\"   - Palabras promedio: {df['word_count'].mean():.1f} palabras\")\n",
    "print(f\"   - Longitud promedio (tóxicos): {df[df['IsToxic']==True]['text_length'].mean():.1f} caracteres\")\n",
    "print(f\"   - Longitud promedio (no tóxicos): {df[df['IsToxic']==False]['text_length'].mean():.1f} caracteres\")\n",
    "\n",
    "print(f\"\\n5. MULTI-ETIQUETADO:\")\n",
    "print(f\"   - Comentarios con múltiples etiquetas: {(df['num_labels'] > 1).sum()}\")\n",
    "print(f\"   - Promedio de etiquetas por comentario tóxico: {df[df['IsToxic']==True]['num_labels'].mean():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
