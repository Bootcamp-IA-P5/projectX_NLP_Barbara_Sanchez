{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducci√≥n de Overfitting - T√©cnicas Aplicables a SVM\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANTE: T√©cnicas para SVM (NO para redes neuronales)\n",
    "\n",
    "**T√©cnicas que NO aplican a SVM:**\n",
    "- ‚ùå Dropout (solo para redes neuronales)\n",
    "- ‚ùå Early Stopping (solo para redes neuronales)\n",
    "\n",
    "**T√©cnicas que S√ç aplican a SVM:**\n",
    "- ‚úÖ **Class Weights** (balanceo de clases)\n",
    "- ‚úÖ **Regularizaci√≥n L2** (par√°metro C en SVM)\n",
    "- ‚úÖ **Data Augmentation** (aumento de datos)\n",
    "- ‚úÖ **Cross-validation** (validaci√≥n cruzada)\n",
    "- ‚úÖ **Reducir complejidad** (menos features, vectorizador m√°s simple)\n",
    "\n",
    "Este notebook implementa todas las t√©cnicas aplicables a SVM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas\n"
     ]
    }
   ],
   "source": [
    "# Librer√≠as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Para sin√≥nimos\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.corpus import wordnet as wn\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    HAS_WORDNET = True\n",
    "    # Descargar recursos si no est√°n\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt', quiet=True)\n",
    "    try:\n",
    "        nltk.data.find('corpora/wordnet')\n",
    "    except LookupError:\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "except ImportError:\n",
    "    HAS_WORDNET = False\n",
    "    print(\"‚ö†Ô∏è  NLTK no disponible. Data augmentation sin sin√≥nimos.\")\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos cargados: 800 train, 200 test\n",
      "Class weights: {0: 0.9302325581395349, 1: 1.0810810810810811}\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "df = pd.read_csv('../data/processed/youtoxic_english_1000_processed.csv')\n",
    "with open('../data/processed/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('../data/processed/y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "X_train_text = df[df.index.isin(range(len(y_train)))]['Text_processed'].values\n",
    "X_test_text = df[df.index.isin(range(len(y_train), len(y_train) + len(y_test)))]['Text_processed'].values\n",
    "\n",
    "# Calcular class weights (balanceo de clases)\n",
    "n_samples = len(y_train)\n",
    "n_classes = 2\n",
    "class_counts = np.bincount(y_train)\n",
    "total = class_counts.sum()\n",
    "class_weights = {0: total / (n_classes * class_counts[0]), \n",
    "                 1: total / (n_classes * class_counts[1])}\n",
    "\n",
    "print(f\"‚úÖ Datos cargados: {len(X_train_text)} train, {len(X_test_text)} test\")\n",
    "print(f\"Class weights: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation (Aumento de Datos)\n",
    "\n",
    "T√©cnica simple: eliminar palabras aleatorias de la clase minoritaria para crear variaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando data augmentation mejorada (50% con sin√≥nimos)...\n",
      "Aumentando 185 muestras de clase 1...\n",
      "Datos originales: 800\n",
      "Datos aumentados: 985 (+185)\n",
      "Incremento: 23.1%\n"
     ]
    }
   ],
   "source": [
    "def get_synonyms(word):\n",
    "    \"\"\"Obtiene sin√≥nimos de una palabra usando WordNet.\"\"\"\n",
    "    if not HAS_WORDNET:\n",
    "        return []\n",
    "    \n",
    "    synonyms = set()\n",
    "    for syn in wn.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonym = lemma.name().replace('_', ' ').lower()\n",
    "            if synonym != word and len(synonym.split()) == 1:\n",
    "                synonyms.add(synonym)\n",
    "    \n",
    "    return list(synonyms)[:3]  # M√°ximo 3 sin√≥nimos\n",
    "\n",
    "def augment_with_synonyms(text, max_replacements=2):\n",
    "    \"\"\"Reemplaza palabras con sin√≥nimos.\"\"\"\n",
    "    if not HAS_WORDNET:\n",
    "        return text\n",
    "    \n",
    "    words = word_tokenize(text.lower())\n",
    "    augmented_words = words.copy()\n",
    "    \n",
    "    # Reemplazar hasta max_replacements palabras\n",
    "    replacements = 0\n",
    "    for i, word in enumerate(words):\n",
    "        if replacements >= max_replacements:\n",
    "            break\n",
    "        if word.isalpha() and len(word) > 3:  # Solo palabras > 3 letras\n",
    "            synonyms = get_synonyms(word)\n",
    "            if synonyms:\n",
    "                augmented_words[i] = random.choice(synonyms)\n",
    "                replacements += 1\n",
    "    \n",
    "    return ' '.join(augmented_words)\n",
    "\n",
    "def advanced_augmentation(texts, labels, augmentation_factor=0.5):\n",
    "    \"\"\"\n",
    "    Data augmentation mejorada con:\n",
    "    1. Sin√≥nimos (reemplazo de palabras)\n",
    "    2. Eliminaci√≥n de palabras aleatorias\n",
    "    3. Duplicaci√≥n de muestras minoritarias\n",
    "    \"\"\"\n",
    "    augmented_texts = list(texts)\n",
    "    augmented_labels = list(labels)\n",
    "    \n",
    "    toxic_count = labels.sum()\n",
    "    non_toxic_count = len(labels) - toxic_count\n",
    "    \n",
    "    if toxic_count < non_toxic_count:\n",
    "        minority_class = 1\n",
    "        n_to_augment = int(toxic_count * augmentation_factor)\n",
    "    else:\n",
    "        minority_class = 0\n",
    "        n_to_augment = int(non_toxic_count * augmentation_factor)\n",
    "    \n",
    "    minority_indices = [i for i, label in enumerate(labels) if label == minority_class]\n",
    "    \n",
    "    print(f\"Aumentando {n_to_augment} muestras de clase {minority_class}...\")\n",
    "    \n",
    "    for i in range(n_to_augment):\n",
    "        idx = random.choice(minority_indices)\n",
    "        original_text = texts[idx]\n",
    "        \n",
    "        # Estrategia 1: Sin√≥nimos (50% de las veces)\n",
    "        if HAS_WORDNET and random.random() < 0.5:\n",
    "            try:\n",
    "                augmented_text = augment_with_synonyms(original_text)\n",
    "                if augmented_text != original_text:  # Solo si cambi√≥ algo\n",
    "                    augmented_texts.append(augmented_text)\n",
    "                    augmented_labels.append(minority_class)\n",
    "                    continue\n",
    "            except:\n",
    "                pass  # Si falla, usar otra estrategia\n",
    "        \n",
    "        # Estrategia 2: Eliminar palabras aleatorias\n",
    "        words = original_text.split()\n",
    "        if len(words) > 4:\n",
    "            n_to_remove = random.randint(1, max(1, len(words) // 5))\n",
    "            words_to_keep = random.sample(words, len(words) - n_to_remove)\n",
    "            augmented_text = ' '.join(words_to_keep)\n",
    "        else:\n",
    "            # Estrategia 3: Duplicar (si no se puede modificar)\n",
    "            augmented_text = original_text\n",
    "        \n",
    "        augmented_texts.append(augmented_text)\n",
    "        augmented_labels.append(minority_class)\n",
    "    \n",
    "    return np.array(augmented_texts), np.array(augmented_labels)\n",
    "\n",
    "print(\"Aplicando data augmentation mejorada (50% con sin√≥nimos)...\")\n",
    "X_train_aug, y_train_aug = advanced_augmentation(X_train_text, y_train, 0.5)\n",
    "\n",
    "print(f\"Datos originales: {len(X_train_text)}\")\n",
    "print(f\"Datos aumentados: {len(X_train_aug)} (+{len(X_train_aug) - len(X_train_text)})\")\n",
    "print(f\"Incremento: {((len(X_train_aug)/len(X_train_text))-1)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizaci√≥n Optimizada (Reducir Complejidad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vectorizaci√≥n ULTRA optimizada: 578 features\n",
      "   Train shape: (985, 578)\n",
      "   Test shape: (200, 578)\n",
      "   Reducci√≥n de complejidad: menos features, m√°s filtros\n"
     ]
    }
   ],
   "source": [
    "# Vectorizador ULTRA optimizado para reducir overfitting\n",
    "# Reducir a√∫n m√°s la complejidad\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,      # Reducido a√∫n m√°s (de 1200 a 1000)\n",
    "    ngram_range=(1, 1),     # Solo unigramas\n",
    "    min_df=5,               # Filtrar a√∫n m√°s palabras raras (de 4 a 5)\n",
    "    max_df=0.75,            # Filtrar a√∫n m√°s palabras comunes (de 0.80 a 0.75)\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,      # log(tf) para suavizar\n",
    "    norm='l2'               # Normalizaci√≥n L2\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_aug)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "\n",
    "print(f\"‚úÖ Vectorizaci√≥n ULTRA optimizada: {X_train_tfidf.shape[1]} features\")\n",
    "print(f\"   Train shape: {X_train_tfidf.shape}\")\n",
    "print(f\"   Test shape: {X_test_tfidf.shape}\")\n",
    "print(f\"   Reducci√≥n de complejidad: menos features, m√°s filtros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci√≥n de Evaluaci√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Eval√∫a modelo y retorna m√©tricas.\"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_f1 = f1_score(y_train, y_train_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    diff_f1 = abs(train_f1 - test_f1) * 100\n",
    "    \n",
    "    return {\n",
    "        'train_f1': train_f1,\n",
    "        'test_f1': test_f1,\n",
    "        'test_accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'test_precision': precision_score(y_test, y_test_pred, zero_division=0),\n",
    "        'test_recall': recall_score(y_test, y_test_pred, zero_division=0),\n",
    "        'diff_f1': diff_f1,\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_test_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizaci√≥n con Class Weights + Regularizaci√≥n L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funci√≥n objetivo ULTRA-ESTRICTA (prioriza MUCHO control de overfitting)\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Funci√≥n objetivo ULTRA-ESTRICTA para bajar de 9% a <5%:\n",
    "    - Regularizaci√≥n L2 MUY fuerte (C muy bajo)\n",
    "    - Class weights ajustados\n",
    "    - Penalizaci√≥n MUY fuerte por overfitting > 5%\n",
    "    \"\"\"\n",
    "    # Regularizaci√≥n L2 ULTRA fuerte: C muy bajo\n",
    "    C = trial.suggest_float('C', 0.01, 1.0, log=True)  # Rango a√∫n m√°s bajo\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    \n",
    "    # Ajustar class weights (menos extremo para evitar recall=1.0)\n",
    "    use_class_weight = trial.suggest_categorical('use_class_weight', [True, False])\n",
    "    if use_class_weight:\n",
    "        # Class weights m√°s balanceados (menos extremo)\n",
    "        balanced_weights = {0: 1.0, 1: 1.1}  # Menos desbalanceado\n",
    "        weight_dict = balanced_weights\n",
    "    else:\n",
    "        weight_dict = None\n",
    "    \n",
    "    model = SVC(\n",
    "        C=C,  # Regularizaci√≥n L2 ULTRA fuerte\n",
    "        kernel=kernel,\n",
    "        gamma=gamma,\n",
    "        class_weight=weight_dict,\n",
    "        random_state=42,\n",
    "        probability=True\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_tfidf, y_train_aug)\n",
    "    results = evaluate_model(model, X_train_tfidf, X_test_tfidf, y_train_aug, y_test)\n",
    "    \n",
    "    # Rechazar modelos in√∫tiles\n",
    "    if results['test_f1'] < 0.55:\n",
    "        return -10.0\n",
    "    \n",
    "    # Rechazar modelos con recall extremo (todo como t√≥xico)\n",
    "    if results['test_recall'] > 0.95:\n",
    "        return -5.0\n",
    "    \n",
    "    # PRIORIDAD 1: Control de overfitting (CR√çTICO - objetivo <5%)\n",
    "    if results['diff_f1'] < 5.0:\n",
    "        # Bonus ENORME si overfitting < 5%\n",
    "        overfitting_bonus = (5.0 - results['diff_f1']) * 0.10  # Bonus muy grande\n",
    "    else:\n",
    "        overfitting_bonus = 0\n",
    "    \n",
    "    # PRIORIDAD 2: Penalizaci√≥n ULTRA fuerte por overfitting alto\n",
    "    if results['diff_f1'] > 5.0:\n",
    "        # Penalizaci√≥n exponencial para overfitting > 5%\n",
    "        overfitting_penalty = (results['diff_f1'] - 5.0) * 0.05  # Penalizaci√≥n MUY fuerte\n",
    "    else:\n",
    "        overfitting_penalty = 0\n",
    "    \n",
    "    # PRIORIDAD 3: F1-score (menos importante)\n",
    "    base_score = results['test_f1']\n",
    "    \n",
    "    # Score final: priorizar MUCHO el control de overfitting\n",
    "    score = base_score + overfitting_bonus - overfitting_penalty\n",
    "    \n",
    "    return score\n",
    "\n",
    "print(\"‚úÖ Funci√≥n objetivo ULTRA-ESTRICTA (prioriza MUCHO control de overfitting)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-03 09:33:39,410] A new study created in memory with name: no-name-3f5938ce-5589-4567-95ea-c7250261aed8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OPTIMIZACI√ìN FINAL - BAJAR DE 9% A <5%\n",
      "================================================================================\n",
      "‚úÖ Data Augmentation (50% con sin√≥nimos)\n",
      "‚úÖ Class Weights balanceados (menos extremos)\n",
      "‚úÖ Regularizaci√≥n L2 ULTRA fuerte (C: 0.01-1.0)\n",
      "‚úÖ Vectorizador ULTRA optimizado (1000 features)\n",
      "‚úÖ Penalizaci√≥n MUY fuerte por overfitting > 5%\n",
      "‚úÖ Rechazar modelos con recall extremo (>0.95)\n",
      "\n",
      "Objetivo: F1 > 0.55 Y overfitting < 5%\n",
      "Estado actual: 9.06% ‚Üí Objetivo: <5%\n",
      "Trials: 100 (b√∫squeda exhaustiva)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb8c4c3c3da4d0db32cc35527dea809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-03 09:33:39,815] Trial 0 finished with value: -5.0 and parameters: {'C': 0.05611516415334506, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 0 with value: -5.0.\n",
      "[I 2025-12-03 09:33:40,156] Trial 1 finished with value: -5.0 and parameters: {'C': 0.5399484409787431, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 0 with value: -5.0.\n",
      "[I 2025-12-03 09:33:40,514] Trial 2 finished with value: -5.0 and parameters: {'C': 0.02310201887845294, 'kernel': 'rbf', 'gamma': 'scale', 'use_class_weight': False}. Best is trial 0 with value: -5.0.\n",
      "[I 2025-12-03 09:33:40,836] Trial 3 finished with value: -5.0 and parameters: {'C': 0.01901024531987036, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 0 with value: -5.0.\n",
      "[I 2025-12-03 09:33:41,196] Trial 4 finished with value: -5.0 and parameters: {'C': 0.15304852121831464, 'kernel': 'rbf', 'gamma': 'scale', 'use_class_weight': False}. Best is trial 0 with value: -5.0.\n",
      "[I 2025-12-03 09:33:41,502] Trial 5 finished with value: -0.40881911854064046 and parameters: {'C': 0.4138040112561014, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': False}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:41,815] Trial 6 finished with value: -5.0 and parameters: {'C': 0.011715937392307063, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': False}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:42,124] Trial 7 finished with value: -5.0 and parameters: {'C': 0.02342658105820405, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': False}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:42,424] Trial 8 finished with value: -5.0 and parameters: {'C': 0.015030900645056829, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:42,750] Trial 9 finished with value: -5.0 and parameters: {'C': 0.05170191786366993, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:43,067] Trial 10 finished with value: -10.0 and parameters: {'C': 0.8971270805430306, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:43,376] Trial 11 finished with value: -5.0 and parameters: {'C': 0.19062374828215112, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:43,686] Trial 12 finished with value: -5.0 and parameters: {'C': 0.07168972790282682, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:44,006] Trial 13 finished with value: -5.0 and parameters: {'C': 0.2593381762689127, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:44,316] Trial 14 finished with value: -5.0 and parameters: {'C': 0.05371765934548002, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 5 with value: -0.40881911854064046.\n",
      "[I 2025-12-03 09:33:44,633] Trial 15 finished with value: -0.11730899625976066 and parameters: {'C': 0.36355698578470025, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 15 with value: -0.11730899625976066.\n",
      "[I 2025-12-03 09:33:44,948] Trial 16 finished with value: -0.3726722180166544 and parameters: {'C': 0.39453398297988584, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': False}. Best is trial 15 with value: -0.11730899625976066.\n",
      "[I 2025-12-03 09:33:45,252] Trial 17 finished with value: -10.0 and parameters: {'C': 0.9160567866502919, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 15 with value: -0.11730899625976066.\n",
      "[I 2025-12-03 09:33:45,557] Trial 18 finished with value: -0.2613631014028811 and parameters: {'C': 0.33712282626421675, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 15 with value: -0.11730899625976066.\n",
      "[I 2025-12-03 09:33:45,871] Trial 19 finished with value: -5.0 and parameters: {'C': 0.12362332330094199, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 15 with value: -0.11730899625976066.\n",
      "[I 2025-12-03 09:33:46,187] Trial 20 finished with value: -5.0 and parameters: {'C': 0.23488187724591175, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 15 with value: -0.11730899625976066.\n",
      "[I 2025-12-03 09:33:46,534] Trial 21 finished with value: -0.13592471358428793 and parameters: {'C': 0.3036032262967419, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 15 with value: -0.11730899625976066.\n",
      "[I 2025-12-03 09:33:46,851] Trial 22 finished with value: 0.1967176564838189 and parameters: {'C': 0.26825532978296507, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 22 with value: 0.1967176564838189.\n",
      "[I 2025-12-03 09:33:47,159] Trial 23 finished with value: -5.0 and parameters: {'C': 0.1992321457381168, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 22 with value: 0.1967176564838189.\n",
      "[I 2025-12-03 09:33:47,468] Trial 24 finished with value: -10.0 and parameters: {'C': 0.5130937919284738, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 22 with value: 0.1967176564838189.\n",
      "[I 2025-12-03 09:33:47,784] Trial 25 finished with value: -0.04913112759611982 and parameters: {'C': 0.29418566992913037, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 22 with value: 0.1967176564838189.\n",
      "[I 2025-12-03 09:33:48,118] Trial 26 finished with value: -5.0 and parameters: {'C': 0.1512251765979272, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 22 with value: 0.1967176564838189.\n",
      "[I 2025-12-03 09:33:48,424] Trial 27 finished with value: -10.0 and parameters: {'C': 0.6186821524659152, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 22 with value: 0.1967176564838189.\n",
      "[I 2025-12-03 09:33:48,738] Trial 28 finished with value: 0.23223546944858464 and parameters: {'C': 0.28827413730968526, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:49,050] Trial 29 finished with value: -5.0 and parameters: {'C': 0.25346792687419545, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:49,356] Trial 30 finished with value: -5.0 and parameters: {'C': 0.10792715319839817, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:49,678] Trial 31 finished with value: 0.10154323437752111 and parameters: {'C': 0.3144777426269207, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:49,998] Trial 32 finished with value: -5.0 and parameters: {'C': 0.20196771486413423, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:50,311] Trial 33 finished with value: -5.0 and parameters: {'C': 0.285944624017348, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:50,656] Trial 34 finished with value: -5.0 and parameters: {'C': 0.5146807867336377, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:50,994] Trial 35 finished with value: -5.0 and parameters: {'C': 0.3643355643237104, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:51,303] Trial 36 finished with value: -10.0 and parameters: {'C': 0.7020499596989707, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:51,611] Trial 37 finished with value: -10.0 and parameters: {'C': 0.4541992361334994, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:51,957] Trial 38 finished with value: -5.0 and parameters: {'C': 0.1639885774760648, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:52,267] Trial 39 finished with value: -0.4181438863836624 and parameters: {'C': 0.4234819606456937, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:52,579] Trial 40 finished with value: 0.20802965002143653 and parameters: {'C': 0.29668146600626005, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:52,895] Trial 41 finished with value: 0.10948727908331701 and parameters: {'C': 0.31323865430123404, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:53,218] Trial 42 finished with value: -5.0 and parameters: {'C': 0.2166352946249872, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:53,531] Trial 43 finished with value: 0.09089957809807725 and parameters: {'C': 0.3192865857593589, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:53,854] Trial 44 finished with value: -10.0 and parameters: {'C': 0.6159834469930037, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:54,186] Trial 45 finished with value: -5.0 and parameters: {'C': 0.25945304959698734, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:54,542] Trial 46 finished with value: -5.0 and parameters: {'C': 0.4436100978014585, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:54,860] Trial 47 finished with value: -5.0 and parameters: {'C': 0.16161752873418755, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:55,208] Trial 48 finished with value: -0.05092665635879823 and parameters: {'C': 0.33984217880214546, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:55,582] Trial 49 finished with value: -5.0 and parameters: {'C': 0.22753969694433793, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:55,944] Trial 50 finished with value: -5.0 and parameters: {'C': 0.17734383440200252, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:56,289] Trial 51 finished with value: 0.145370596371329 and parameters: {'C': 0.3104542326042237, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:56,622] Trial 52 finished with value: -5.0 and parameters: {'C': 0.2810842200963256, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:56,950] Trial 53 finished with value: -0.24277366477224793 and parameters: {'C': 0.3793632883133853, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:57,269] Trial 54 finished with value: -5.0 and parameters: {'C': 0.21073121514155244, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:57,597] Trial 55 finished with value: 0.030489325229858255 and parameters: {'C': 0.33012217139204786, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:57,944] Trial 56 finished with value: -5.0 and parameters: {'C': 0.24593853974449936, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:58,300] Trial 57 finished with value: -0.3362365827746636 and parameters: {'C': 0.42860144156104724, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 28 with value: 0.23223546944858464.\n",
      "[I 2025-12-03 09:33:58,697] Trial 58 finished with value: 0.24335432143730273 and parameters: {'C': 0.28852510298522693, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:33:59,046] Trial 59 finished with value: -5.0 and parameters: {'C': 0.13914741646311074, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:33:59,410] Trial 60 finished with value: -5.0 and parameters: {'C': 0.18412608402064826, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:33:59,783] Trial 61 finished with value: -5.0 and parameters: {'C': 0.28493885721745893, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:00,152] Trial 62 finished with value: -0.12244419560957465 and parameters: {'C': 0.36042388634119815, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:00,497] Trial 63 finished with value: -5.0 and parameters: {'C': 0.23810123717485343, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:00,860] Trial 64 finished with value: 0.11212796384019208 and parameters: {'C': 0.31301622494566356, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:01,223] Trial 65 finished with value: -0.5088376041988268 and parameters: {'C': 0.4904597858610235, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:01,565] Trial 66 finished with value: -0.30557348889221947 and parameters: {'C': 0.3994156897806203, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:01,928] Trial 67 finished with value: -5.0 and parameters: {'C': 0.25797981494079913, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:02,265] Trial 68 finished with value: -5.0 and parameters: {'C': 0.20583176611335716, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:02,598] Trial 69 finished with value: -0.09512043341386667 and parameters: {'C': 0.298646265223645, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:02,963] Trial 70 finished with value: -0.11730899625976066 and parameters: {'C': 0.363409691760169, 'kernel': 'linear', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:03,296] Trial 71 finished with value: 0.022343249785273356 and parameters: {'C': 0.33261685585390643, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:03,618] Trial 72 finished with value: -5.0 and parameters: {'C': 0.27684584180861405, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:03,946] Trial 73 finished with value: -5.0 and parameters: {'C': 0.22467614616943501, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:04,273] Trial 74 finished with value: -0.5074644893226404 and parameters: {'C': 0.4944821673935584, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:04,597] Trial 75 finished with value: -0.1931484914882856 and parameters: {'C': 0.3178704031321604, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:04,952] Trial 76 finished with value: -5.0 and parameters: {'C': 0.39471160406938444, 'kernel': 'rbf', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:05,278] Trial 77 finished with value: -10.0 and parameters: {'C': 0.5774148104724838, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:05,601] Trial 78 finished with value: -5.0 and parameters: {'C': 0.18357306982019128, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:05,932] Trial 79 finished with value: -5.0 and parameters: {'C': 0.2579425556584912, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:06,258] Trial 80 finished with value: -0.41541342747297294 and parameters: {'C': 0.4565552428440312, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:06,588] Trial 81 finished with value: 0.15325985466650455 and parameters: {'C': 0.3092945073509978, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:06,915] Trial 82 finished with value: 0.19244930327404575 and parameters: {'C': 0.30403417631420027, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:07,245] Trial 83 finished with value: 0.20025550581106139 and parameters: {'C': 0.3011267428474755, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:07,622] Trial 84 finished with value: -5.0 and parameters: {'C': 0.23337609638826157, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:07,953] Trial 85 finished with value: -0.2812500000000002 and parameters: {'C': 0.3921585508199917, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:08,276] Trial 86 finished with value: -5.0 and parameters: {'C': 0.2774792233945301, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:08,621] Trial 87 finished with value: -0.2690158197336 and parameters: {'C': 0.34726589064762686, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:08,999] Trial 88 finished with value: -5.0 and parameters: {'C': 0.2037083450965623, 'kernel': 'rbf', 'gamma': 'scale', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:09,325] Trial 89 finished with value: 0.19244930327404575 and parameters: {'C': 0.3032510363645625, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:09,651] Trial 90 finished with value: -5.0 and parameters: {'C': 0.25618968604414255, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:09,985] Trial 91 finished with value: 0.09089957809807725 and parameters: {'C': 0.31835564717115644, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:10,311] Trial 92 finished with value: 0.21061394146209478 and parameters: {'C': 0.2918354003993198, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:10,637] Trial 93 finished with value: -5.0 and parameters: {'C': 0.28476637404274757, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:10,964] Trial 94 finished with value: -5.0 and parameters: {'C': 0.22319705307391335, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:11,290] Trial 95 finished with value: -0.04722744360902276 and parameters: {'C': 0.35300803874297176, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:11,616] Trial 96 finished with value: -0.3406524265802744 and parameters: {'C': 0.42763164208516236, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:11,944] Trial 97 finished with value: -5.0 and parameters: {'C': 0.18980287471970447, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': False}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:12,273] Trial 98 finished with value: -5.0 and parameters: {'C': 0.24454606510396992, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "[I 2025-12-03 09:34:12,603] Trial 99 finished with value: -0.30557348889221947 and parameters: {'C': 0.39958169035192576, 'kernel': 'linear', 'gamma': 'auto', 'use_class_weight': True}. Best is trial 58 with value: 0.24335432143730273.\n",
      "\n",
      "‚úÖ Optimizaci√≥n completada\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZACI√ìN FINAL - BAJAR DE 9% A <5%\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ Data Augmentation (50% con sin√≥nimos)\")\n",
    "print(\"‚úÖ Class Weights balanceados (menos extremos)\")\n",
    "print(\"‚úÖ Regularizaci√≥n L2 ULTRA fuerte (C: 0.01-1.0)\")\n",
    "print(\"‚úÖ Vectorizador ULTRA optimizado (1000 features)\")\n",
    "print(\"‚úÖ Penalizaci√≥n MUY fuerte por overfitting > 5%\")\n",
    "print(\"‚úÖ Rechazar modelos con recall extremo (>0.95)\")\n",
    "print(\"\\nObjetivo: F1 > 0.55 Y overfitting < 5%\")\n",
    "print(\"Estado actual: 9.06% ‚Üí Objetivo: <5%\")\n",
    "print(\"Trials: 100 (b√∫squeda exhaustiva)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n‚úÖ Optimizaci√≥n completada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESULTADOS FINALES\n",
      "================================================================================\n",
      "F1-score (test): 0.6277\n",
      "Accuracy (test): 0.4900\n",
      "Precision (test): 0.4725\n",
      "Recall (test): 0.9348\n",
      "Diferencia F1: 12.69%\n",
      "\n",
      "‚ö†Ô∏è  F1-score aceptable pero overfitting a√∫n alto\n",
      "   Overfitting: 12.69% (objetivo: <5%)\n",
      "   Mejora: de 9.06% a 12.69% (reducci√≥n: -3.63%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Entrenar mejor modelo\n",
    "best_params = study.best_params\n",
    "use_class_weight = best_params.get('use_class_weight', False)\n",
    "\n",
    "# Usar class weights balanceados si se activ√≥\n",
    "if use_class_weight:\n",
    "    balanced_weights = {0: 1.0, 1: 1.1}  # Menos extremo que class_weights originales\n",
    "    final_class_weight = balanced_weights\n",
    "else:\n",
    "    final_class_weight = None\n",
    "\n",
    "best_model = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'],\n",
    "    class_weight=final_class_weight,\n",
    "    random_state=42,\n",
    "    probability=True\n",
    ")\n",
    "\n",
    "best_model.fit(X_train_tfidf, y_train_aug)\n",
    "results = evaluate_model(best_model, X_train_tfidf, X_test_tfidf, y_train_aug, y_test)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESULTADOS FINALES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"F1-score (test): {results['test_f1']:.4f}\")\n",
    "print(f\"Accuracy (test): {results['test_accuracy']:.4f}\")\n",
    "print(f\"Precision (test): {results['test_precision']:.4f}\")\n",
    "print(f\"Recall (test): {results['test_recall']:.4f}\")\n",
    "print(f\"Diferencia F1: {results['diff_f1']:.2f}%\")\n",
    "\n",
    "if results['diff_f1'] < 5.0 and results['test_f1'] > 0.55:\n",
    "    print(\"\\n‚úÖ‚úÖ‚úÖ OBJETIVO CUMPLIDO: Overfitting < 5% Y F1 > 0.55\")\n",
    "    print(f\"   ¬°Reducci√≥n exitosa de 9.06% a {results['diff_f1']:.2f}%!\")\n",
    "elif results['diff_f1'] < 5.0:\n",
    "    print(\"\\n‚úÖ Overfitting controlado (<5%) pero F1-score bajo\")\n",
    "    print(f\"   F1-score: {results['test_f1']:.4f} (objetivo: >0.55)\")\n",
    "    print(f\"   Overfitting: {results['diff_f1']:.2f}% ‚úÖ\")\n",
    "elif results['diff_f1'] < 6.0:\n",
    "    print(\"\\nüéØ MUY CERCA: Overfitting < 6%\")\n",
    "    print(f\"   Overfitting: {results['diff_f1']:.2f}% (objetivo: <5%, diferencia: {results['diff_f1']-5.0:.2f}%)\")\n",
    "    print(f\"   F1-score: {results['test_f1']:.4f}\")\n",
    "elif results['test_f1'] > 0.55:\n",
    "    print(\"\\n‚ö†Ô∏è  F1-score aceptable pero overfitting a√∫n alto\")\n",
    "    print(f\"   Overfitting: {results['diff_f1']:.2f}% (objetivo: <5%)\")\n",
    "    print(f\"   Mejora: de 9.06% a {results['diff_f1']:.2f}% (reducci√≥n: {9.06-results['diff_f1']:.2f}%)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Revisar estrategia - ambos objetivos no cumplidos\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaci√≥n Cruzada (Cross-Validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (CV): 0.7088 (+/- 0.0158)\n",
      "Scores: [0.72423398 0.70254958 0.70555556 0.70422535 0.70752089]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import vstack\n",
    "X_all = vstack([X_train_tfidf, X_test_tfidf])\n",
    "y_all = np.concatenate([y_train_aug, y_test])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_model, X_all, y_all, cv=cv, scoring='f1', n_jobs=-1)\n",
    "\n",
    "print(f\"F1-score (CV): {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "print(f\"Scores: {cv_scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Modelo no guardado: No cumple objetivos\n",
      "   Overfitting: 12.69% (objetivo: <5%)\n",
      "   F1-score: 0.6277 (objetivo: >0.55)\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo si cumple objetivos o est√° muy cerca\n",
    "if results['diff_f1'] < 5.0 and results['test_f1'] > 0.55:\n",
    "    # Objetivo cumplido perfectamente\n",
    "    save_model = True\n",
    "    reason = \"Objetivo cumplido\"\n",
    "elif results['diff_f1'] < 6.0 and results['test_f1'] > 0.55:\n",
    "    # Muy cerca del objetivo, aceptable\n",
    "    save_model = True\n",
    "    reason = f\"Muy cerca del objetivo (overfitting: {results['diff_f1']:.2f}%)\"\n",
    "else:\n",
    "    save_model = False\n",
    "    reason = \"No cumple objetivos\"\n",
    "\n",
    "if save_model:\n",
    "    with open('../models/final_model_anti_overfitting.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    with open('../models/final_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "        pickle.dump(tfidf, f)\n",
    "    \n",
    "    model_info = {\n",
    "        'hyperparameters': best_params,\n",
    "        'test_f1': results['test_f1'],\n",
    "        'diff_f1': results['diff_f1'],\n",
    "        'cv_f1_mean': cv_scores.mean(),\n",
    "        'class_weights_used': use_class_weight,\n",
    "        'data_augmentation': True\n",
    "    }\n",
    "    \n",
    "    with open('../models/final_model_info.pkl', 'wb') as f:\n",
    "        pickle.dump(model_info, f)\n",
    "    \n",
    "    print(f\"‚úÖ Modelo guardado exitosamente ({reason})\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Modelo no guardado: {reason}\")\n",
    "    print(f\"   Overfitting: {results['diff_f1']:.2f}% (objetivo: <5%)\")\n",
    "    print(f\"   F1-score: {results['test_f1']:.4f} (objetivo: >0.55)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis de Resultados y Estrategias Alternativas\n",
    "\n",
    "Si el modelo a√∫n no cumple objetivos, considerar:\n",
    "1. Aceptar overfitting ligeramente mayor si el modelo es funcional\n",
    "2. Documentar las limitaciones del dataset peque√±o\n",
    "3. Probar modelos m√°s simples (Logistic Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AN√ÅLISIS DETALLADO\n",
      "================================================================================\n",
      "\n",
      "üìä Comparaci√≥n Train vs Test:\n",
      "   Train F1: 0.7546\n",
      "   Test F1: 0.6277\n",
      "   Diferencia: 12.69%\n",
      "\n",
      "üìä Matriz de Confusi√≥n:\n",
      "[[12 96]\n",
      " [ 6 86]]\n",
      "\n",
      "   Verdaderos Negativos (TN): 12\n",
      "   Falsos Positivos (FP): 96\n",
      "   Falsos Negativos (FN): 6\n",
      "   Verdaderos Positivos (TP): 86\n",
      "\n",
      "üìä Hiperpar√°metros finales:\n",
      "   C: 0.28852510298522693\n",
      "   kernel: linear\n",
      "   gamma: auto\n",
      "   use_class_weight: True\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis detallado\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DETALLADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Comparaci√≥n Train vs Test:\")\n",
    "print(f\"   Train F1: {results['train_f1']:.4f}\")\n",
    "print(f\"   Test F1: {results['test_f1']:.4f}\")\n",
    "print(f\"   Diferencia: {results['diff_f1']:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Matriz de Confusi√≥n:\")\n",
    "print(results['confusion_matrix'])\n",
    "\n",
    "# Calcular m√©tricas adicionales\n",
    "tn, fp, fn, tp = results['confusion_matrix'].ravel()\n",
    "print(f\"\\n   Verdaderos Negativos (TN): {tn}\")\n",
    "print(f\"   Falsos Positivos (FP): {fp}\")\n",
    "print(f\"   Falsos Negativos (FN): {fn}\")\n",
    "print(f\"   Verdaderos Positivos (TP): {tp}\")\n",
    "\n",
    "print(f\"\\nüìä Hiperpar√°metros finales:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
