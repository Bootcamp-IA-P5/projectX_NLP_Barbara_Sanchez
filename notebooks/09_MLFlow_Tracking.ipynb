{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä MLFlow Tracking - Experimentos de Hate Speech Detection\n",
    "\n",
    "Este notebook demuestra c√≥mo usar MLFlow para trackear experimentos de machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# A√±adir src al path\n",
    "project_root = Path('../').resolve()\n",
    "sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "from models.train import train_model\n",
    "from models.evaluate import evaluate_model\n",
    "from features.vectorization import load_vectorized_data\n",
    "from utils.mlflow_tracking import get_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar Datos Vectorizados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos vectorizados cargados desde: ../data/processed\n",
      "‚úÖ Datos cargados:\n",
      "   Train: (800, 1000)\n",
      "   Test: (200, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos vectorizados\n",
    "X_train, X_test, y_train, y_test = load_vectorized_data(\n",
    "    input_dir=Path('../data/processed'),\n",
    "    prefix='tfidf'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Datos cargados:\")\n",
    "print(f\"   Train: {X_train.shape}\")\n",
    "print(f\"   Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inicializar MLFlow Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLFlow tracker inicializado: hate_speech_detection\n",
      "‚úÖ MLFlow tracker inicializado: hate_speech_detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barbara/.pyenv/versions/3.11.9/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "# Inicializar tracker de MLFlow\n",
    "tracker = get_tracker(experiment_name=\"hate_speech_detection\")\n",
    "print(f\"‚úÖ MLFlow tracker inicializado: {tracker.experiment_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenar y Registrar Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Entrenando svm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/09 18:44:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/09 18:44:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  M√©tricas saltadas: confusion_matrix (array 2D)\n",
      "‚ö†Ô∏è  No se pudo guardar el modelo en MLFlow: No module named '_lzma'\n",
      "   Se guardaron las m√©tricas y par√°metros correctamente.\n",
      "   Para guardar modelos, instala Python con soporte completo o usa SQLite backend.\n",
      "‚úÖ Modelo svm registrado en MLFlow\n",
      "‚úÖ svm registrado en MLFlow\n",
      "   F1-score (test): 0.6866\n",
      "   Overfitting: 2.54%\n",
      "\n",
      "üîß Entrenando logistic...\n",
      "‚ö†Ô∏è  M√©tricas saltadas: confusion_matrix (array 2D)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/09 18:44:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No se pudo guardar el modelo en MLFlow: No module named '_lzma'\n",
      "   Se guardaron las m√©tricas y par√°metros correctamente.\n",
      "   Para guardar modelos, instala Python con soporte completo o usa SQLite backend.\n",
      "‚úÖ Modelo logistic registrado en MLFlow\n",
      "‚úÖ logistic registrado en MLFlow\n",
      "   F1-score (test): 0.7119\n",
      "   Overfitting: 11.36%\n",
      "\n",
      "üîß Entrenando naive_bayes...\n",
      "‚ö†Ô∏è  M√©tricas saltadas: confusion_matrix (array 2D)\n",
      "‚ö†Ô∏è  No se pudo guardar el modelo en MLFlow: No module named '_lzma'\n",
      "   Se guardaron las m√©tricas y par√°metros correctamente.\n",
      "   Para guardar modelos, instala Python con soporte completo o usa SQLite backend.\n",
      "‚úÖ Modelo naive_bayes registrado en MLFlow\n",
      "‚úÖ naive_bayes registrado en MLFlow\n",
      "   F1-score (test): 0.4355\n",
      "   Overfitting: 30.45%\n",
      "\n",
      "üîß Entrenando random_forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/09 18:44:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  M√©tricas saltadas: confusion_matrix (array 2D)\n",
      "‚ö†Ô∏è  No se pudo guardar el modelo en MLFlow: No module named '_lzma'\n",
      "   Se guardaron las m√©tricas y par√°metros correctamente.\n",
      "   Para guardar modelos, instala Python con soporte completo o usa SQLite backend.\n",
      "‚úÖ Modelo random_forest registrado en MLFlow\n",
      "‚úÖ random_forest registrado en MLFlow\n",
      "   F1-score (test): 0.6335\n",
      "   Overfitting: 12.24%\n"
     ]
    }
   ],
   "source": [
    "# Entrenar m√∫ltiples modelos y registrarlos en MLFlow\n",
    "models_to_test = [\n",
    "    {'name': 'svm', 'type': 'svm', 'params': {'C': 0.056, 'kernel': 'linear', 'class_weight': 'balanced'}},\n",
    "    {'name': 'logistic', 'type': 'logistic', 'params': {'C': 0.1, 'penalty': 'l2', 'class_weight': 'balanced', 'max_iter': 1000}},\n",
    "    {'name': 'naive_bayes', 'type': 'naive_bayes', 'params': {'alpha': 10.0}},\n",
    "    {'name': 'random_forest', 'type': 'random_forest', 'params': {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5, 'class_weight': 'balanced'}}\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_config in models_to_test:\n",
    "    print(f\"\\nüîß Entrenando {model_config['name']}...\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model = train_model(\n",
    "        model_type=model_config['type'],\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        **model_config['params']\n",
    "    )\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    metrics = evaluate_model(\n",
    "        model, X_train, X_test, y_train, y_test, verbose=False\n",
    "    )\n",
    "    \n",
    "    results[model_config['name']] = metrics\n",
    "    \n",
    "    # Registrar en MLFlow\n",
    "    tracker.log_model_training(\n",
    "        model=model,\n",
    "        model_name=model_config['name'],\n",
    "        metrics=metrics,\n",
    "        params=model_config['params'],\n",
    "        vectorizer_type='tfidf',\n",
    "        tags={'experiment': 'model_comparison', 'vectorizer': 'tfidf'}\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ {model_config['name']} registrado en MLFlow\")\n",
    "    print(f\"   F1-score (test): {metrics['test_f1']:.4f}\")\n",
    "    print(f\"   Overfitting: {metrics['diff_f1']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Comparaci√≥n de Modelos:\n",
      "       Modelo  F1 (test)  F1 (train)  Overfitting (%)  Accuracy (test)  Precision (test)  Recall (test)\n",
      "     logistic   0.711864    0.825485        11.362036            0.745          0.741176       0.684783\n",
      "          svm   0.686567    0.711930         2.536300            0.580          0.522727       1.000000\n",
      "random_forest   0.633540    0.755952        12.241201            0.705          0.739130       0.554348\n",
      "  naive_bayes   0.435484    0.740000        30.451613            0.650          0.843750       0.293478\n"
     ]
    }
   ],
   "source": [
    "# Crear DataFrame con resultados\n",
    "comparison_data = []\n",
    "for model_name, metrics in results.items():\n",
    "    comparison_data.append({\n",
    "        'Modelo': model_name,\n",
    "        'F1 (test)': metrics['test_f1'],\n",
    "        'F1 (train)': metrics['train_f1'],\n",
    "        'Overfitting (%)': metrics['diff_f1'],\n",
    "        'Accuracy (test)': metrics['test_accuracy'],\n",
    "        'Precision (test)': metrics['test_precision'],\n",
    "        'Recall (test)': metrics['test_recall']\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "df_comparison = df_comparison.sort_values('F1 (test)', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Comparaci√≥n de Modelos:\")\n",
    "print(df_comparison.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizar en MLFlow UI\n",
    "\n",
    "Para ver los experimentos en la interfaz de MLFlow:\n",
    "\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "Luego abre: http://localhost:5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
