# ğŸ“‹ Issues para Crear en GitHub

## ğŸ¯ Issues Recomendadas (5-7 issues)

### Issue 1: Mejorar CalibraciÃ³n de Probabilidades del Modelo

**TÃ­tulo**: `feat: Improve model probability calibration for better user experience`

**DescripciÃ³n**:
```markdown
## ğŸ¯ Objetivo
Mejorar la calibraciÃ³n de probabilidades del modelo SVM para que las predicciones sean mÃ¡s distinguibles y confiables para el usuario.

## ğŸ“Š Contexto Actual
El modelo actual tiene probabilidades muy similares (rango 0.44-0.48) que requieren amplificaciÃ³n manual. Aunque funciona, serÃ­a mejor tener un modelo con mejor calibraciÃ³n intrÃ­nseca.

## âœ… Tareas
- [ ] Investigar tÃ©cnicas de calibraciÃ³n (Platt scaling, Isotonic regression)
- [ ] Implementar calibraciÃ³n post-entrenamiento
- [ ] Evaluar mejora en mÃ©tricas
- [ ] Actualizar documentaciÃ³n

## ğŸ”— Relacionado
- Modelo actual: `backend/models/optimized/best_optimized_model.pkl`
- CÃ³digo relevante: `backend/src/api/predict.py`

## ğŸ“ Notas
Prioridad: Media
EstimaciÃ³n: 4-6 horas
```

**Labels**: `enhancement`, `model`, `priority-medium`

---

### Issue 2: Implementar Data Augmentation para Mejorar Dataset

**TÃ­tulo**: `feat: Add data augmentation techniques to expand training dataset`

**DescripciÃ³n**:
```markdown
## ğŸ¯ Objetivo
Implementar tÃ©cnicas de data augmentation para aumentar el tamaÃ±o del dataset y mejorar el rendimiento del modelo.

## ğŸ“Š Contexto
El dataset actual tiene 1,000 comentarios. Con data augmentation podrÃ­amos expandirlo y mejorar la generalizaciÃ³n del modelo.

## âœ… Tareas
- [ ] Implementar reemplazo por sinÃ³nimos (usar WordNet o spaCy)
- [ ] Implementar traducciÃ³n y back-translation
- [ ] Implementar parafrasis
- [ ] Aplicar augmentation al dataset
- [ ] Evaluar mejora en mÃ©tricas del modelo
- [ ] Crear notebook `12_Data_Augmentation.ipynb`

## ğŸ”— Relacionado
- Dataset: `backend/data/raw/youtoxic_english_1000.csv`
- CÃ³digo: Crear `backend/src/data/augmentation.py`

## ğŸ“ Notas
Prioridad: Alta (requisito de rÃºbrica)
EstimaciÃ³n: 6-8 horas
```

**Labels**: `enhancement`, `data`, `priority-high`, `rubric-requirement`

---

### Issue 3: AÃ±adir AnÃ¡lisis de Clustering para EDA

**TÃ­tulo**: `feat: Add clustering analysis for exploratory data analysis`

**DescripciÃ³n**:
```markdown
## ğŸ¯ Objetivo
Implementar anÃ¡lisis de clustering (KMeans, DBSCAN) para descubrir patrones ocultos en los comentarios y mejorar el EDA.

## ğŸ“Š Contexto
El clustering puede revelar grupos naturales de comentarios que no estÃ¡n relacionados directamente con la etiqueta tÃ³xico/no tÃ³xico.

## âœ… Tareas
- [ ] Crear notebook `11_Clustering_Analysis.ipynb`
- [ ] Aplicar KMeans con diferentes k (2, 3, 4, 5)
- [ ] Aplicar DBSCAN para encontrar outliers
- [ ] Visualizar clusters con PCA/t-SNE
- [ ] Analizar caracterÃ­sticas de cada cluster
- [ ] Integrar visualizaciones en frontend (opcional)

## ğŸ”— Relacionado
- Datos vectorizados: `backend/data/processed/tfidf_X_train.pkl`
- EDA actual: `backend/notebooks/01_EDA.ipynb`

## ğŸ“ Notas
Prioridad: Alta (requisito de rÃºbrica)
EstimaciÃ³n: 4-6 horas
```

**Labels**: `enhancement`, `eda`, `clustering`, `priority-high`, `rubric-requirement`

---

### Issue 4: AÃ±adir Soporte Multiidioma

**TÃ­tulo**: `feat: Add multi-language support for hate speech detection`

**DescripciÃ³n**:
```markdown
## ğŸ¯ Objetivo
Extender el sistema para soportar detecciÃ³n de hate speech en mÃºltiples idiomas (espaÃ±ol, francÃ©s, etc.).

## ğŸ“Š Contexto Actual
El modelo actual estÃ¡ entrenado solo en inglÃ©s. Para ser mÃ¡s Ãºtil, deberÃ­a soportar otros idiomas.

## âœ… Tareas
- [ ] Investigar modelos multilingÃ¼es (mBERT, XLM-RoBERTa)
- [ ] Recopilar dataset en otros idiomas
- [ ] Entrenar modelo multilingÃ¼e o modelos por idioma
- [ ] Actualizar API para detectar idioma automÃ¡ticamente
- [ ] Actualizar frontend con selector de idioma
- [ ] Documentar limitaciones

## ğŸ”— Relacionado
- Modelo actual: SVM optimizado (inglÃ©s)
- API: `backend/main.py`

## ğŸ“ Notas
Prioridad: Baja (futuro)
EstimaciÃ³n: 20-30 horas
```

**Labels**: `enhancement`, `feature`, `priority-low`, `future`

---

### Issue 5: Mejorar Manejo de Errores en API

**TÃ­tulo**: `fix: Improve error handling and user feedback in API endpoints`

**DescripciÃ³n**:
```markdown
## ğŸ¯ Objetivo
Mejorar el manejo de errores en la API para proporcionar mensajes mÃ¡s claros y Ãºtiles al usuario.

## ğŸ“Š Contexto Actual
Algunos errores no tienen mensajes descriptivos o no se manejan correctamente.

## âœ… Tareas
- [ ] Revisar todos los endpoints y casos de error
- [ ] AÃ±adir validaciÃ³n mÃ¡s robusta de inputs
- [ ] Mejorar mensajes de error (especÃ­ficos y Ãºtiles)
- [ ] AÃ±adir logging estructurado
- [ ] Crear cÃ³digos de error personalizados
- [ ] Actualizar documentaciÃ³n de API

## ğŸ”— Relacionado
- API: `backend/main.py`
- Tests: `backend/tests/test_api.py`

## ğŸ“ Notas
Prioridad: Media
EstimaciÃ³n: 3-4 horas
```

**Labels**: `bug`, `api`, `priority-medium`

---

### Issue 6: Optimizar Tiempo de Respuesta de la API

**TÃ­tulo**: `perf: Optimize API response time and add caching`

**DescripciÃ³n**:
```markdown
## ğŸ¯ Objetivo
Optimizar el tiempo de respuesta de la API mediante caching y optimizaciones.

## ğŸ“Š Contexto
La API puede ser lenta con mÃºltiples requests. El caching puede mejorar significativamente el rendimiento.

## âœ… Tareas
- [ ] Implementar caching de predicciones frecuentes (Redis o in-memory)
- [ ] Optimizar carga de modelo (lazy loading)
- [ ] AÃ±adir rate limiting
- [ ] Medir tiempos de respuesta antes/despuÃ©s
- [ ] Documentar estrategia de caching

## ğŸ”— Relacionado
- API: `backend/main.py`
- Predictor: `backend/src/api/predict.py`

## ğŸ“ Notas
Prioridad: Baja
EstimaciÃ³n: 6-8 horas
```

**Labels**: `performance`, `enhancement`, `priority-low`

---

### Issue 7: AÃ±adir Tests de IntegraciÃ³n

**TÃ­tulo**: `test: Add integration tests for complete user workflows`

**DescripciÃ³n**:
```markdown
## ğŸ¯ Objetivo
AÃ±adir tests de integraciÃ³n que prueben flujos completos de usuario (end-to-end).

## ğŸ“Š Contexto Actual
Tenemos tests unitarios, pero faltan tests de integraciÃ³n que prueben el sistema completo.

## âœ… Tareas
- [ ] Crear tests de integraciÃ³n para flujo completo:
  - [ ] AnÃ¡lisis individual â†’ guardado en BD â†’ consulta
  - [ ] AnÃ¡lisis YouTube â†’ predicciones â†’ estadÃ­sticas
  - [ ] Batch analysis â†’ resultados agregados
- [ ] AÃ±adir fixtures para datos de prueba
- [ ] Configurar CI/CD para ejecutar tests
- [ ] Documentar cÃ³mo ejecutar tests

## ğŸ”— Relacionado
- Tests actuales: `backend/tests/`
- API: `backend/main.py`

## ğŸ“ Notas
Prioridad: Media
EstimaciÃ³n: 4-6 horas
```

**Labels**: `testing`, `enhancement`, `priority-medium`

---

## ğŸ“ Instrucciones para Crear las Issues

### OpciÃ³n 1: Desde GitHub Web

1. Ve a: https://github.com/Bootcamp-IA-P5/projectX_NLP_Barbara_Sanchez/issues
2. Click en "New Issue"
3. Copia y pega el tÃ­tulo y descripciÃ³n de cada issue
4. AÃ±ade las labels correspondientes
5. Click en "Submit new issue"

### OpciÃ³n 2: Desde GitHub CLI (si lo tienes instalado)

```bash
# Issue 1: CalibraciÃ³n
gh issue create --title "feat: Improve model probability calibration for better user experience" \
  --body-file issue1.md \
  --label "enhancement,model,priority-medium"

# Issue 2: Data Augmentation
gh issue create --title "feat: Add data augmentation techniques to expand training dataset" \
  --body-file issue2.md \
  --label "enhancement,data,priority-high,rubric-requirement"

# Issue 3: Clustering
gh issue create --title "feat: Add clustering analysis for exploratory data analysis" \
  --body-file issue3.md \
  --label "enhancement,eda,clustering,priority-high,rubric-requirement"

# Issue 4: Multiidioma
gh issue create --title "feat: Add multi-language support for hate speech detection" \
  --body-file issue4.md \
  --label "enhancement,feature,priority-low,future"

# Issue 5: Manejo de errores
gh issue create --title "fix: Improve error handling and user feedback in API endpoints" \
  --body-file issue5.md \
  --label "bug,api,priority-medium"

# Issue 6: OptimizaciÃ³n
gh issue create --title "perf: Optimize API response time and add caching" \
  --body-file issue6.md \
  --label "performance,enhancement,priority-low"

# Issue 7: Tests de integraciÃ³n
gh issue create --title "test: Add integration tests for complete user workflows" \
  --body-file issue7.md \
  --label "testing,enhancement,priority-medium"
```

---

## ğŸ¯ Issues Prioritarias para la RÃºbrica

Si solo quieres crear las **mÃ­nimas necesarias** para la rÃºbrica, crea estas 3:

1. âœ… **Issue 2**: Data Augmentation (requisito NLP)
2. âœ… **Issue 3**: Clustering (requisito ML)
3. âœ… **Issue 1 o 5**: Cualquiera de mejora/optimizaciÃ³n

---

## ğŸ“Š Resumen

- **Total issues**: 7
- **Prioridad Alta** (rÃºbrica): 2 (Data Augmentation, Clustering)
- **Prioridad Media**: 3 (CalibraciÃ³n, Errores, Tests)
- **Prioridad Baja**: 2 (Multiidioma, OptimizaciÃ³n)

**RecomendaciÃ³n**: Crea al menos 5 issues para demostrar buen uso de la herramienta.

